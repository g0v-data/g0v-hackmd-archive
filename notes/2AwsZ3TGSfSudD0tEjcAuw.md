# 司改會xSMC 20231217 講座紀錄

## 筆記
### 講座資訊
- 時間：2023/12/17 
- 主持人：
    - SMC 台灣科技媒體中心 陳璽尹執行長
- 講者：
    - 義謙法律事務所林俊宏律師
    - 台師大圖資所曾元顯特聘教授
    - 台大語言所謝書凱教授
- 紀錄：
    - Peter 
- vTaiwan 後續活動報名連結：https://docs.google.com/forms/d/e/1FAIpQLSehY4iklD2Kj6f2ji-Zh99ZSzV5kAATRWDfJBvoMvD46netFQ/viewform?usp=sf_link  
### 講座內容
- 謝：科技進入社會，法律與倫理議題。
- 對於司法院科技的看法
    - 觀眾1科技背景：AI 有點黑盒子，但司法應該要有一定明確性。所以只能盡量參與。
    - 觀眾2：有使用ChatGPT，認為是省時工具，但認為法官應該要確認跟檢查。
- 林：
    - 司法院發布新聞時，有點震驚，司法院的能力有這麼強嗎？
    - 最基本的主張：召開公聽會與指引
        - 第一時間的想法：請林律師參加內部專家會議。
        - 政策轉彎：改成公聽會。
        - 有了指引
    - 當初：沒有指引就有系統，似乎反過來了。
    - 司法院的草案指引：比想象中好一些。
        - 要點：
            - 強調輔助審判
            - 使用者自主原則
        - 對比：問 ChatGPT 如果要做司法應用的指引
            - 透明性
            - 法規
            - 反歧視與公正機制
            - 公眾參與
            - 社會更新
            - ChatGPT比司法院完整。
    - 法律人角度：是否能夠得到合理公正的判決，另一個角度是如果做得到，是否要來使用？
    - 機器只能做到判決整理
        - 司法院提到，想要降低法律的工作量。
        - 疑慮：當機器幫忙做整理時，整理作為篩選相關資訊的過程，就是做決定。
        - 防範機制。
        - 具體的操作細節：還不知道。
        - 公聽會是很低度的參與程序。
- 陳：
    - 目前的應用有限制在某些領域的案件上，原因是？
        - 目前是應用在人頭帳戶、毒品、車禍
            - 原因：數量大、案件類型較為單純
            - 是否真的單純？
                - 在具體案件的脈絡中，會需要討論案件的背景訊息
                - 變化性很強的態樣，是否真的適合用人工智慧來判斷？
        - 林律師覺得司法院有點誇大相關的能力
            - 人工智慧系統很厲害，就很難控制。
            - 司法院不是人工智慧的專業單位。
            - 社會影響評估是否要先做好？對於司法院來說，法官工作負擔是更優先的事項
    - 在法律上擔心重複出現的偏誤會是什麼？
        - 這個偏誤是確實存在的。但在現行的訴訟程序中仍然有可能出現
        - 但人工智慧的出現，會讓判決過程被固定。
        - 司法判決的另一個價值：捍衛某種價值。
        - 司法判決也是法律變遷與進步的場域：現在的看法，在過去是不可以的。
            - 人工智慧可能會造成法律演進的停滯
            - 法院直接接觸證據與評價證據：直接審理的要求，可能會被人工智慧的介入所影響
                - 直接審理原則：法官直接審理與接觸證據。
            - 輔助是輔助什麼？幫忙整理資料？人工智慧會如何摘錄資料？思維面向是否是相同的？
                - 摘要資料本身就會是價值選擇。
- 曾：
    - 科學傳播：十年前有寫過科學文章，認為science communication很有意義。
    - 問題回應：
        - AI 幻覺？AI 偏見？
            - 對於司法院的判決系統是不清楚的。
        - 如何監督與管理生成的內容
            - 技術開源
            - 訓練資料開源
            - 訓練資料有偏見，AI就有偏見
                - 也包含茲料量大的贏，量少的輸
            - 將人工智慧視為助理
        - 目前的系統是非常誤導：一鍵生成
            - 讓人工智慧提醒法官是否有沒有考量到的部分，這一部分人工智慧是有優勢的，例如常見問答集的審理，因為人工智慧系統有相關的資料，觀點就會更周到。
    - 人工智慧的原理
        - 目前的生成式人工智慧就是語言模型
        - 目前司法院使用的TMT5的基礎預訓練模型，以 chatgpt 等級來說，不算是大型語言模型。
            - 司法院利用T5這個語言模型，來微調與訓練。
            - T5模型 2019 Google 發布：
                - 文字與文字之間轉換器
                - 訓練方法：指示在前＋文句段落
                - 範例：翻譯與摘要
            - 訓練：輸入資料後，針對輸出資料進行評估，以調整模型的權重。
            - 其技術背後就是一個單純的神經網路：
                - 將文字轉為向量，再從向量到文字。藉由訓練的參數輸入，有越多的區塊，模型就會越大。資料越多，向量越多，區塊越多，就會越精準。
                - GPT: 2018 第一代 2019 第二代 2020 第三代
                - 資料量才是重點，因為網路架構都是開源的，LLAMA2是180萬個GPU小時來建立模型。微調訓練我們還是做不到。學校實驗室做不起來（GPT3以上就不行）
            - 結論：司法院的技術絕對不如 chatgpt，如何協助法官判斷。
            - 如何自動生成文字？
                - 條件機率問題：在獲知前幾個字詞後，準確估計下一個字詞的條件機率
                - 如何建構：問題上稱為條件建模
            - 語言解碼：
                - 輸入一個詞，AI 會選擇機率最高的給我選
                - 目前已經無法由人類來判斷，裏面已經沒有人工給的規則，而是他訓練的文本
            - 有效的語言建模：
                - 以神經網路來閱讀大量高品質的文字
                - 我如何預測下一個字的方法：解碼演算法
            - 會生成訓練資料裡沒有的文句（創造）
                - 訓練資料中有足夠的案例，就會影響生成結果
            - 輸入資料也會影響到生成結果
            - GPT擅長移花接木
                - 用經濟新聞來訓練 [相關論文](https://web.ntnu.edu.tw/~samtseng/papers/2020_GPT_News_1027.pdf)
                - 在長句的時候：生成內容與捏造內容密不可分。
    - AI 法官
        - 愛沙尼亞：試辦人工智慧法官
            - 沒有發展的新聞
        - Casetext 服務

    - 回應剛剛醫學的問題
        - 醫學的資料已經是千錘百鍊，法律跟人工智慧還沒看到大量的實驗。
        - 通用的案例試驗尚未出現，特定的是有可能的
            - 但是沒有看到數據，很難質疑
            - 沒有開源跟公開，人工智慧很難走到這個地步
- 謝：
    - 法律的：人工智慧的發展是黑盒子與灰盒子的狀態，為何相信科技，是因為科技是可控可以了解的，目前人工智慧有滿足？當人工智慧法官出現後，人類是可以選擇的嗎？如果系統真的有一個 insight，我們要聽嗎？
    - 技術的：我支持開源，但是 / 技術運作飛快，但調整要時間，呼應林律師提到，司法院是否有足夠能力來做這個事情？/ 如果技術真的到位了，未來我們要怎麼做？
    - 對於人工智慧的想像是現在的想像，但是人工智慧的議題很多是未來才會遇到的。人工智慧固然更穩定，但是其仍然依賴人類提供的資訊。
    - 司法院規範時，將規範對象稱呼為「使用者」，但是對於一般人有一個「透明性」，但是透明性，應該是不太可能的
- 陳：
    - 如果技術真的到位，是否應用就會有倫理問題
        - 目前判決中考量的資料是過去的判決書不存在的，但是這樣對於當下的事件判斷是否適當？好或不好？ [name=林俊宏律師]
        - 人工智慧幫助人類的同時，價值是否就不存在？[name=林俊宏律師]
    - 考量現實，開源是什麼意思？政府與企業的人工智慧又是如何？
        - 目前司法院公布的這四波，我預測能力是很受限的。[name=曾元顯教授]
        - 系統設計上有更多的解釋，利用 sub sentence 來指出訓練資料與生成結果的差異，人工智慧生成時，可以引經據典來考量，解釋的介面可以很清楚的話，就能降低大家的疑慮，也能讓受影響的當事人加以處理。輔助的措施做的夠多，信任就能多一些 [name=曾元顯教授] 

### 綜合與談 
- 信任度的問題，是否有調查過對司法系統的信任度是高的嗎？如果跟人工智慧相結合，是否能夠提升信任度？在無法信任人類法官時，或許人工智慧是一條路
    - 目前沒有實驗數據加以判斷 [name=曾元顯教授]
    - 如果不相信過去判決，為何會相信基於過去判決的人工智慧 [name=林俊宏律師]
    - 人工智慧會有一定的穩定性，與同質性的判斷
- 在制度方面，人的經驗知識也是建立在其他的科學知識基礎上，是否要做更新與演進
- 聽眾分享：目前 OpenAI 使用的方法不是更新與演進，而是以 rule-based 防範可能的風險。目前的大型語言模型，會偏好自身的大型語言模型，也因此用語言模型來規範語言模型來說是不可能的。
    - 現在的可解釋性，是用生成式結果來產出藉口，研究人員會認為這是說服使用者的結果，但是用在司法上會有不同的結果
    - 謝舒凱老師回應：科學上的可解釋性是，是請人工智慧提供判斷依據與知識圖譜。
- 陳：收斂的話，偏見應該是不可避免的？
- 偏見的定義是什麼？
- 曾：訓練方式可以被視為是統計上的內差法
    - 如果資料基礎多，那生成結果就會比較完整。
    - 但是資料基礎少的話，很多時候就會是變動。
    - 司法院要告知大家要做什麼？[name=林俊宏律師]
- 林：目前指引與應用的出現，就是容許司法院做這件事，但是萬一之後能力突飛猛進時，我們可以做到監督嗎？
- 陳：目前判決的訓練資料足夠嗎？過往的判決有偏見與歧視時，我們有辦法做出更好的AI嗎？
    - 我們面對的是一個什麼都懂的東西，然後要更懂法律 [name=謝舒凱教授]
        - 從語言觀點來說，目前人工智慧是以自然語言與人類溝通，例如法律上對於「公然」的定義，每個人都有自己的定義，大家對於公然有各自的想像，但法律上公然有判決累積的定義，這是在人工智慧的訓練上，要做到的。
- 如果有一個更好的司法院應該怎麼做？除了開源之外，要怎麼做？司法院可以如何進行接下來的行動？
    - 實驗方法公開、實驗數據公開、說服使用者，再來推廣。且應該學習醫學，相關指引應該要先出來，指引與流程都應該嚴謹。 [name=曾元顯教授]
    - 第一件事把指引弄好，指引的生成也要讓大家來討論。再來就是影響評估，來判斷正面與負面影響[name=林俊宏律師]
    - 第一步是公開，但是科技發展的速度比科學發展的速度更快，內部的輔助使用，接下來才能討論對於輔助利用。[name=謝舒凱教授]
- 政府開放資料的作業指引，那就開源，大家來共筆，藉由國發會來訂指引。
    - 目前共筆的機制可能會有篩選效益 [name=陳璽尹]
    - 可以透過代理人機制來處理 
- 開源有一個蠻大的風險，大家都能預測司法會發生什麼事，會快速放大偏誤。
    - 我覺得這不是風險，以後的技術會越來越快，這些技術會發生，且一定會發生。這不是問題，下一個問題是可不可以讓他們更有信賴感。  [name=曾元顯教授]
- 陳：剛剛的討論中，觀眾有沒有回饋？
    - 這些系統即便利用了，或許也可以公開給律所做使用，提供刺激與進步的方向。或許在第一審可以做利用，背後有制度與人事可以做把關
    - 做研究的老師要怎麼知道人的意見？[name=陳璽尹]
    - 人工智慧應用於判決，將來還要三級三審嗎？這是要在指引上路前討論的。在可以調整的前提下，誰來決定權重與比例？[name=林俊宏律師]
    - 目前可以調整的部分是，各種訓練的資料的比例。 [name=曾元顯教授]
    - 在另一種調整時，有一個面向是內部判決做改變。例如將國外的判決變成向量資料庫，在系統覺得有必要時就可以援引。[name=謝舒凱教授]
- 同樣的問題，會出現在社福等層面，目前如何進行賦能與取代
    - 目前有paper 

### 觀眾問題
- 相關指引：可操作性的問題
    - 抽象與具體的規範
#### 法律疑慮
> 預設是林俊宏律師回答
- 是否跳得太快？輔助也有可能類似資料庫，如果將其作為提供資料的依據？提供法官來做判斷？
    - 單純資料整理：不一定要用到人工智慧。
    - 但司法院的輔助判決尚未明確。
    - 縱使是資料整理，仍然要一定的脈絡
- 人工智慧協助撰寫書狀的問題，問題是會牽涉到被告的命運嗎？醫療現場會依賴分析系統，機器的分析系統可以幫助人類醫生下決定？讓AI來寫判決書會比讓人來寫判決書還差嗎？人類本身有自己的感情。
    - 人工智慧會生成公平公正合理的判決，是否合理？
    - 判決本身不是很機械化的工作，會有很多人類與社會價值的取捨，與醫學科學判斷不同。
- 這一次的指引，影響最大的是法官？目前司法實務上有量刑表與書類機制，是否對於法官產生影響？
    - 當時提出時，司法院並沒有說明
- 指引出來是雙面刃，會影響人民對於司法信任。風險在於人民會不會因此對司法信任動搖？
    - 人的成分會被機器弱化，
- 我們要的判決是，同樣一包證據，是誰來判都有結果的穩定性與規律化，還是法官會有個人意見比較好？再來就是協助上，例如親權酌定中，透過連結來mapping，決策支援的兩個層次：事實上的分類與判決內容生成，哪一個是可以被接受的？
    - 法律判決的決定性與安定性在現在是會被追求的，但是很難找到個案完全相同的。
    - 問題在於後面的價值考量是否能夠全面性地被考量，讓判決成為固定與僵化的判決。

### 總結
- 曾：五年十年之後，這些問題都可以獲得驗證。
- 林：這個技術是必然會到來的，但是作為司法相關NGO，會擔憂的是是否走得太快，因為司法仍然是司法相關的守護者。
- 謝：未來是人機共存的時代，但至少人的精神還要存在。

## 紀錄文章本文

司法院於今年9月發布新聞稿，宣布司法院將利用人工智慧協助法官進行判決撰寫等工作。相關新聞利用引發諸多討論。尤其適逢 ChatGPT 等生成式人工智慧技術造成的改變開始影響大家的生活，人工智慧的技術與相關的法律與倫理議題亦逐漸受到重視。民間司改會等關注司法議題的民間團體之後召開記者會回應，提醒司法院要注意相關的倫理與法律議題，避免人工智慧造成的風險，並且應該先提出相關的規範指引，再投入應用。

司法院於是在12月底，就〈司法院及所屬機關發展人工智慧參考指引草案〉召開公聽會。為了讓大眾更加了解這個議題，台灣科技媒體中心與民間司改會在12月17日舉辦講座「生成式AI輔助寫判決書，智慧司法的時代即將來臨？」，分別邀請法律與技術的專業人士，就司法院利用人工智慧輔助判決的議題進行討論。本次講座邀請到義謙法律事務所林俊宏律師、台師大圖資所曾元顯特聘教授與台大語言所謝書凱教授參與，分別對這個議題就法律與技術的不同層面與現場的參與者進行討論。

12月17日，寒流來襲的週日早上，民間司改會的活動場地還是有許多參與者出席本場活動，其中亦包含技術與法律的從業人員與相關專業者。講座由台灣科技媒體中心的陳璽尹執行長拉開序幕，陳璽尹博士分享了台灣科技媒體中心的工作，以及舉辦這場講座的初衷，希望大家對於技術與技術背後的議題能夠在共同的基礎上進行討論。接著便由 vTaiwan 社群參與者 Peter 分享 vTaiwan 目前的專案，以及之後會進行的與本場講座主題相關的意見徵集活動。

謝舒凱教授在引言中提到，新的技術進行會有倫理與道德的問題，於是希望讓大家進行討論。主持人隨後先問觀眾，是否有了解司法院應用人工智慧的新聞？有一位科技背景的參與者提到，人工智慧是具有不透明性與黑盒子的，但是司法的程序要具有一定的明確性，所以自己也只能盡量參與相關的討論。另一位觀眾則是提到，自己有利用 ChatGPT 等生成式人工智慧，節省了許多時間，但是對於司法上的應用，法官應該會在生成內容後進行檢查與更改。




