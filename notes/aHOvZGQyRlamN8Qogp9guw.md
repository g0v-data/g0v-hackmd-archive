---
tags: vTaiwan, openAI
---

# 9/24 vTaiwan-AI-人權 諮詢會議共筆

:::info
歡迎來到 vTaiwan-AI-人權 諮詢會議共筆 :mega:
點擊本頁上方的 

:::warning

| 時間 | 活動流程 |
| -------- | -------- |
| 14:00-14:15 | 開場、介紹 vTaiwan 與計畫、講解行政事項、合照 |
| 14:15-14:30 | 參與者自我介紹：我是XXX 我來自XXX 我希望AI XXX |
| 14:30-14:45 | 議題背景與意見徵集階段性報告 |
| 14:45-15:15 | 議題一：隱私與資料保護 
| 15:45-16:15 | 議題三：Governance 在地化 / 倫理規範 |
| 1620-16:30 | 主持人總結，最後意見補充 |

- 活動共筆： https://g0v.hackmd.io/aHOvZGQyRlamN8Qogp9guw
- 線上參與： https://meet.google.com/imy-mzzg-gck
- Polis 意見徵集： https://pol.is/4m6xdhddfz
- Slido 意見徵集：https://app.sli.do/event/dccAhNwEMkfqBgCBY4bCWY
- 活動公開簡報：https://docs.google.com/presentation/d/1Y4yYg76TW3SFkl4Z2bATy-yX-u5IyxmCRGM47Fb5A9Q/edit?usp=sharing
- 活動直播影片：https://www.youtube.com/watch?v=quOjUG6X8w4


:::info

:::

---

請於下方開始共筆：

## 議題一：隱私與資料保護
> 議題說明：
> 個性化的體驗與匿名化資料保護兩者的權衡標準？去識別化的程度與範圍？隱私遭侵犯的咎責？

> Po.lis 最沒有共識的點子
> 
> ![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_14ad48a1b12f51e23aee568eeda6abfa.png)

Sanya - 希望確認45公平性的定義。想要知道誰會去餵養這些資料，通常可以餵養資料都是比較有權力的人，而不是少數族群，所以想知道這個公平的定義是什麼。
Peter - 建議可以留到議題二。
Teemo - 是否可以取得投影片連結？
Peter - 現場更改畫面。
Teemo- 我在醫療領域，我有使用大語言魔性在上面。醫療領域如果希望有模型，就會使用到客戶資料，或者跟人有關係的病例。如何保障隱私權的情況下，使用這些資料，我覺得是蠻重要的。如果不能使用這些資料，對在醫療影域使用AI會有困難。
PBS- 我在智慧監控產業做過AI開發工程師。監控產業如何使用AI，其實是關關係到公開好還是隱私好。大家知道全台北市大小街道的影像都是公開的，在網路上都找得到，而且在台北市官網上有說會協助開發。但是走在路上都不知道自己被拍攝。全球的法律都保障可以用這些資料，但美國或歐盟的案例都主張只要有拿來開發，開發後不要可以直接搜尋到圖片，就是合法的，這是要保障技術開發的作法。原來對這些人技術開發優先於隱私權。所以需要更多人來做討論。我想要透過這個例子回應醫療產業，看技術開發的問題，給大家討論。
Nicole - 我在看這些議題，所以很多議題的層次要拉出來。因為把AI想像成工具，現在的目的是作為我們數位轉型2.0或3.0，讓很多應用成為可能，這樣真的會用到很多資料。但這些資料還是不會改變現有法制架構。有些資料是可以被應用的，有些是個資的。根本性的議題可能還要是去跟隨。請大家記得ChatGPT剛發布，有公司發現有資料被引用，但這個根本應該是資料治理的問題。是使用上根本不應該讓這些資料進到ChatGPT，這些應該要回到既有的問題。所以我們應該要釐清清楚。
Peter- Teemo是不使用資料是否很難進行，PBS則提到技術開發和隱私權的問題，Nicole提醒有些問題不是AI問題，而是別的問題所衍生的。
臺權會-很多問題有很多條件問題，讓我Polis無法選擇對或否。如果有些開發沒有講清楚應用範圍涉及開發，之後使用者要求撤回，但已經訓練下去，這時候要怎麼辦？
Peter-追加一個問題，如果他不是想要撤回，但是想要共享，取得利潤，那是否可行呢？
Ronny- 我們討論很多領域使用AI有什麼權利，例如撤回權。但我們是否有盤點過是哪些權利很難實現，例如撤回權，我們就應該注意。就是區分傳統上有哪些作法，是AI上不可行的。
國科會 - 想要附和上位朋友的說法。各國都有各自的個資法，但很多在現代是不合適的。在AI的世代下，知情同意已經不夠了，更重要的是怎麼使用和利用。例如我們從來不知道第三方是誰。第三方需被明確告知。傳統個資保護推播一些廣告或者朋友，可能他不需要你名字，但也很清楚你，所以隱私和個資保護的範圍應該不同。
貴智- 有看到點子中有提到著作權，覺得著作權討論和隱私討論應該要釐清。討論隱私應該先討論我們對於隱私的期待是什麼，然後再來討論AI，這樣可能會更切和。如果是醫院，就會附和Nicole的想法，應該醫院要有獨立AI，而不是用公開AI。
戴老師-我們現在的科技與時俱進發展，也挑戰很多新的概念，隱私權的概念是歐盟之前就在討論的。人有被遺忘的權利，但是德國有政治人物的妻子以前當過性工作者，所以搜尋他妻子的資料都會有提到他。
AI是否應該要開放程式碼。
Teemo-這些問題點子容易混淆，是因為我們沒有很清楚定義哪些資料可以餵，哪些資料不能餵，還有他取得資料後，可不可以這樣回答，沒有很明確的描述，也很難區分怎麼處理。有些東西可以讓模型學習，但如何讓他產出可以是另一個使用。這些題目沒有很好定義學習和使用。
洪申翰 -個資法修法討論很久，坦白說現在個資法很多問題，不細說。但是前一段時間大家想討論就是隱私到底是什麼。很多糾紛裡面，行政部門對於隱私的認定非常不同，這裡面的討論如果隱私或者保護是個概念，會不會AI的時代，不只物件什麼，沒被保護好要付出的代價是不同的。在AI的時代有些資訊沒有保護法要付出代價，這些想像和隱私的定義應該被處理的。很多民間團體想處理，但目前還無法。
義成：如果希望給大型AI開發者建議的話，將來要依靠法律程序去維護個人權利，可能很難做到，需要AI開發者自我管理。
Nicole：我覺得主辦單位這樣整理應該也有道理，雖然著作權和個資不相干，但是技術上有被操作的可能性。但重點是保護的法益、效果不同，所以可以放一起，還是要注意分開。如果根本的問題應該要先不討論，不然很難討論。同意義成，所有權現在可以在進行，那是因為開發者用了有著作權問題的事情再發生，所以才讓我們現在可以討論。我同意現在很難說事前去保護，應該要從風險去討論。
國科會-懷疑很難規範嗎？應該要公開哪些資料去喂？個資法和AI中的個資應該要分開。但每一個人個資定義不同，應該要區分公司和團體。
貴智-前端的資料怎麼公開應該是我們要做的事情。但是在使用ChatGPT的時候，當下是否可能也直接告知侵權的風險，減少瞟竊的可能。

## 議題二：歧視與偏見
> 議題說明：未來的AI開發需要怎麼樣的努力確保資料集的多樣性和公平性呢？著重在透明度和可解釋性會是移除歧視與偏見的最佳辦法嗎？哪些族群與情境？
> 
> po.lis 最沒有共識的點子
> 8. 是所有意見最分歧的
> 
> ![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_3f51756bad55c5ea78ed79ce989da20d.png)

柔伊：分歧的內容是什麼？
佑宇：這些議題好像比較偏向社會人士(?)，但以今年來說，例如原住民的歧視，也好發在校園與網路上。例如脫口秀演員，他們的網路聲量大，那這些訊息很容易讓別人認為是事實，這樣的歧視就會停不下來。
Ronny：AI一定要有警語，但是不應該避免回答歧視性問題。
冠汝：想講的和Ronny類似，現在我不太清楚Open AI如何去進行運算或訓練，在資料被訓練後也可能造成偏見與歧視。
柔伊：以議題工作者而言，沒辦法相信Chat GPT，因為它給的資料是錯的，那我會好奇何以更深入討論
阿甘：蒐集的意見是給高科技巨頭的時候，那我們又怎麼能夠從政府的角度去看說什麼部分是會被重視或被贊同的？或許可以保持文本的多元性。
貴智：我的想法跟前一位很類似。我也反對由高科技公司來判斷仇恨言論與歧視內容與刻板印象。如果讓Open AI來判定，反而具有風險。
什麼仇恨言論是立基於社會的通念，OpenAI沒有能力判斷，FB之前試圖這樣做，結果是做出不符合大眾想像的結果


戴瑜慧：現在許多公司都提出倫理規範，但實際有起什麼作用嗎？
文化產品很複雜，模型怎麼分辨政治諷刺與真正的仇恨言論
遵守當地的規範要非常小心，例如中國模式。
Nicole：問題的答案只有0和1就是巨大的災難，AI風險定性的描述，如果它原本就有歧視，那當然是需要被注意；但現在的問題是模型算法不透明，回過頭來看，應該要求的是可解釋性、公平性與可追溯性。那這些資料治理、資料來源都能夠更透明，降低社會影響。
模型與訓練需要公開，才能讓公民社會有充足的資訊來自己決定要怎麼運用這個模型，要調適、要反對，還是相信或不相信。

周弈成：全世界都變Chatgpt所驚訝，據說現在的OpenAI裡面自己的工程師都不一定知道為什麼模型會產生特定的內容，而作為預先訓練pre-trained的模型，大量的資料進來之後偏見的問題可能更嚴重。

未來可能不一定是預先訓練的模型，而且可能是分眾，

RR：資本企業不能做價值判斷，但政府也不一定可以。最後可能重點是用警語的內容，和哪些情況要加警語，可能需要有公眾討論的機制。

冠汝：要區分內容審查跟資料偏差的辨識，我們可能不樂見模型變得像是現在的社群媒體中的高密度審查。發現AI生成的內容可能不會是台灣習慣的語言、用詞。企業沒有責任進行道德判斷嗎？我們有類似人權宣言的東西，而且我們也要求企業要有社會責任。

Nicole：國科會有一個TAIDE

貴智：大數據讓AI模型會複製社會既有的偏見，當然科技可能放大它。但這似乎超出了這次會議可以討論的範圍。所以應該要回到政府，確認出哪些是該被處理的偏見問題，私人企業才有行動的依據





## 議題三：Governance 在地化 / 倫理規範
建立全國性的AI治理標準和倫理規範可以確保跨國性的一致性，但也需要處理不同文化、法律和價值觀之間的差異。審查體系的存在？入境隨俗該是哪個俗？

> po.lis 最沒有共識的點子
> 
> ![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_0883c89d7f1351b245c2ea66e48a59b0.png)



貴智：
從商業或是工具性的角度出發，在地化可能是關於在地使用者的需求能不能被滿足。例如找婚紗只出現西方白沙，可能只是他好不好用的問題，但也可以是在強化西方文化的主導地位，就會是人權問題。所以值得討論

peter：OpenAI認為在地化的資料取得上有困難。例如OpenAI希望做政治立場相關的資料，但大多是皮由等美國為主的公司。原因是在地的可信政治、民調資料難以取得。

阿甘：想要釐清倫理規範的定義，會被OpenAI做為未來的產品倫理規範嗎？對象是誰？

很多問題我覺得太複雜，沒辦法用二元的方式回答，所以拒絕回答。另外，要注重在地化與多元之間的平衡，在地化可能又變成同溫層。

Teemo：我在此呼籲OpenAI應該要開放仲裁權給使用者。希望是民主化且可以調整的。
內容仲裁的過程應該要是開放、民主的，因為標準、倫理觀點在不同的地方、不同時間而改變

RR：議題二和議題三其實在解決方案上會有點類似，所以應該要可以參考議題二的討論和解方。另外OpenAI這種大型的模型，可能可以透過自行選擇的方式，讓使用者自行選擇要不要在地化的內容，或是其他客製化的選項。


Peter：能不能邀請劉昌德老師與張正老師發表，讓我們聽聽科技媒體與新移民方面的觀點。

劉昌德：OpenAI的運作，可能不像是ptt能夠以草根性的方式來形成在地性的文化、版規、自主規範。

張正：「不要把新移民跟勞工連結」也是一種歧視？同意內容的產出可能是反映出社會的偏見。

洪申翰：我對於讓企業進行價值判斷很保留，可能會衍生其他風險，例如剛剛提到的meta。該怎麼理解AI，模型只是社會的投射、放大，還是未來會產生某種質變，我不知道，我希望技術工作者能夠解答。


戴瑜慧：我們可能要避免把新住民同質化，例如我之前跟遊民工作，有得人會想要強調自己跟別人一樣，但各個社群的內部差異是存在的。如果要在全球化中討論在地化與倫理，可能要會到普世人權的討論。

PBS：Chatgpt出來後，有些企業用版的chatgpt也有出來。而我看到相關的開發者時，我覺得他們對這些事情是蠻沒有sense的。所以看到現在大家的討論，跟目前的運作狀況有蠻大的gap，應該是未來要努力的方向


總結：

YY：我前段時間的業務上有準備一些資料，讓我很掙扎。認為讓模型的發展自我受限比較矛盾，期待AI能夠讓人的生產力有所提升。

Watkins：I worried about how small groups with lesser data can be presented properly.  And I wish AI technology can help me cross language and culture barriers in cross-culture communication.


智?：我們想要AI做什麼？任何新媒體出來的時候，都會有類似的討論我。我當然希望更多元，但作為市場，我們應該要干預的什麼程度

Sophie：chatGPT好像神隱少女的無臉男，丟什麼他就長成什麼，所以應該要探討平台的責任，例如平台應該要公開有機制讓公眾介入、干預。

Sanya：這場會議激發我們很多想法。

Wendy：我簡單分想個人想法，現在的大型語言模型都是用公開資料進行訓練。大家也開始期待生成出來的內容是不是符合大家的期待，我認為今天這種參與模式，應該被利用到其他的大型語言模型之中。尤其是，改變以資本主義或是以商業為主的開發方向。


匿名：這已經遠超過台灣新住民與其他弱勢族群的歧視，而是在國際現實環境下，在OpenAI中。台灣的聲音一樣被壓制，也許未來其他大平台的AI的機械學習內容與學習架構可能會不同。 想問在此狀況下，先別談我們台灣是不是需要審查~我們要如何脫離目前的困境，讓OpenAI能使用我們台灣文化界與新住民還有大多台灣人民所相信的數據?





---

![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_86bdd68dab8cfd16b3add02b60fb3302.jpg)

---

### 參與者自我介紹：我是XXX 我來自XXX 我希望AI XXX
* 我是Teemo 我來自醫療領域 我希望AI 幫助人們增加效率，減少疏漏。
* 我是Sanya Hung，我來自金融資訊業，同時是產業工會理事長，我希望AI讓人增加工作效率有了空白的時間後，能盡情發揮創意讓工作與生活更美好，透過AI讓人更像人。
* 我是RR，我來自g0v社群和數位發展部，我希望AI幫助政府更有創意。
* 我是YY，我來自數位發展部，我希望AI可以幫助更有效率的生產。