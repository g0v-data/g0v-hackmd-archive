---
tags: vtaiwan
---
# 3/31 監察院國家人權委員會分眾座談
- g0v 揪松團於 3/21 收到通知，邀請揪松團參與監察院國家人權委員會「探討及研究人工智慧對人權之影響」分眾座談NGO場次
    - 四個場次
    - NGO 場次
- vTaiwan 專案於 2024 年 12 月 20 日舉行議題小聚，產出[紀錄報告](https://docs.google.com/document/d/1kYIYbHdTctGBXrV-U3qivkzByV-uAxOAiS7fB_sGacU/edit?usp=sharing) 
    - 預計以此作為發言內容


## 討論
探討人工智慧對人權影響座談

討論題綱

參與者：
台灣人權促進會 周冠汝
司改會數位法小組 RS 
國際特赦組織 劉李俊達
台灣事實查核中心 
台灣展翅協會 
開放文化基金會 林韋丞
vTaiwan Peter 

(一) 【利害關係人合作】針對生成式 AI 工具的發展所可能導致的人權危害，是否有進行相關倡議？是否與民間企業合作，於相關產品設計、開發時，表達意見？

台權會：發表人工智慧造成的人權危害，著眼點不單單是生成式人工智慧
- 政府開發與應用的資料往往是採購案，等到開發到一定程度後，才發新聞稿（e.g. 司法院的判決自動化）政府應該要更積極盤點，而非僅推動使用。
- 間接案例：衛福部與 google 合作的計畫，疑慮在於資料如何取得，以及是否取得同意。
- 如何在減輕公務人員的負擔與減少失誤間產生平衡？
- 個資保護委員會：
    - 定為三級機關，是否足夠？因為同時要監督私部門與公部門，新興技術涉及到個資利用
    - 
開放文化基金會：
- 開發者與使用者兩個方向理解。
- 如何取得更多繁體中文的資料，開發更好的 ai 
- 資料上。除了開放授權的資料與自行購買的資料外
- 案例：粵語的ai 發展
- 不屬於開放資料的脈絡下的資料：資料的授權蠻看情境
- 建議回到資料治理的生命週期來思考：持有者與開放的情境都會不一樣
- 不應該理解成單一面向
- 橫向連結：治理委員會 end user 有席次
台灣事實查核中心：
- 科技平台會迴避實質的問題
- 科技平台也會捐助事實查核與推廣 e.g. google.org 的媒體素養教育
- media literacy 到 ai literacy 
國際特赦組織：
- 2023 美國分會與商業與人權資源中心有提出科技巨頭其實沒有對於人權進行相關承諾。僅有一間願意投入相關dd 
- 台灣沒有相關法規與要求。（ungp 有）
- ai 會對相對不利處境的群體產生影響，避免產生錯誤偏見。
- 世界經濟論壇將人工智慧製造的不實訊息當作是短期風險。
- 丹麥：程式如何產生歧視（對於社會福利）
- Dd 本來就是內部的監督機制
- 不同的利害關係人如何進行評估，會很麻煩
- 作用法與基本法的規劃與時程，以及數發部與通傳會的職能
台灣展翅協會：
- 兒童與青少年是很大的使用者，而且往往從很早期就開始使用。
- Safety by design 很重要的概念
- 倡議重點放在使用倫理的概念
- 兒童與青少年能夠被收集的是非常有限的
- 多層面，難以一一盤點
司改會：
- 之前人工智慧基本法就有相關聲明：建議從權利保障出發，而非技術發展。
- 行政機關與民間機構：對人民產生的權利衝擊其實是來自於統計或抽樣的偏誤。
- 針對去識別化：科技發展下仍有再識別的可行性。
- 去識別化不代表免除個資法相關義務
vTaiwan: 
- 與 openai 合作
- 副作用：企業缺乏誘因，權力不對等

人權會 筱涵：
- 政府應該要公告
- 知情同意可以如何執行？公開的資訊要如何取得？
- 教育開發商的使用倫理？
- 外部監督與內部審核的機制？
- Ai  基本權：

人權會 秀蘭：
- 查核以外，可以做些什麼？
人權會 周杰：
- 個資保護修法的意見
監察委員 鴻義章：
- 原住民血清研究
- 大型語言模型

(二) 【隱私權侵害、偏見與歧視、假訊息風險】是否因為生成式 AI科技而發生隱私權受侵害、或遭歧視案例？是否觀察到錯誤或虛假訊息、深偽技術造成的危害？可否概述相關情形？

台灣事實查核中心
- 已經從風險轉成具體危害
- 選舉期間經常出現
- ai 發展的這些疑慮已經越來越好了 e.g. 吉卜力風潮的圖源已經越來越多樣化
- ai 越來越好，對於事實查核也帶來越多挑戰
- 詐騙也受到影響
台灣展翅協會
- 成人內容：容易出現相關內容，開發良莠不齊，對於兒童與青少年產生不利影響。
- deepfake 被用於教學，引發學習興趣的同時，讓學生也學習到技術。
- 資料來源的教育很重要
- 教育領域的人對於科技可能沒有這麼熟稔
司改會：
- 國內有很多廠商在使用人工智慧：公關公司對網路留言的處理。
- Ai 軍備競賽：科技公司不一定能夠掌握風險，例如思考鏈

(三) 【公民參與】臺灣目前已制定《人工智慧基本法》草案，該草案具宣示效果，規範人工智慧之研發與應用應遵循的七大原則，及政府應推動風險分級規範、建立負責機制、保障勞工權益與個資隱私、使用人工智慧之風險評估等。於法案制定過程中，是否有進行相關倡議？相關內容為何？

VTaiwan: 
- 利用 read the room 的方式進行討論

(四) 【強化科技素養】一般民眾科技素養會影響對人工智慧的應用與了解，進而維護自身資料隱私、分辨虛假資訊，並了解 AI 演算法可能造成的影響。對於強化社會大眾的科技素養，可否分享訓練實例？政府可朝哪些面向努力？
-  歐洲理事會框架公約
台灣事實查核中心
- 社群平台對事實查核的努力是完全不夠的
- 數位落差會因為 ai 而擴大
- 付費使用與沒有付費使用帶來的落差是巨大的。
    - 資源在使用者面向的顯現
- 一部份的資源拿來訂閱 ai 的使用工具
- 偏鄉學校收到的是過期的東西
台灣展翅協會：
- 透明度的提升，會帶來信任
- 在素養之前，還有治理
- 政府落實治理
- 對風險的評估要很全面
- 政策發展與白皮書
vTaiwan
- 審議與討論
- ai 共學團：種子教師的訓練

司改會
- 政策上如何去建立素養
- 有很多人把人工智慧視為一個可靠的知識來源
    - 我聽那個人說的
    - 我看那本書說的
    - 我看那個報紙說的
    - 我看那個電視節目說的
    - 我看那個臉書上的網紅說的
    - 我看那個抖音說的
    - 我問 chatgpt 的
展翅協會：
- 盤點相關的風險

(五) 【環境權】在生成式 AI 蓬勃發展的時代下，算力即國力，但增加算力的背後，是用電量與碳排放大幅增加，據 2019 年馬薩諸塞大學阿默斯特分校研究人員估計，訓練大型語言模型(LLMs)的碳足跡，相當於約 30 萬公斤(300 噸)二氧化碳排放當量，相當於普通汽車生命週期排放量或 125 次紐約與北京之間往返飛行 ；另外，全球資料中心數量從 2012 年的 50 萬個增加至 800 多萬個，能源消耗量每 4 年翻 1 倍 ，資料中心運作過程中所需水冷散熱亦會消耗大量水資源，相關 AI 基礎建設耗費水量很快就會比擁有600 萬人口的丹麥用水量多了6 倍。面對人工智慧造成的環境風險，企業應採取哪些因應措施減輕對環境的衝擊？

台灣事實查核中心：
- 算力內容
司改會
- 政策上往往會因為追求創新，而帶來資源的浪費
國際特赦組織
- 數據需要更新，不過可以看出ai 對於環境衝擊的嚴重性
- 柏克萊大學法學院的人權研究中心

人權會 林文程 
- 針對大型科技公司採取的行動？

開放文化基金會
- 購買平台無法因應使用者轉移產生的問題
- 網路治理與內容平台的治理
- buttom up 創造治理原則
- 法律先行的話往往會有負面的效果
國際特赦組織
- 這是另外一個題目
- 技術性很高，需要降低討論門檻
台權會
- 詐騙有關的內容

人權會 葉宜津
- 目前人類對於人工智慧的追求已經失控了
- 碳費
- 全球的政府都很棘手

國際特赦組織
- 拜訪政委，有提出相關意見
    - 國際人權標準
    - 禁止違反人權標準的人工智慧技術
    - 豁免
    - 風險評估
    - 生命週期

## todo list
- 詢問承辦人員的內部團隊意見如何
- 索取照片
- 