---
tags: vTaiwan, openAI
---

# 9/24 逐字稿整理

:::info

- [9/24 實體諮詢會議共筆](/aHOvZGQyRlamN8Qogp9guw)
- [活動直播影片](https://www.youtube.com/watch?v=quOjUG6X8w4)

:::

:::info
發言者名字整理：
Peter
Erica
RR
周奕成
Nicole
洪申翰
貴智
Teemo
Ronny
YY
PBS
Vanessa
PC
洪滿枝
慧穎
柔依
林佑宇
Mariko
阿甘
Sophie
戴瑜慧
Sanya
政翔
杜瑛秋
Wendy
冠汝
劉昌德
張正
智原 (不確定)
unnamed Japanese participant1
unnamed Japanese participant2
:::



[07:21 - 07:44] 

**Peter:**
我們等一下會利用一些線上的工具 幫助大家除了現場的討論以外 也可以在線上進行互動 同時我們線上也陸續有朋友加入 包含來自司改會的鄭翔 還有Sanya還有Wendy都在線上 我們如果要使用網路的話Wi-Fi的話可以使用Meeting Guest 我們等一下會利用一些線上的工具 幫助大家除了現場的討論以外 也可以在線上進行互動 同時我們線上也陸續有朋友加入 包含來自司改會的鄭翔 還有Sanya還有Wendy都在線上 我們如果要使用網路的話Wi-Fi的話可以使用Meeting Guest

[07:44 - 08:06] 

**Peter:**
這個Wi-Fi的Meeting Guest 我們會使用Sli.do來收集大家的問答 因為等一下問答的時間 等一下現場的話 每個人的發言時間 為了要顧及每位參與者的發言權利 可能會受到限制 所以如果你有任何問題 或者是回答還來不及完整的表達的話也都歡迎利用Sli.do的方式 

[08:06 - 08:29] 

**Peter:**
我們都會在上面收集 並且所有的討論跟所有的紀錄 都會被archive 也會被呈現在我們的報告當中 然後同時上面投影的大的QR Code 是Sli.do的QR Code 可以直接掃描 小的QR Code是VTaiwan後續參與的QR Code 如果有想要後續參與VTaiwan的話 也都可以掃描上面的QR Code 然後小的後續參與vTaiwan的QR Code跟海報上的QR Code是相同的

[08:29 - 08:53] 

**Peter:**
歡迎大家 好,那我們事不宜遲 因為現在時間也差不多了 我們活動正式開始 大家好,歡迎來到VTaiwan人權的諮詢會議 我是主持人Peter 另外一位主持人是Erica Erica要不要自我介紹

**Erica:**
大家好,我是另外一個主持人 
[08:53 - 09:15] 

**Erica:**
我叫Erica 嗨,大家好 

**Peter:**
我們是今天活動的兩位 就是負責導引 負責帶領大家來做今天諮詢會議的主持人 那今天的流程 大概會是像投影片上所顯示的這個樣子 我們目前的時程 應該是有稍微往後延五分鐘的那目前的話 

[09:15 - 09:39] 

**Peter:**
如果按照既定的流程的話 會是先由我來做開場的計畫介紹 還有相關的 什麼是vTaiwan 這個vTaiwan程序是什麼的一個介紹 然後接下來會有15分鐘的時間 讓在場跟線上的參與者 做一個自我介紹 然後等一下自我介紹是有固定的格式的 所以大家可能要遵循那個格式 避免影響到其他的人發言時間然後再來是會有15分鐘的背景報告

[09:39 - 10:02] 

**Peter:**
包含針對整個人工智慧 還有倫理規範的議題背景 以及我們目前透過意見徵集的時候 所徵集到的意見背景來作為報告 緊接著我們就會針對議題一 議題二跟議題三 分別來進行討論 最後會有一個主持人的總結 還有最後一輪的意見的徵集跟發表 所以如果大家有任何 剛剛在議題一議題二議題三 還沒有來得及說或者是還沒有辦法說的意見 
[10:02 - 10:25] 

**Peter:**
都可以在最後的階段再做補充 或者是可以善用我們線上的 不管是共筆的連結 已經放在Mail裡面 如果有興趣的話 可以直接到Mail裡面去 寄給你大家的郵件裡面 有都有 或者是可以到那個Slido上面 去發表你的提問 或發表你的討論跟意見 那同時線上的觀眾我們也同時在臉書跟那個YouTube上 

[10:25 - 10:47] 

**Peter:**
有直播 所以直播的觀眾其實 我們在現場也都安排議程助理 協助我們就是將相關的意見 放到聊天室上 所以歡迎大家 用各式各樣的方式來表達意見 好那事不宜遲 就先由我來 喔喔海報掉下來了 那事不宜遲就先由我來 做開場跟計畫的介紹 好那首先先有一個 就是這邊的開場跟計畫介紹大概分成三個部分 

[10:47 - 11:09] 

**Peter:**
首先是要跟大家介紹說 什麼是vTaiwan 然後再來是 什麼是Bridge in the Recursive Public 這也是為什麼我們今天會在這邊 然後會有辦法來辦這個諮詢會議的原因 最後我們想要跟大家介紹的 就是我們的vTaiwan 是怎麼樣去進行整個流程的 首先什麼是vTaiwan 大家可能很好奇說vTaiwan的緣起 就是vTaiwan這個程序到底是什麼但其實它的緣起一點都 

[11:10 - 11:32] 

**Peter:**
就是大家應該都滿 就是大家應該都滿熟悉的 其實就是在2014年 太陽花學運的時候 太陽花學運改變了 整個台灣的社會運動的 就是歷史 然後同時它也激發了 很多的公民科技 跟公民的相關的能量 那太陽花學運的造成的緣起 對於民眾來說是 整個社會開始脈動 開始改變 但對於政府來說他們發現 
[11:32 - 11:55] 

**Peter:**
其實傳統的意見徵集的過程 好像不太夠 也因此當時的政務委員蔡玉玲 就來到了g0v時政府 這樣子的一個公民科技社群提案 希望去建立一個新的 數位法規的調適平台 而這個調適平台 就正是vTaiwan的誕生 那vTaiwan跟以往的 法規的制定政策的過程 有什麼樣不同的地方呢首先vTaiwan的以前的 

[11:55 - 12:18] 

**Peter:**
在vTaiwan出現以前的法規制定 往往是由專家所引導的 包含說可能會有一些學者參與 但是這些學者可能 基本上來講 如果你是比較持反對意見的 可能就不太容易會找進去 政府擔任專案制定者 那同時也會有企業遊說的影響 最後最重要的事情是 整個討論的過程 是相當的不透明的一個狀態 相關的會議紀錄即使有公開也都是相當不完整的狀態 

[12:18 - 12:41] 


**Peter:**
而vTaiwan呢 我們希望打造一個 第一個是社群導向的一個平台 希望是由社群來擔任 整個法案制定 然後整個法案 連結不同利害關係人的角色 同時我們也在 整個制定的流程當中 不管是我們一開始所做的 用Polis做的意見徵集 還是我們現在在進行的 所謂的諮詢會議其實都會透過網路直播 

[12:41 - 13:03] 

**Peter:**
或網路共筆的方式 讓整個意見的徵集過程 還有意見的連結跟討論的過程 是公開透明的 好 所以這個大概就是 整個vTaiwan的流程 也就是利害關係人會帶著 他們的問題 來到了vTaiwan的流程裡面 他們會被初步的形塑成意見 然後意見呢 會在 意見會在社群當中的討論 去進行收斂同時我們也會對外進行意見徵集 

[13:03 - 13:25] 

**Peter:**
這些討論跟徵集的過程 會不斷的收斂 然後呢 第四重複 然後到最後呢 就會形成一個可以回應 當初意見的草案 最後這個草案呢 就會變成法規的一部分 那其實參加vTaiwan 還有另外一個特色是 其實以往的 以往的社群運動 或者是所謂的組織 其實都會需要大家扮演一個特定的角色 

[13:25 - 13:47] 

**Peter:**
然後付出非常多的心力 但是在vTaiwan裡面呢 我們其實有分級 譬如說像坑主 像是 重度的參與者 中度的參與者 輕度的參與者 甚至是奈米級的參與者 其實都可以在整個過程當中 盡到一份心力 所以不用擔心說 自己時間不夠 就沒有辦法來參加 這整個流程 而是說 大家其實每一個人 他在不同的時間點都可以扮演不同的角色

[13:47 - 14:09] 

**Peter:**
每一個人都可以在vTaiwan的 整個流程裡面 扮演重要的角色 這個是我們vTaiwan希望透過社群的 整個參與 來達到的事情 好 那再來接下來就要介紹的是 什麼是 Bridging the Recursive Public 好 那Bridging the Recursive Public呢 其實是源自於 OpenAI於今年 推出的一個計畫 叫做Democratic Input to AI 我們都知道 其實在OpenAI推出了所謂的

[14:09 - 14:32] 

**Peter:**
Chat GPT 還有像DAll-E DAll-E 1 DAll-E 2 DAll-E 3 現在DAll-E 3 這些工具之後呢 其實AI的 生成式AI的衝擊跟浪潮 都開始影響了 整個 影響了 不管是影響了商業模式的運作 還是影響了 整個社會的規範 甚至是對於 整個社會跟法規 都造成衝擊 那也因此 OpenAI有意識到這一點 於是他們 推出了這個Democratic Input to AI 

[14:32 - 14:54] 

**Peter:**
他們希望從全球 找到十組不同的團隊 希望能夠透過科技 或者是社群的力量 然後找到一個 能夠幫助AI 變得更加民主化的方法 那很高興的是vTaiwan跟英國的一個 著名的智庫 叫做Chatham House 我們合作去 投稿了這個計畫 並且成功地 從八百個團隊當中 脫穎而出成為最後

[14:54 - 15:17] 

**Peter:**
十個入選的團隊之一 那這也是一個 很重要的創舉 因為我們是 唯一一隊 有台灣人參與的團隊 我們是唯一一隊 有台灣人參與的團隊 所以 可以說 這樣的一個專案呢 是一個 我們能夠把我們的意見 包含在座的大家 今天所發表 所討論的東西 全部都會放在 我們的報告裡面 並且這些報告是能夠被OpenAI的 

[15:17 - 15:40] 

**Peter:**
不管是他們的 開發團隊 甚至是他們公司的 內部的PR團隊 乃至於就是 公司的管理層所看到的 好 那我們 想要達到的目標就是 希望透過vTaiwan的 這個流程 讓人工智慧的 開發跟部署 能夠納入 更多更多人的意見 納入更多 不同利害關係人的意見然後這個同時 

[15:40 - 16:04] 

**Peter:**
其實也是美國 NIST 美國的國家標準 與技術研究院 他們所提出來的 就是 他們之前有發佈了一個 人工智慧的風險管理的 一個相關的框架 那在這個人工智慧風險管理 相關框架當中 他提出了風險管理的 四大要素 其中一個最重要的 治理端的部分 就是要先去設定 人工智慧在開發的時候 要如何避免風險的一些方向而在這個治理端當中

[16:04 - 16:26]

**Peter:**
最重要最重要的就是 我們要納入 多元利害關係人的意見 讓不只是技術背景的人 可以讓更多 不同的社會背景的人 有既有的domain knowledge 有既有的知識的人 可以加入到這個過程當中 參與這樣子過程的運作 好 那接下來就會面臨到 一些可能的質疑 包含說 OpenAI這家公司 為什麼要做這樣的事情 他們是不是在做某一種的所謂的 

[16:26 - 16:49] 

**Peter:**
open washing 我們常常聽過 所謂的green washing 就是洗濾 漂濾 這樣子的一個行為 他們是不是在 透過這樣子的一個計畫 來達到某一種門面 或作秀的一個效果呢 確實 這樣子的批評是存在著的 而且是我們在團 我們在整個計畫運作 包含是像我們vTaiwan 台灣端的vTaiwan 或者是英國端的Chairman House 一直在努力避免的一個目標

[16:49 - 17:11] 

**Peter:**
我們要如何避免呢 第一個 我們希望盡可能的 讓OpenAI參與後續的討論 也因此 我們在今天的會議 其實是有邀請 OpenAI的代表出席的 只是我們沒有辦法 邀請到他們 但 不過他們是有參與 英國端的圓桌會議 round table的會議的 所以我們是盡可能的 希望讓OpenAI 可以參與後續的討論 同時也可以讓相關的資料我們把相關的資料公開 

[17:11 - 17:35] 

**Peter:**
讓後續的研究者 在研究這些法規制定的過程 或AI倫理規範制定的過程的時候 可以當作參考 那這樣子的話 我們希望就可以 降低這樣子 open washing 或降低這樣子 作秀的一個質疑 那同時我們社群 會持續的在進行相關的討論 好 那接下來的話 我們要討論的就是 如何vTaiwan如何vTaiwan 

[17:35 - 17:59] 

**Peter:**
大家看現在的投影片可以發現 它其實有分成五個不同的階段 第一個是要如何去設定核心議題 第二個是意見徵集 第三個是現在大家所在的諮詢會議 第四個是資料的整理跟彙整 然後第五個是報告 好 首先第一個 設定核心議題的部分 當時我們在爭取這樣子的一個 就是OpenAI給予的這個OpenAI的Democratic Input to AI Grant的時候

[17:59 - 18:22] 

**Peter:**
它其實是有讓我們選擇題目的 那我們所選擇的大主題就是這個 如果人工智慧要同時處理 具有人權或當地法律及文化差異的議題 例如LGBTQ或女性議題的時候 那人工智慧在處理相關的議題 應該要遵循何種的原則 人工智慧應該基於使用時的文化 以及地區差異 來改變他們的回應嗎這個是我們所選擇的討論的議題 

[18:22 - 18:44] 

**Peter:**
也因此我們要從這個議題去發想 想出說 如何讓後續的討論能夠進行 但大家其實可以發現一件事情 就是這個議題最大的問題就是 它是一個非常抽象的議題 它的討論的層面非常廣 而且它沒有太多具體的案例 也因此如果我們要繼續後續的討論的話 勢必要讓整個討論變得更加的具體才行那要如何讓討論變得更加的具體呢 

[18:45 - 19:07] 

**Peter:**
我們就要透過這樣的方式 來讓討論變得更加的具體 包含說我們在每一週三晚上的 離台灣小聚的時候 都會彙整相關的意見 同時我們也有邀請 不管是中研院的李梅君研究員 或者是其他的一些來自社會科學 來自法律相關背景的老師去進行訪談同時我們也跟不同的背景的參與者聊天 

[19:07 - 19:29] 

**Peter:**
然後來蒐集相關的資料 最後我們彙整出了一份 大家可能在事前的時候都有收到的一份 就是你在事前參與活動之前 可以收到的一份學習資料的內容 那這些學習資料的內容 正是我們透過這樣的方式來聊天 並且最後設定出的一個討論框架 那接下來有了討論框架之後 我們就可以開始來做意見徵集了那我們的意見徵集

[19:29 - 19:52] 

**Peter:**
我們希望達到的目標是 我們希望能夠在框架跟開放間達成一個平衡 也因此我們丟了30則不同的種子意見 放到POLIS之上 並且讓大家去做這個POLIS的意見徵集 而很高興的是 我們在最後的結果 我們發現有188個人 願意參與POLIS的這個意見徵集同時大家針對他們的意見 

[19:52 - 20:15] 

**Peter:**
提出了4000多則 超過4500則的投票 並且原先的30則種子意見 也有45則新增的意見被提出來了 這件事情讓我們感到非常的開心 也證明了我們的討論 確實是有幫助到 幫助大家建立一個 對於人工智慧倫理規範的初步框架之外 也有達到一個開放大家提供自己意見 跟提供自己看法的一個目的那接下來最後就是諮詢會議的部分 

[20:15 - 20:38] 

**Peter:**
也是大家所在的這個地方 我們後來在整理整個POLIS的議題之後 發現大家所提出來的意見 包含種子意見在內 比較多是集中在三個部分 第一個是資料與隱私保護 第二個是人工智慧可能帶來的歧視與偏見 第三個是在地化的部分 那也因此我們便是以這三個 來做為等一下的框架討論最後我們也邀請到了 

[20:38 - 21:02] 

**Peter:**
很多目前在座的各自各樣 來自各種不同領域的厲害關係人 在這邊先非常感謝大家 願意參與今天的諮詢會議 那我們原本vTaiwan的設計 是會有一個回應者的 不過這個部分呢 是我們仍然在調整 一些探索當中的部分 就是未來我們是不是要讓 OpenAI或其他的開發人工智慧的公司 擔任這樣子回應者的角色那我們會在之後的程序當中 

[21:02 - 21:24] 

**Peter:**
去努力實踐 好 那接下來就會是資料的整理 彙整以及最後的報告 我們將在10月20號的時候 針對vTaiwan的這整個程序跟經驗 向OpenAI提出一個報告 同時我們也會將在下禮拜 出發前往舊金山 去OpenAI的總部進行參訪 並且跟OpenAI的團隊進行聊天 好 我們希望能夠把台灣的聲音 帶進Chat GPT這個是我們今天 

[21:24 - 21:46] 

**Peter:**
大家群聚在這邊 大家參與這個諮詢會議 最重要 最重要的目的 好 感謝大家 那接下來的話 我們要宣布一些行政事項 包含說 等等討論呢 第一個 請不要使用冒犯性的言詞 第二個 請尊重與你不同意見的人 第三個 請注意發言的時間 我們都有派人在那邊計時啦 但不會用那個尖叫機或其他的方式打斷 

[21:46 - 22:10] 

**Peter:**
但是我們主持人會善意的提醒您 要稍微的做一個總結 那如果您有不夠的話 請利用剛剛提到的 不管是共筆的連結 或是slido的連結去進行發言 那一些行政事項 包含飲水機跟洗手間 請在二樓跟一樓做使用 那場地內是禁止飲食的 那如果有任何問題 其實都可以詢問在場 貼有這個樣子姓名標籤的工作人員好 那接下來就會進到 

[22:10 - 22:33] 

**Peter:**
我們的自我介紹時間 好 那自我介紹時間 因為現場參與者其實滿多的 那為了不浪費大家的時間 我們希望可以讓大家 依循這樣子的一個格式 來做自我介紹 那等一下的話 是由主持人來做一個示範 請大家依循這樣子的格式 來自我介紹 第一個是我是誰誰誰 第二個是我來自哪裡 然後第三個是我希望AI可以做什麼事情 

[22:34 - 22:56] 

**Peter:**
好 那如果以主持人的範例來說的話 我就先以我來做範例 我是崔家瑋 這是我的中文本名 那我來自G0V臨時政府的社群 我希望AI的發展 可以有更多人的意見加入 好 那事不宜遲 我們現在就讓現場的 現場的主持人 第二個主持人來做自我介紹 依照這個格式試試看嗨 Erica

[22:56 - 23:22] 

**Erica:**
好 謝謝Peter 然後我是Erica 我來自設計師的社群 然後我希望AI的發展 可以讓更多人可以參與 讓不管是什麼樣的種族性別 什麼類型的人都可以參與 好 那我們接下來要讓 從左邊還是右邊 第一排開始吧 就是RR

**RR:**
大家好 我是RR

[23:22 - 23:47] 

**RR:**
那我來自G0V社群 然後同時就是 現在也在數位發展部任職 那我希望就是AI的發展 可以就是 可以就是給政府部門 多一點不同的創新跟創意 

**周奕成:**
大家好 我是周益誠 我來自創業家還有野百合世代的社群 

[23:47 - 24:09] 

**周奕成:**
這樣講好了 我希望AI能夠促進社會的平等 還有民主的發展 換Nicole 

**Nicole:**
大家好 我是詹婷怡 Nicole 我來自 要怎麼歸屬 好 我是詹律師那我希望AI可以讓

[24:09 - 24:33] 

**Nicole:**
可以為大家創造更好的生活 然後可以讓更多人的意見 都能夠更自由更充分的表達 

**洪申翰:**
大家好 我是洪申翰 我現在來自立法院 現在在立法院工作然後我希望AI可以更溫柔

[24:37 - 24:59] 

**貴智:**
大家好 我是貴智 那我來自法律白話運動 那我希望AI 希望更好用吧 但我覺得這個好用 就是大家都不會覺得被冒犯的意思 

**Teemo:**
我是Timo 我來自醫療領域 我希望AI可以幫助人們增加效率減少疏漏

[25:00 - 25:24] 

**Ronny:**

我是Ronnie 我來自g0v社群 我希望AI不要擴大貧富差距 資源落差的問題 然後也希望AI不要促成 網路上越來越多虛假言論的問題 

**YY:**
大家好 我是YY 我來自於數位發展部 那我希望AI的發展是提供台灣各方面的一個生產效率提升

[25:25 - 25:47] 

**YY:**
生產效率的提升 那比如降低台灣整個高齡化之後 產生的一些生產力不足的衝擊 

**PBS:**
我是PBS 我的背景是 我是PBS 潘碧璇 那我的背景是國立陽明交通大學人文社會學系

[25:47 - 26:11] 

**PBS:**
現在在華碩AIOT部門 擔任產品經理 那我希望AI技術的發展 可以結合人文社會的考量 

**Vanessa:**
大家好 我叫Vanessa 我來自盧廷福大學的學術研究院 主要是為了學習 如何與人們一起參與這個非常重要的課題 

[26:11 - 26:36] 

**Vanessa:**
我的願望是 AI能夠擴大語言差距 讓我能夠直接與你們溝通 我強迫那兩個人 跟我一起翻譯 我保證他們 不需要自我介紹 因為他們只是因為我而在這裡

**PC:**
大家好 我是PC

[26:36 - 27:01] 

**PC:**
那我是學校老師 也是台師大教育心理學的研究生 那我希望AI可以照顧到所有人 那也為教育帶來新的思維模式 謝謝 

**洪滿枝:**
大家好我是南洋台灣姊妹會的理事長 

[27:01 - 27:24] 

**洪滿枝:**
我是洪滿枝 我希望AI不要成為詐騙流傳的平台 

**慧穎:**
大家好 我是南洋台灣姊妹會的慧穎 我希望AI不要只是被最後發展AI的發展不要被少數有權有勢的人掌握 
[27:25 - 27:48] 

**柔依:**
大家好 我是同志諮詢熱線的柔依 我希望AI的發展是 可以提供我們更多幫助 去服務有需要的同志族群還有同志父母 

**林佑宇:**
大家好 我是原住民族學生聯盟的召集人 我叫林佑宇我希望AI能夠增加大家的文化敏感度 

[27:48 - 28:12] 

**林佑宇:**
並且對於歧視的議題是能夠有所反思的 

**Mariko:**
嗨 我是Mariko 我來自東京和日本 抱歉 我不能說台灣語 今天只有英文

**阿甘:**
嗨 大家好 我是甘榛榕 可叫我阿甘 

[28:12 - 28:41] 


**阿甘:**
我來自國科會科技民主與社會研究中心 DSET 我是裡面的研究員 專長是AI倫理議題 我希望AI發展可以公共化與強化民主韌性 不是只有技術跟有資本的才能享受AI帶來的好處 或者總是讓沒有社經地位 沒有資本 沒有技術的人先承受惡果 謝謝

**Japanese Participant1:**
嗨 大家好 我叫?

[28:41 - 29:05] 

**Japanese Participant1:**
我來自日本 我對vTaiwan與government activity的活動有興趣 所以我參與了這個活動 

**Sophie:**
大家好 我是Sophie 我來自於科技產業我希望AI的發展可以讓我們的生活更好更便利 

[29:05 - 29:28] 


**戴瑜慧:**
謝謝 大家好 我是Lesley 黛玉惠 目前在陽明交通大學任教 也有參與性別和無家可歸的組織 我希望AI可以不損害以及我們應該在聯合國保障的文化公民權和數位權 

[29:28 - 29:51] 

**戴瑜慧:**
在這個前提之下 保障我們的權益 可能包含弱勢 特別關心的是弱勢群體的權益 還有地緣政治可能帶來的影響 

**Peter:**
還有其他現場參與者嗎 如果沒有的話我們會開放讓線上的參與者進行自我介紹 

[29:51 - 30:14] 

**Peter:**
目前線上的話 我們看到了四位不同的參與者 應該是三位不同的參與者 那不曉得是否方便讓正翔先開始呢 正翔 好像有聽到我的聲音 有echo 還OK嗎請等我一下 
[30:16 - 30:38] 

**Peter:**
好沒關係慢慢來 那在這段時間要不要先讓Sanya Sanya不好意思 你在線上可以自我介紹一下嗎 

**Sanya:**
好的 那現場的朋友們大家好 我是Sanya 那我是來自中國信託資訊管理處 同時我也是電子工會的理事長那我們是希望是能夠透AI 

[30:38 - 31:00] 

**Sanya:**
讓我們人們增加工作效率 那有了空白的時間 可以發揮更多的創意 讓工作與生活更美好 透過AI讓人更像人 謝謝 

**Peter:**
好謝謝Sanya 那正翔OK了嗎 

**政翔:**
這樣應該可以了大家好我是司改會的政翔 

[31:00 - 31:23] 

**政翔:**
那我希望之後AI可以 促進我們國家司法的進步 但不要有再有更多的歧視跟不平等 謝謝大家 好非常感謝政翔 

**Peter:**
現場好像還有 瑛秋杜瑛秋小姐 不好意思可以方便請你自我介紹嗎 格式是我是誰誰誰我來自哪裡哪裡哪裡 

[31:23 - 31:48] 

**Peter:**
我希望AI可以怎麼樣 

**杜瑛秋:**
嗨 各位好我是婦女資源基金會 對 然後不好意思因為有點晚加入 那我希望AI可以創造更多的 一些生活便利以外還有另外一部分是可以保障更多的 

[31:48 - 32:15] 

**杜瑛秋:**
這些權益 尤其在免於被歧視跟免於被攻擊 還有一些侵害到人權的一些事件的一些產生 好了謝謝 

**Peter:**
謝謝 好謝謝英秋 那英秋之後我們還有一位線上的參與者是Wendy Wendy在嗎有的非常清楚 

[32:17 - 32:41] 

**Wendy:**
好 我是 我是在數位發展部 我的AI是可以協助 協助人們達成更好的社會 而不是透而不是因為一個新興技術的發展 而令人們對於未來的 謝謝 謝謝 謝謝

**Peter:**
好謝謝Wendy 

[32:41 - 33:04] 

**Peter:**
線上應該沒有 OK 好那我們自我介紹環節到這邊告一段落 那接下來就會是一個合照的時間 那合照時間就交給攝影師 來幫我們安排一個現場的合照沒關係

[33:04 - 33:27] 

**Peter:**
我們時間有預留一些 不用擔心慢慢來 對 那 好的 那麻煩兩邊的 如果不介意的話 可不可以做的集中一點呢 目前中間的部分應該還有一些空位 可以在合照這段時間 讓我們做的集中一點 然後等到等一下 拍完照之後再回到原本的位置嗎這樣OK嗎 

[33:30 - 33:54] 

**Peter:**
不好意思再麻煩大家了 兩個海報都掉了 這樣OK嗎 好 那好啊好啊 

[33:54 - 34:34] 

**Peter:**
那我們兩位主持人就在這邊加入接下來的話 

[34:34 - 34:59] 

**Peter:**
就會是由我們來做 AI的相關的背景 還有意見徵集的階段報告 那 任祥可以幫我們切到 就是大螢幕切到那個投影片的部分嗎 OK 好 剛剛已經結束自我介紹時間 也結束合照時間 感謝大家的配合那我們接下來就要一起來討論 

[34:59 - 35:22] 

**Peter:**
就是V Taiwan的人工智慧的倫理規範 在此之前我們要先有一個背景報告 首先我們要先來談的是 AI這個議題的背景 我們要先從AI談起吧 今天我們剛剛有提到 我們目前發現 大家提出來的意見 集中在三個不同的層面 第一個是個資與隱私保護 第二個是歧視與偏見 第三個是在地化的相關規範那我們接下來就從 

[35:22 - 35:45] 

**Peter:**
幾個不同的案例來看 首先這個是這禮拜產生的新聞 就是微軟的開發者 他們AI的開發者 他們在就是把他們的東西 去push上GitHub的時候 不小心的把38TB的機密資料 都放在GitHub上面了 所以等於是這個38TB的data就這麼不小心的被洩漏出來了 

[35:45 - 36:08] 

**Peter:**
那AI的發展其實資料 而且是高品質的資料 十分的重要 那這樣子他也會衍生出 個資甚至是資料利用上的一些疑慮 那同時另外一個新聞 其實也可以佐證這一點 像是Zoom今年 他修正了他的使用者條款 他提出說他們會 公司可能會利用 你在Zoom開會的時候所記錄下來的會議記錄跟聲音 

[36:08 - 36:30] 

**Peter:**
那這些東西也都讓大家懷疑說 Zoom是自己想要開發 自己的AI的資訊系統 或者是AI的工具 但是他卻是以使用者 使用Zoom的所留下的資料 為代價跟為基礎加以開發的 那在資料的另外 以外的第二個議題 就是所謂的偏見跟歧視的問題 這個左邊的這張圖是一個很有趣的笑話 

[36:30 - 36:54] 

**Peter:**
就是有一個人 有一個美國網友 他分享了一個事情 他是說 他叫AI問說 AI那個Mid Journey 你能不能夠幫我生一個 白人搶銀行的圖片 AI幫他生出來了 但是他生出來的是一個 穿著白色衣服的黑人 去搶銀行的圖片 那很明顯的 我們大家並不是想要看到一個 這很明顯就凸顯出來AI的系統對於犯罪 

[36:54 - 37:16] 

**Peter:**
或者是對於刑事的案件 其實是具有它一貫的一個偏見存在的 那這個偏見可能來自於 過往的資料 也可能來自於它本身在 函數或者是相關的 內部的演算法設計過程當中 所產生的一個偏見 那另外一個偏見 另外一個偏見 或者所謂的刻板印象呢 則是如果你在 目前的圖片生成的人工智慧上面去搜尋所謂的wedding dress 

[37:16 - 37:39] 

**Peter:**
所謂的婚紗的時候 它跑出來的結果 絕大多數都是像 我現在圖面上所顯示的 右邊圖片上所顯示的 是傳統西方婚禮的白紗 但是我們要知道的是 結婚的服飾 其實在全球各地的文化當中 都有不同的服飾 像中國有所謂的漢族的 結婚的服飾甚至是其他少數民族的服飾 

[37:39 - 38:01] 

**Peter:**
那以台灣的原住民來說 也會有相當其他 不同的傳統服飾 如果是日本的話 也會有所謂的白無垢的 這樣子的一個結婚服飾 所以這樣子的一個 為什麼AI只能夠生產得出 這種白色婚紗 並且把它認定為是 婚紗的唯一的形式呢 這就會牽扯到 其他的歧視 以及偏見的一個部分 最後一個是所謂的在地化的部分 

[38:01 - 38:24] 

**Peter:**
這個報導的內容 擷取自紐約時報 之前針對文心一言 也就是中國開發的 深層式語言模型系統 還有ChatGPT的比較 那這邊提到了 他說我們請文心一言 談談在中國部分 或完全受到審查的話題 包含說中國的 新冠清零政策 究竟是成功還是失敗 1989年的6月4號 是發生了什麼事情呢俄羅斯是否侵略了烏克蘭 

[38:24 - 38:46] 

**Peter:**
或者是美國 如何影響台灣局勢呢 文心一言迴避了 有關中國新冠清零 限制措施的問題 而是對該政策 進行了非常冗長的論述 當被要求講述 1989年6月4號 發生的事件時 聊天機器人自行重啟了 重新加載的頁面上 彈出一條消息 我們換個話題怎麼樣你會希望說AI 


[38:46 - 39:12] 

**Peter:**
未來的AI發展 是在你問到一些 相對來說政治上 比較敏感的話題的時候 在中國的使用者 或是中國開發的 人工智慧系統 是會變成這個樣子的嗎 那這個就會牽扯到 AI在地化的一個相關議題 好 那三個議題部分 介紹完了 接下來我們讓Erica 來呈現給我們 意見徵集的相關結果好 對 

[39:12 - 39:36] 

**Erica:**
那不曉得大家有沒有用過 Polis我們給大家投票 或者是表達意見的那個平台 那今天我們就是 建立在這個 資料蒐集的結果之後 然後召集大家 一起來討論更深入 或者是我們更多 沒有蒐集到的想法 那這份報告呢 我們總共有188個人參與然後像剛剛Peter說到的 

[39:36 - 39:59] 

**Erica:**
我們原本只有丟 30個種子意見進去 那最後呢 我們產生了75個 不同的論點 然後大家對這75個論點 加以投票 然後這個結果 成就了我們有三組 最主要的意見分類群 然後這是一個 蠻有趣的現象 然後從這三組有意見的分類群 

[39:59 - 40:22] 

**Erica:**
我們今天比較沒有著重在 到底這三組是長什麼樣子 而是我們想要先讓大家看看 我們具有共識的 最主要的一些點有哪些 然後大家可以看到 左手邊就是 那75個意見裡面的 其中五個最具有共識的部分 然後而這五個意見 也佔整個群體裡面 70%以上的人都是認同這件事情 

[40:23 - 40:46] 

**Erica:**
那這些其實都是偏比較中性 或者是說 關於AI這個 關於生存式AI 它在整個創造的過程中 我們應該要保持中立 要保持開放 然後要讓這個模型 可以讓大家都可以去理解 然後再加上 我們的訓練不應該我們的資料不應該 

[40:46 - 41:09] 

**Erica:**
來自於我們的客戶 或是不應該侵犯到人的隱私 所以這個其實是 大家都有的共識 那比較有趣的就是 剛剛我們提到 我們後來分類成三個議題 也就是等一下接下來 會跟大家一起分類討論 議題一議題二跟議題三 然後這議題裡面 有一些就是很有趣的是 像是關於歧視與偏見我們從這三個分類裡面 
[41:09 - 41:34] 

**Erica:**
C族群是非常反對這個意見的 就像我認為 如果有一個脫口秀演員 他在運用AI 在生成一個 跟LGBTQ族群有關的笑話的時候 那AI那個GPT是應該要不回答 還是要回答 還是要怎麼樣去處理這個可能帶有偏見或是歧視的過程

[41:34 - 41:58] 

**Erica:**
然後像接下來議題三 我們也會點到說 關於審查體系還有在地化 當他遇到了AI 然後我們可以看到 像我們的第七個觀點 他說我認為 一個在中國的GPT 就是像剛剛Peter舉例的 應該要排除這個敏感的關鍵字 但是可以看到 雖然我們可以看到 C族群覺得應該要反對但是其實我們有很多人

[41:58 - 42:22] 

**Erica:**
是直接拒絕 對這個論點做任何表達的 那這也是為什麼 今天會想要邀請大家 因為有32%的人 是完全對這個議題 是覺得不想要去回答 那今天在場 就是會希望我們可以針對 我們今天提出的議題一二三 然後收集更多的想法然後讓Peter還有我們的團隊 

[42:22 - 42:45] 

**Erica:**
帶去給chat GPT做為參考 好那接下來就是希望大家 在議題的過程中 只要你有想法 然後想要發言 就可以舉手 然後包括我們線上的朋友 如果你有想法 可以留言 也可以就是告訴我們的團隊 然後我們會讓你們有時間 發表你的想法然後會希望大家 

[42:45 - 43:10] 

**Erica:**
可以控制自己的時間 因為這樣可以讓更多人 去發表自己的想法 好那這是我們剛剛 一直提到的那個題幹 比較有點長 比較抽象比較尖銳的題幹 對的 那我們就直接進到 我們把這個題幹 分成三個議題去作為討論 那我這邊就稍微讓大家去暖機一下 

[43:10 - 43:32] 

**Erica:**
我們接下來的議題一二三 分別會裡面會想要 更深入去探討的 像是議題一 我們會碰到隱私跟資料保護 那這一塊呢 主要就是涉及到 深層次AI 它需要大量的資料 去投入訓練 那這些資料呢 本身我們可能希望 我們使用者會希望 這個AI如果它的回答能夠越個人化 

[43:32 - 43:56] 

**Erica:**
或者是越符合 我自己需求越好 但是在過程中 你如果想要它越有個性 你勢必就是需要你的資料 需要有更多有隱私的資料進來 才有辦法達到這個目的 要不然它就會像 以前我們問Google搜尋一樣 就是非常的general 那要怎麼樣在個性化的體驗跟匿名化資料保護之間 

[43:56 - 44:19] 

**Erica:**
做取捨 這就是我們議題一 最主要想要去探討的部分 然後當如果真的隱私權被侵害了 我們究責到底要該怎麼究責 是要怪AI 還是要怪使用這個AI的人 那議題二的話 就是主要著重在 剛剛Peter點到 歧視與偏見 不管是婚紗或者是搶匪 我們針對這些資料當它被餵進去的時候 

[44:19 - 44:42] 

**Erica:**
可能是本來我們這個社會 就帶有一些偏見或是歧視 那要怎麼樣 讓這些已經有bias的資料 丟進去之後 能夠讓大家去意識到 其實這些是偏見或是歧視 那我們要怎麼樣去解決這個問題 當這個新科技已經又出現了 難道要再讓歧視跟偏見 繼續發生嗎 那議題三的話 就是在講在地化跟倫理規範可以想像成就是 

[44:45 - 45:08] 

**Erica:**
一樣的問題 在不同的國家 不同的情境 還是一樣的答案嗎 入境隨俗 那個俗到底是什麼 對 簡單來說 我們接下來就是會 這樣進到三個議題 好 那 事不宜遲 我們就進到議題一 然後這邊的話 是我們收集到 剛剛提到的那個報告的結果 

[45:08 - 45:31] 

**Erica:**
然後我們 截取了 一二三四五七個 這七個 有點有趣是 它落在 整個共識裡面 最沒有共識的部分 所以這是 這是用來 可以讓大家有一些靈感 然後在場我們其實是希望 只要是針對 隱私或是資料保護 你有什麼想法 你都可以 非常隨時歡迎你們提供你們的想法跟意見 

[45:31 - 45:53] 

**Peter:**
簡單來說 你們可以針對上面的 幾個敘述 編號的 編號的敘述 來進行回應 也可 就是提出你們的看法 或者是你們覺得 上面的敘述 可能沒有涵蓋到 你們想要討論的東西 也都可以提出來 那 現場的參與者 如果有提出意見或議題 然後你想要回覆的話也都直接可以舉手回覆 

[45:53 - 46:15] 

**Peter:**
這樣子 沒錯 好 那不曉得 這一題上面 大家有什麼想要 有誰想要率先舉手的嗎 有嗎 個資跟隱私保護 如果沒有的話 我們可能就會 看看在場 有沒有一些參與者 剛剛自我介紹的背景 是比較接近的 線上好像有人 是想要舉手回應的嗎 看一下Sanya請 
[46:15 - 46:38] 

**Peter:**
Sanya請說 

**Sanya:**
我比較想先確認一下 第45題的 公平的定義是什麼 

**Peter:**
第45題 您指的是第45個敘述的 所謂的公平性的定義嗎 

**Sanya:**
對啊 是依誰為公平呢 或者是依什麼族群或者是依什麼定義 
[46:38 - 47:01] 

**Sanya:**
去決定這是公平的Data 

**Peter:**
是 那這個問題的話 因為目前的這個敘述裡面 是沒有包含 這樣子的一個標準的 那想問一下Sanya 你會覺得說 怎麼樣的標準會比較好 會比較好呢 

**Sanya:**
因為如果先依現場 大家都會希望 AI是一個沒有歧視的沒有偏見的一個狀態

[47:01 - 47:23] 

**Sanya:**
那我就會比較好奇說 那今天誰會去餵養這樣的資料 因為看起來 能夠餵養這些資訊的族群 都是屬於所謂 比較有資源的 比較有Power的 那所謂的少數族群 應該可能比較不會有這樣的機會去處理這些Data

[47:23 - 47:46] 

**Sanya:**
那所以到底餵進去的是 對誰公平呢 所以這是我有發想的一些 想法這樣子 

**Peter:**
了解 感謝Sanya提供意見 我們這個意見感覺是可以留到 第二部分的歧視跟偏見的部分 來進行討論的 還是說現場的參與者 有誰想要回應Sanya的意見的嗎對 

**Erica:**
針對資訊的餵養

[47:46 - 48:10] 

**Peter:**
相關的公平性 或者是其他的隱私相關的議題 Teemo要發言嗎 還是 Teemo那個麥克風是沒辦法用的 所以可能要請工作人員 讓我可以在電腦旁邊看 那任祥麻煩您 對 投影片有連結嗎好 那任祥你先幫我調子母畫面 

[48:10 - 48:34] 對 先放到這樣子 讓大家能夠參與 然後 對 

**Teemo:**
好 我本身在醫療領域 然後我有使用 我有使用大語言模型 在我的工作上面 對 那 我覺得第25那個 把客戶的資料放在AI上面 基本上如果你希望醫療領域有一個 

[48:34 - 48:57] 

**Teemo:**
自己專用的模型的話 它就是會 它就是會使用大家的 醫療的資料 比如說健保資料 或者是相關的一些 就是跟人 有直接有關係的病例 或是病理資料這些 對 那如何在 保障那個隱私權的情況下 使用這些資料對醫療產生貢獻 

[48:57 - 49:23] 

**Teemo:**
我覺得是蠻重要的 所以如果說不能使用 客戶的資料 在訓練AI這件事 或放到AI系統上面的話 那基本上所有跟 就是醫療領域 至少在醫療領域 使用AI的上面 就會有困難這樣子 了解 好 

**Erica:**
我們請PBS

**PBS:**
我要站起來嗎

[49:23 - 49:46] 

**PBS:**
我介紹一下我的背景 我之前在智慧監控產業 也做過AI開發的工程師 然後 也回應剛剛醫療產業 我也分享一下 以生成式影像分析 以及監控產業如何使用AI 這個問題有點像是到底資訊應該要公開 

[49:46 - 50:10] 

**PBS:**
還是要keep it private 就是什麼是隱私 是公開好呢 還是隱私好 我舉個例子來說 大家知道全台北市 大小街道攝影機的畫面 是公開的嗎 你現在在YouTube上面 都找得到 而且你在台北市的官網上面 你可以看到 它有一行附註說 這些資料都是公開然後它鼓勵大家

[50:10 - 50:34] 

**PBS:**
用這些資料去做技術的開發 也就是說在這個產業裡面 其實大家會拿這些東西 來做開發 但是你走在路上 台北市的路上 你知道自己被拍攝了嗎 你並不知道 我也研究過相關法律 除了台灣以外 全大部分全球的法律 也都是保障說 我今天可以用這些資料 然後這些資料應該要被公開 但是它有一個不論是美國的官司訴訟 

[50:34 - 50:57] 

**PBS:**
或者是歐盟有打過的案例來說 他們現在主張的做法是說 只要我把它拿來開發 開發完技術以後 我不要在網路上 直接可以搜尋到你的這個圖片 那我們認為它就是合法的 因為它是應該要 保障技術開發的一個做法 這個是一個 我自己在這個產業的時候 我自己有感覺到說原來對這些人來說 

[50:57 - 51:19] 

**PBS:**
技術開發是優先於 所謂什麼叫做隱私權 這些人有沒有被同意 這是對他們來說 這是完全不同的兩件事情 所以我認為 在這個議題上面 的確需要有更多人 在看到不同面向來去做對話 那也就是先拋出一個 現在有一個這樣的狀況 然後全世界可能都會進行 有這樣的狀況就是你在網路上的東西 
[51:19 - 51:43] 什麼是公開的 什麼是隱私的 這兩個之間的界線到底是什麼 我想要透過這個議題 然後回應剛剛醫療產業的朋友 提出來的想法就是 技術開發的確需要這些資料 那在過去的案例當中 也有這樣的做法 先拋出來給大家 可以繼續做討論 謝謝 

**Peter:**
好 感謝 有誰想要回應剛剛不管是Teemo還是PBS 

[51:43 - 52:05] 

**Peter:**
還是線上的SENYA 提出的意見的嗎 Nicole 

**Nicole:**
謝謝 我自己在看這些議題的時候 我覺得可能我們基本上 要把蠻多議題的層次 要把它拉出來 那因為如果我們把AI想像把它 把AI它是一個工具 

[52:05 - 52:29] 

**Nicole:**
然後它現在的目的是 作為我們 比如說這個數位轉型的2.0或3.0 它就是一個AI 它就是一個科技化的工具 讓這個很多的應用 或者很多的這個應用成為可能 那如果從這樣來看的話 它事實上它確實是會用到很多的資料那但是這些資料還是無改於 

[52:29 - 52:51] 

**Nicole:**
我們既有的法治的體系的架構 比如說有些資料 它是屬於各自的保護 有些資料它是屬於隱私的保護 有些資料它可能是 並不涉及到各自或什麼 它其實是可以被運用的 可以去做這個 甚至所謂的Data Economy的應用的這種 所以那個基礎的那個議題可能還是必須要去跟隨 

[52:51 - 53:15] 

**Nicole:**
比如說今天如果是一個公司 它在剛剛比如說這裡的這個第26題 我跟各位舉一個例子 Chet GPT剛出來的時候 沒多久 大家如果印象還記得的話 好像是Samsung還是哪一家公司 他用了這個之後 然後資料就 公司內部的資料就外洩 我跟各位報告 那個根本不是AI的問題 那是公司治理的問題因為它公司內部 

[53:15 - 53:38] 

**Nicole:**
針對它公司內部的資料 它沒有把它用智慧產權的管理制度 去區分為哪一些是機密 哪一些不是機密 哪一些不可以去用一個 甚至不是企業化的版本的Chet GPT的AI 而是用一個Open的 一般User都可以用的 那你把它丟上去 你基本上已經先違反了公司內部的資料治理

[53:38 - 54:00] 

**Nicole:**
跟這個智慧產權治理 所以剛剛那些議題 其實應該我的個人的建議 是把它爬梳清楚 那這樣子的話 既有的法規怎麼去遵循 那AI而產生新的問題 我們怎麼去用新的Solution 去在Design in的時候去關注它 這個可能會讓這個問題 比較可以更進一步往前去討論跟發展 
[54:00 - 54:23] 

**Peter:**
了解 稍稍梳理一下 剛剛Teemo提出來的是 如果不利用資料的話 似乎在技術發展上就很難去進行 那PBS剛剛提出來的 則是技術發展的 有些人他過度看重技術發展 反而會忽略了隱私保護 這樣子的一個重點 那Nicole提出來的則是說 除了在看重AI跟隱私 這樣的衝突之外可能也要了解到說 

[54:23 - 54:46] 

**Peter:**
這個隱私的問題 可能不一定是因為 AI的系統而產生 而可能是來自於 其他不同的問題 包含像公司自己的問題 那想 不知道想要 在座或者是線上的參與者 有沒有想要針對 剛剛這幾位 或者是針對 我們目前提出來的這幾個 大家在意見徵集的時候 共識比較小的議題 來提出回應的呢有 

[54:48 - 55:11] 

**Peter:**
不好意思 那個麥克風麻煩 然後 可以自我 也可以順便自我介紹一下 自我介紹 

**冠汝:**
大家好 我是冠汝 然後是來自人權團體 其實我會想要問一個問題 就是今天 就是補充一個 我看到上面的問題 其實我當初在填的時候 有滿多 我是因為我覺得 

[55:12 - 55:34] 

**冠汝:**
可能有一些條件 所以我會略過沒有回答 就是沒有直接選出是或否 那我其實會想 我再問另外一個問題 就是說 如果今天在訓練一個AI的時候 他一開始 沒有去跟 這些資料的主體 講清楚 我收集什麼資料 我後續要做什麼應用我未來會把它用在什麼東西上 

[55:34 - 55:56] 

**冠汝:**
那之後如果這個當事人 他提出說 我現在想要 心思 就是我希望 我不要在這個資料機裡面 我要撤回 不管是他過去曾經有同意過 提供資料 但是可能沒有到提供資料 給AI應用這個程度不管是他要撤回同意

[55:56 - 56:20] 

**冠汝:**
或是他要行使他的拒絕刪除權 那這時候應該怎麼辦 就是我想問的是這一個 但因為已經訓練下去了 可能出來的是一個模型 不再包含他原本資料 但是畢竟這個模型是 當初有使用他的資料去 不管是開發或是測試 那這個時候 是不是也會對於這個不管是商業還是發展應用 

[56:20 - 56:44] 

**冠汝:**
變成是他後續難以運作的問題 

**Peter:**
了解 剛剛冠汝提出來的好像是 第一個是關於同意的問題 就是在使用資料進行利用的時候 是否有同意過 有做到同意的問題 然後第二個是 他如果同意了 或是他沒有同意 但他之後想要 不管是怎麼樣的情況 他想要把資料撤回 這樣子的一個情況 要怎麼樣去處理這個是冠榮剛剛提出來的一個問題

[56:44 - 57:06] 

**Peter:**
那不曉得在座 還有誰想要回應的嗎 如果沒有的話 我可以再另外再 可能再追加一個 跟冠汝提到的部分 有關的一個議題就是 那如果他不是想要撤回這個資料 而是他想要 他想要分享AI模型所貢獻的這個利潤 

[57:06 - 57:30] 

**Peter:**
就像是我的資料被餵給了Chet GPT 那我能不能夠從Chet GPT當中的 他所獲得的利潤 去claim一點 去說我好像可以拿到 是不是可以拿到一點分潤 這樣子的感覺 不曉得在座的各位 對於剛剛提出來的問題 有什麼樣的一個想法呢 Ronny

**Ronny:**
其實我在想一個問題 

[57:30 - 57:53] 

**Ronny:**
就是說我們AI 就是我們本來就已經有討論很多 在不是在AI領域 在其他領域下 使用各自有什麼樣的限制 有什麼樣的 例如說我要有撤回權 我要有被遺忘權之類的 那麼有沒有人盤點說 在AI的領域 有什麼權利是好像很難實現的 例如像我自己想像 被遺忘權這件事情 我們傳統上好像在資料庫裡面

[57:53 - 58:15] 

**Ronny:**
刪掉就是被遺忘權 可是在AI裡面 我們要叫一個人忘掉一件事情 是很困難的 在AI會不會也是很困難的 有哪些權利 在我們過去認為理所當然的 或是必須要有的 但是在AI領域 他可能會難以執行的 有這樣的一個盤點嗎 我是蠻好奇這件事情 假如有這樣的盤點我會覺得可行的 

[58:15 - 58:41] 

**Ronny:**
那當然平常怎麼運作的 那他就在AI就怎麼運作 但是不可行的 那我們就要討論 他有什麼樣的運作法 

**Peter:**
所以Ronnie是認為說 我們應該要先做 譬如說資料的權利 跟制度上的盤點

**Ronny:**
傳統上我們在各自怎麼保護
[58:41 - 59:03] 

**Ronny:**
那我們在AI上就應該怎麼保護 但是會不會有傳統上 保護不可行的 在AI上可能不可行的方法 

**Peter:**
好 所以Ronny的論點比較像是 如果傳統上的AI 傳統上的個資保護 是可行的話 那好像可以利用 傳統的個資保護的規範 來做規範就可以的 但現在的話問題就在於說 
[59:03 - 59:28] 

**Peter:**
有沒有一些狀況是特別有 人工智慧創造出來的一些 個人資料或隱私保護上的風險呢 有誰想要回應的嗎 

**阿甘:**
想Echo剛才那位朋友的說法 我覺得的確是這樣 就是說在傳統的 那個各自保護的話也許各國都有所謂相關各自法 

[59:28 - 59:52] 

**阿甘:**
就算是台灣的 可能還不夠齊全的話 但是有時候在 我覺得不只是GAI 甚至是比較傳統預測型的AI 可能有一些原來 傳統保護各自的方式 其實是做不到的 那就像說傳統的話 我們很在乎 可能所謂的知情同意 你一定要先同意 可是我覺得在AI的世代就是說世代的狀況下 

[59:52 - 01:00:15] 

**阿甘:**
其實我覺得知情同意已經不夠了 可能更在乎是 你到底怎麼處理跟利用 譬如說我們手機下載APP的話 常常它說跟第三方分享 可是我們從來不知道 所謂的第三方是哪裡 它就不知道到哪去了 還有這是第一個 我覺得就怎麼處理利用 所謂跟第三方分享 我覺得這個其實是要更明確定出來 

[01:00:15 - 01:00:39] 

**阿甘:**
這是第一個 然後第二個的話是在於是 譬如說事實上現在 傳統的個資保護不夠的話 可能你說像我們 使用一些數位平台 然後它會有推播 推播一些廣告 或推播一些朋友 你可以去跟他加朋友那些 事實上它可以不需要你名字 可是它對你掌控得一清二楚 那我覺得在這一塊上就算他不知道我名字 
[01:00:39 - 01:01:03] 

**阿甘:**
可是我也覺得我隱私被侵犯 所以我覺得隱私跟個資保護 應該是兩回事 就都是不一樣的 每個人的隱私的範圍可能不一樣 可是個資保護 也許傳統的法律有訂定 可是不太適合現在的數位時代 

**Peter:**
了解 所以阿甘提出來的比較像是說 隱私感覺是一個比較新興的 AI時代的隱私會是一個比較新興的問題

[01:01:03 - 01:01:26] 

**Peter:**
嗎 好的 那再來Teemo好像有想要回應 然後貴智有想要回應 不好意思 可以先讓貴智回應 然後再讓Teemo回應嗎 因為貴智剛剛還沒有發言過 好 那桂智 

**貴智:**
我的疑問是因為這個標題是隱私與資料保護 

[01:01:26 - 01:01:48] 

**貴智:**
然後從上面的七個問題來看 其實我覺得兩個涉及到 我覺得它不是很切題 第一個 因為譬如說在討論 AI生成有沒有著作權 然後有沒有利用 那它到底算是隱私還是資料保護 這讓我覺得很困惑 因為今天既然都已經進入到 著作權討論的話 這東西本來就預期是要公開只是可能被使用的人認為

[01:01:48 - 01:02:11] 

**貴智:**
它的著作非法被利用 那這是不是也涉及到資料保護 我也覺得很困惑 因為這個標題讓我感覺是 可能是要去討論 AI的使用過程中 它會不會有過度的 收集了大家的個資 或者是讓使用者 在沒有預期情況下 站在個人的觀點我的資料怎麼被收集了 

[01:02:11 - 01:02:34] 

**貴智:**
我的資料怎麼會被這樣利用了 所以目前選出來這七個 會讓我覺得有一些 是不是可以切出去 做不同的討論 這樣會比較切題一點 然後再來是我覺得 在討論到隱私的時候 我的想法是 我們是不是應該要先想 到底我們對於隱私的期待是什麼 然後我們再判斷目前的AI 我們最熟悉的 CHPT這樣的形式它到底會在什麼情況下面

[01:02:34 - 01:02:58] 

**貴智:**
侵害到個人的隱私 我覺得也許這些層次要去拉出來 我們才有辦法去做更 我們才有辦法去做更細緻的討論 以我個人觀點來說 回到今天第一個 第一位朋友講的 像醫院可能需要使用AI的話 那我的想法就會跟前面的 前面有一位 不好意思忘記名字 那也是律師的 這位朋友的想法是一樣 就是他應該是他應該有獨立的資料庫的概念

[01:02:58 - 01:03:20] 

**貴智:**
不是讓自己客戶 放到一個公眾 都有機會被使用的資料庫的概念 了解 所以貴智剛剛 想要回應Teemo的部分 比較是說 如果要利用的話 至少 就是Teemo是剛剛提出醫療問題的 就是比較如果要利用的話 或許可能要比較 用一個獨立的資料庫 或一些合理的處置的方式 來加以利用這樣子 

[01:03:20 - 01:03:43] 

**Peter:**
OK 那後面 戴瑜慧教授 戴瑜慧老師 

**戴瑜慧:**
那謝謝剛剛各位的討論 那我是戴瑜慧 那就是的確 如剛剛的朋友提的 就是 我們現在的科技那一直的與時俱進的發展

[01:03:43 - 01:04:08] 

**戴瑜慧:**
所以也挑戰了我們一些 新的概念 所以剛剛講的一個很重要的 隱私權的概念 的確是歐盟之前就在討論的 就是 它挑戰了我們原來的 我們現在都已經知道 我們現在進入一個 平台資本主義的時代 那這些平台 它一個很重要的利潤基礎

[01:04:08 - 01:04:31] 

**戴瑜慧:**
是來自於各位所有人的Data 而這些所有人的Data 卻是集中 擁有在這些私有產權的 平台裡面 所以這是我們今天聚集在這邊 一個很重要的原因 那所以它裡面出現的案例 譬如說 德國有重要的政治人物他的妻子過去曾經是性工作者 

[01:04:31 - 01:04:54] 

**戴瑜慧:**
所以你只要搜尋他妻子的名字 就會出現 他是性工作者的資料 那 所以人 就剛剛有朋友提到 被遺忘的權利 或數位足跡等等 所以隱私權的這個概念 那平台方也會提出 理由 就是說我們有知的權利我們這邊很多傳播的學者 

[01:04:54 - 01:05:17] 

**戴瑜慧:**
周奕成大哥也是 所以沒想到平台方 他就會說我們有知識的 知的權利這種 所以的確就是 我們可能就要更Define清楚 我們可能想要新的 伸張的 權利概念是什麼 然後據此去捍衛就是 

[01:05:17 - 01:05:41] 

**戴瑜慧:**
好 那個隱私權是什麼 在這樣的目前的結構之下 我們希望怎麼樣去 得到 那另外一個我覺得很重要的是 AI的基礎是來自於 Data的餵養 那 它一個透明化 就是這個演算法 它的程式碼的公開透明 以及如何取得資料這個是很重要的基礎 

[01:05:48 - 01:06:11] 

**Erica:**
剛剛是不是還有另外一位朋友 

**Teemo:**
我補充一下 剛剛就是順著阿甘講的那個議題 我覺得現在這幾題 之所以難以歸類於某一類 或者是難以取 就是把它分別在某一個 可以釐清的範圍的原因 是因為 我們沒有很好的把這幾個題目定義出它 

[01:06:11 - 01:06:33] 

**Teemo:**
什麼情況下 它可以把資料餵給它做學習 以及在什麼情況之下 它可以被授權回答 就是 如果我們今天把資料餵給大語言模型 那哪一些資料可以餵 哪一些資料不能餵 這件事情 就是在這幾個題目裡面沒有被先前提定義清楚 

[01:06:33 - 01:06:58] 

**Teemo:**
然後以及 它學到了這些資料之後 可不可以這樣回答 這件事情也沒有在這幾個題目裡面 被後面明白的描述 所以才會造成 現在我們這幾個問題 看起來很難被歸類 或者是很難被區分出 它應該要怎麼樣處理 舉例來說學習生火有很多的方式

[01:06:58 - 01:07:20] 

**Teemo:**
但是如果 如果說有一種生火的方式 會傷害人類的話 這個方式也許可以讓大語言模型去學習 但是應該要限制它 不可以回答 會傷害人類的這些用法 所以學習是一回事 然後如何被回答 以及讓它產出 又是另外一個問題所以我覺得現在 

[01:07:20 - 01:07:44] 

**Teemo:**
就是線上的這幾題 並沒有很好的 區分出學習跟使用這樣子 

**Erica:**
好 那關於這些 這個部分的話 其實我們在定義 整個議題一二三的時候 其實有經過非常 其實它不是非常容易 然後加上這75個觀點 其實本身都是來自珍貴的大家貢獻的意見 

[01:07:44 - 01:08:07] 

**Erica:**
那我們也沒有辦法去 針對每個意見 去做修改或是調整 因為那都是每個人 自己寫出來的東西 那剛剛提到著作權 出現在這裡 或者是 大家對於怎麼樣去定義 這些題目應該要怎麼放 基本上我們希望 這一場會議本身我們其實都是用引導的方式 

[01:08:07 - 01:08:29] 

**Erica:**
那這些題幹 也是希望可以讓大家 有一些靈感 然後是希望 大家可以看到這些 想法之後 如果你覺得 這個好像有點瑕疵 那你可以提出 你的看法的部分是什麼 對 然後因為今天時間 真的非常有限 然後如果你是對於 這幾個問題 應該要怎麼做 這件事情的話我們可能今天沒有辦法

[01:08:29 - 01:08:51] 

**Erica:**
針對這個部分去討論 反而是比較希望 大家可以提出更深 或者是更廣的 去講這些東西 然後很不好意思 著作權我們放過了 一二三最適合放的地方 是在這邊 對 如果 讓你覺得非常不舒服的話 對 那針對議題 還有沒有人有什麼想法 然後對 好

[01:08:51 - 01:09:13] 

**Erica:**
那我們請申翰 有沒有幫忙遞個麥克風 

**洪申翰:**
個資法的修法 其實討論很久 然後坦白說 我們現在的個資法 有非常多的問題 這個問題我就不一一細說 可是確實在個資法裡面有一個最根本的問題 

[01:09:13 - 01:09:36] 

**洪申翰:**
是在前一段時間 大家想要討論的 但在幾個月前那次修法 也沒有辦法放進去的部分 就是包括隱私到底是什麼 因為在有很多的糾紛裡面 是實際上面發現 行政部門對於 什麼到底算是隱私 什麼不算是隱私 這件事情都有南轅北轍的看法 

[01:09:36 - 01:09:59] 

**洪申翰:**
那所以這裡面會有一個討論 假設隱私是一個概念 保護是一個概念 我有一個不是非常成熟的想法 但也想提出來討論的事情是 會不會是在AI的時代裡面 就是說到底隱私 什麼算隱私 什麼公開了以後會有傷害 這件事情 不只是它本身那個物件是什麼 而是它如果沒被保護好會產生什麼代價 

[01:09:59 - 01:10:23] 

**洪申翰:**
也許在不同的時代 透過不同的工具 其實付出的代價跟成本 是不一樣的 那如果從這個角度來說的話 有沒有在AI的時代 如果把某一些資訊 沒有保護好的話 可能會付出什麼代價 這件事情的想像 跟在進入AI時代以前 會不會是有差別 我的意思是說對於到底什麼是隱私的定義 

[01:10:23 - 01:10:45] 

**洪申翰:**
除了名義上面的定義以外 有沒有可能更多是 如果沒保護好以後 我會付出什麼巨大的 付出什麼不可見的 負面的代價回推 那到底什麼 該被認知為是隱私 那說實話 剛剛在討論到 有些人在討論到個資法 但是實質上面 我覺得以現在的個資法幾乎完全都跟不上 

[01:10:45 - 01:11:09] 

**洪申翰:**
現在討論的概念 什麼被遺忘權等等 在這個資法裡面 幾乎都沒有辦法處理 當然現在是有一些民間團體 希望能夠去處理這件事情 可是目前基本上 還沒有辦法處理到這事情 那只能在一些最基本 說誰有什麼責任 誰有什麼責任 大概在這個基礎上面 在這個框架 可是這個框架 都還有非常大調整的空間所以以上是幾個意見的補充 

[01:11:09 - 01:11:32] 

**Erica:**
謝謝 那好 那請奕成大哥 還有Nicole 奕成先 

**周奕成:**
大家好 我是周奕成 那我很簡短的 講一下我的意見 因為如果說我們今天 這個討論 目的是希望給OpenAI 或者說其他這些 大型的AI他們的開發者的話

[01:11:32 - 01:11:55] 

**周奕成:**
那我覺得在隱私 還有個人資料的保護上面 我們將來很快 會遇到一個境地 就是每一個個人 每一個individual 其實你已經沒有辦法 去保護你自己的權利 為什麼呢 因為所有的資料 理論上這個AI它都可以去hack 

[01:11:55 - 01:12:18] 

**周奕成:**
所有的資料庫 那你要在網路上 去保護這些個人的資料 幾乎是可以講說 很快都可以被破解 然後再來就是個人 當這些大量的隱私被侵害 的案例非常多的時候 我們的法律系統會崩解 

[01:12:18 - 01:12:43] 

**周奕成:**
就是說沒有辦法 透過現在的 這個法律的程序 來進行一個案件 一個案件的個人的資料 還有權利的保護 所以我們現在 應該要對OpenAI 或者其他的開發者 要讓他們知道說到最後其實只有這個AI本身 

[01:12:43 - 01:13:06] 

**周奕成:**
它的自己的 這個自我的管理 才有辦法去保護 這上面的所有人的資料和隱私 那將來要靠個人 去伸張自己的權利 然後經由這個法律的程序 很可能是會很難做到的 謝謝
[01:13:06 - 01:13:28] 

**Nicole:**
我很快 我很快再稍微講一下 我的意見 就是說首先那個主辦單位 把這些議題放在這邊 我認為其實是也有它的道理 因為本質上 本質上雖然基礎上 駐合權跟隱私跟個資 隱私是民法上的權利 雖然跟個資法的保護 它是不相干可是它在Internet 

[01:13:28 - 01:13:51] 

**Nicole:**
跟Generated的時代 它其實有一些技術上 被操作可能性的同質性 也就是說它那個資料 不管是屬於 駐合權保護的範圍 或者是個資保護的範圍 它是自動的 可能是被資料抓進去 然後去做一些生成式的產出 所以它本質上 是有一定程度的相似性所以但是重點是在於 

[01:13:51 - 01:14:13] 

**Nicole:**
它保護的法義 跟它可能要解決的方法 可能還有法律的效果 可能不太一樣 所以它有它可以放在一起 討論的可能性 但是我們要知道 我們要討論的是什麼 所以這個我覺得是第一個 那第二個就是說 我覺得我們在討論跟AI 特別是生成式AI的時候 如果是很基礎的議題大概就先bypass不討論 

[01:14:13 - 01:14:36] 

**Nicole:**
否則我們就沒有辦法去處理 AI 在AI的時代 發生這些問題的時候 我們怎麼去看它 那我同意剛剛奕成提到 就是說因為在現在 它最大的問題是 就像著作權 現在有很多可以再進行 是因為著作權的權利人 他因為OpenAI 或者是Meta他們用了盜版的內容 

[01:14:36 - 01:14:59] 

**Nicole:**
侵害的內容 去訓練它的content 而產出新的copyright的東西 所以類似像這樣 有generate AI的特質的工具性 而讓它變成這樣 結果的這件事情 在原來的既有的框架上 沒有辦法去處理的時候 我們來討論說 好 那要怎麼樣 好 那最後 那也因為是這樣所以我同意剛剛奕成說的 

[01:14:59 - 01:15:22] 

**Nicole:**
其實在現在這個時代 你很難從事前去處理說 我要怎麼樣的保護 你不能拿我的東西 什麼什麼 那個東西可能已經 沒有辦法去處理 所以剛剛主辦單位 他們參加提到的NIST那件事 它是從risk management的方式 來討論這件事 所以我們回過頭來看 當客觀上的事實 跟不管我是屬於 個資或隱私或者著作權在一個Internet時代 

[01:15:22 - 01:15:45] 

**Nicole:**
OpenAI時代 會變成這樣的結果的時候 我們要用一些什麼樣的方法 去分散這個風險 降低這個風險 同時又維護最基本的法律 原來給予它法律制度的 保護的可能性 大概是這樣 

**Peter:**
目前還有兩位參與者 一位是阿甘 一位是貴智 那我們會先 我們就按照剛剛舉手的順序然後兩位可能 

[01:15:45 - 01:16:07] 

**Peter:**
如果可以的話 因為我們大概就要換 接下來就要 可能要換到下一個題目 來進行討論了 那如果覺得還有什麼 未竟的意見 還沒有補充完畢的話 都歡迎上slido的 或者是用共筆的方式來進行 那先阿甘 

**阿甘:**
其實很快的那個 回應剛才那個 好像是詹婷怡朋友那邊說的就是 

[01:16:07 - 01:16:30] 

**阿甘:**
我覺得在GAI時代的話 那個最起碼 雖然我們事前很難去規範 他拿什麼不拿什麼 可是事實上很難規範嗎 這點我懷疑 其實就像剛才那位老師說 我覺得這些科技大公司 到底拿了哪些資料 把餵進去來學習 這點是他一定要公開那因為出來之後的東西 

[01:16:30 - 01:16:53] 

**阿甘:**
可能難以辨識 他會說類似 所以我覺得在GAI時代的話 起碼他要針對這塊要公開 然後那再來我覺得 那個隱私跟個資保密要分開 因為那個個資保密是個資法 什麼是個資 我覺得那是法律定義 那現在也許不足 可是我覺得可以再定義 可是那不代表 每個人隱私的那個 其實是不一樣的狀況下 那我覺得在這一塊應該區分個人跟團體 

[01:16:53 - 01:17:17] 

**阿甘:**
那我覺得可能在議題討論上 會更清楚 謝謝 

**貴智:**
一樣我延續前面的我延續前面大家的這個想法 

[01:17:17 - 01:17:40] 

**貴智:**
我就衍生出個想法是 如果是從後端的想法來看 怎麼去做控制風險的話 或許前端的資料庫 他如何的生成 他如何的製作 然後他收集哪些資料 他如何公開 然後如何去限制 我覺得這是一個 我覺得這是一個 我們一定要去思考的事情 但另外一個是 就是當使用者 在跟AI互動的時候 我覺得有一些東西有沒有可能是立即做 

[01:17:40 - 01:18:04] 

**貴智:**
然後可以降低 我們現在已知的風險 譬如說當使用者 說心裡畫一張宮崎駿風格圖 他能不能立刻告知使用者說 你這個可能有侵權的風險 我們或許我們可以 用這樣的方式 是不是就可以先大量減少 這些創作者覺得 他們被剽竊的問題 我覺得就以我自己的經驗好了 就我們在網站在做圖的時候 我們確實就試過請你畫一張紐約時報風格的圖 

[01:18:04 - 01:18:27] 

**貴智:**
紐約客風格的圖 然後我們也玩過 請你用李宗盛的風格 寫一串歌詞給我 然後大家都會覺得 那是不是很像李宗盛寫的 那這樣子的行為 是不是AI在後端的使用者介面上 他自己就可以先禁止這樣的行為 他可以自己提示說 這個行為可能涉及了剽竊 即使我們資料庫裡面 已經有李宗盛全部的歌詞 但我們並不允許什麼使用者直接把他想要的內容 

[01:18:27 - 01:18:50] 

**貴智:**
去對應到他所期待的那個狀態 另外就是當使用者輸入的資料 本身涉及到隱私資料的時候 說不清使用者自己沒有意識到 那AI既然有能力判斷的話 我們也期待他有能力判斷的話 這個AI能不能夠直接告訴使用者說 你現在輸入的資料 已經涉及了一些隱私的資料 那他有一個機會是他這個使用者可以撤回 

[01:18:50 - 01:19:13] 

**貴智:**
然後按一個取消鍵 他就不會存入系統裡面 我想我們也許在 也許在比較有執行面的階段上面 或許我們可以先來建議 GPT-4思考這些方向 

**Peter:**
感謝 我們看一下線上的夥伴 有沒有想要 就是目前可能看線上夥伴 還沒有最後一個就是想要發表想法的機會

[01:19:13 - 01:19:36] 

**Peter:**
因為我們接下來可能要 切換到下一個議題了 線上的夥伴有嗎 有人舉手 如果有的話可以直接按舉手 如果沒有的話 那我們可能就會切到下一個議題了 但是我們都歡迎大家 就直接利用我們 不管是共筆還是slido的 那個線上連結的方式 來就是提出你們 可能還沒有表達完整的想法 對線上還有

[01:19:37 - 01:19:59] 

**Peter:**
目前看起來好像 沒有嗎 目前看起來好像沒有 那我們就會先進到下一個 偏見與歧視 

**Erica:**
進到下一個之前 想說就是還是鼓勵大家可以 歡迎使用線上的slido 然後貢獻你的想法 然後我覺得 大家剛剛 怎麼講 我覺得後面關於隱私或者是什麼 

[01:19:59 - 01:20:24] 

**Erica:**
其實確實像剛剛Nicole還有奕成 還有申翰這邊點到的 其實很多事情我們沒有辦法 事前先知道 然後所以 什麼樣的情境 或是什麼樣的產業 有可能會遇到什麼樣的風險 我們其實可以事先先想一些 不一樣的情境 然後也歡迎大家在slido上面 點出可能像你工作的產業有可能當這個AI出現之後 

[01:20:24 - 01:20:46] 

**Erica:**
什麼樣的情境 的data餵進去之後 會有什麼樣的風險 然後可以再做更多後續的討論 然後甚至是帶到Chat GPT 讓他們去了解說 原來還有這些不一樣的情境 然後讓他們去思考 他們在做這個模型的時候 還要再考量哪些事情 好那我們就進到議題2 

**Peter:**
好在進到議題2的時候 

[01:20:46 - 01:21:10] 

**Peter:**
我想要借用剛剛Sanya提出來的問題 就是 AI的資料的訓練 要確保它是公平的 要確保它是沒有偏見 但Sanya或者是剛剛其他的 現場參與者其實有提到說 其實這樣子其實是蠻難做到的 就是AI的資料的訓練 勢必就一定會產生一定程度的問題 那同時它產生的結果就會是一些歧視與偏見的部分 

[01:21:10 - 01:21:32] 

**Peter:**
那接下來的話 就是關於歧視與偏見的內容 不曉得大家有目前的話 是否想要針對上面我們所提出的一些 抓到的一些就是分歧的意見 來加以回應 事實上我想要跟大家分享的是 第八個 就是如果脫口秀演員 運用AI模型撰寫這個笑話的這個意見呢其實它是所有意見 

[01:21:32 - 01:21:55] 

**Peter:**
它不僅僅是在這個族群當中 在這個就是歧視與偏見的這個族群當中 意見最分歧的意見 它也是在整個我們所收集到的 75個意見當中 大家的表示的意見 是最分歧的這個意見 所以不曉得大家是否想要針對 大家就可以針對這些意見來進行就是回應跟討論 

[01:21:55 - 01:22:18] 

**Peter:**
那不曉得現場的夥伴 或是線上的夥伴 如果有線上夥伴 如果想要直接提問或發表意見的話 可以直接舉手沒有關係 那現場的話也可以就是 可以舉手或發表意見 

**柔伊:**
然後我想要問 就是剛有提到那個第八點是意見最分歧的一個意見 

[01:22:18 - 01:22:41] 

**柔伊:**
那我們會知道 分歧的內容會是什麼嗎 這是可以看到的嗎 

**Peter:**
那寫的內容是 我們可能會在後台上有顯示說 因為那個polis 它會幫我們去算出 大家在投同意或不同意的時候 那比例大概會是多少 那如果大家都同意或大家都不同意的話 大家如果都同意或大家都不同意的話 就會視為是比較有共識的一個意見 但是如果是大家都同意跟不同意 

[01:22:41 - 01:23:09] 

**Peter:**
就是分歧性 就是五比五五五波這樣子的話 那就代表說它是一個 就是分歧程度最大的一個意見 那這個是剛好第八則意見 因為它會幫我們把那個光譜排出來 就是最分歧的跟最有共識的意見 那剛好就是落在光譜中 最分歧的那個意見的那一段點上面因為在座其實有蠻多是來自於 

[01:23:09 - 01:23:32] 

**Peter:**
就是不同的領域的Stakeholder 然後來自於不同領域的Stakeholder 不曉得就是 這些來自於不同領域的Stakeholder 有沒有想要針對 就是AI所造成的歧視跟偏見的議題 就是來提出一些討論 不管是針對 如何去改進這個歧視或偏見 或是想要建議OpenAI 可以採取什麼樣的一個行動 來降低歧視或偏見發生的機會其實都可以提出來 

[01:23:32 - 01:23:56] 

**Peter:**
對 有嗎 不好意思 好 佑宇 來 

**林佑宇:**
因為我是以學生的身分來 所以我突然覺得很好奇 因為這一些議題 它可能是比較偏向社會人士 但是其實從今年我們也看得出來 在原住民族的歧視裡面其實校園也發生了非常多 

[01:23:56 - 01:24:18] 

**林宇:**
而且其實就我自己身邊的經歷來講 我問他們說 為什麼你會對我們的族人 有這種莫名其妙 甚至是錯誤的想法 他們都說 要嘛是來自朋友 要嘛是來自家人 那最多最多其實就是來自於網路上 所以我會覺得說他應該有必要去防範 

[01:24:18 - 01:24:40] 

**林佑宇:**
而且如果以第八點來講的話 脫口秀演員 他在社會上通常是具有一定聲量的人 所以這件事情就會變得很可怕 因為你只要一旦 怎麼說呢 就是他聲量很大 所以有的人就會無法去思考說他講出來的東西到底是笑話還是事實 

[01:24:40 - 01:25:04] 

**林佑宇:**
就有人會搞不清楚了 加上他聲量很大 所以這些資訊會被散播的非常的快 變成可能這個刻板印象 或者是歧視 他沒有辦法停止 他會不斷的延續下去 

**Peter:**
不好意思 又有想要確認一下 所以你認為說使用AI工具 會加強或擴大這樣子的一個在社會上對於特定族群 

[01:25:04 - 01:25:28] 

**Peter:**
例如原住民族的歧視或偏見嗎 

**林佑宇:**
我覺得可能是有的 因為學生 在學校他們其實有時候 透過網路的方式去搜尋 因為學校其實也很少在教 所謂像媒體識讀 或是資料查證的這些東西 變成大家可能就是會無腦的去相信 他們所查到的這一切 所以就會變得很可怕 

**Peter:**
好那不曉得在座其他參與者 

[01:25:29 - 01:25:52] 

**Peter:**
阿甘還有貴智舉手 因為阿甘跟貴智剛剛有發言過 所以想看看有沒有其他 剛剛沒有發言過的參與者 可以想要針對這個部分表達看法的嗎 如果沒有的話 那就會先是阿甘 然後再來是貴智 

**Erica:**
或是我補充一下 就是剛剛 佑宇講到的 其實 它真的是完全跟AI有關嗎 會不會其實現在Google搜尋也是會做到這件事情 

[01:25:53 - 01:26:16] 

**Erica:**
所以大家可能可以更往 如果這件事情是針對AI的情境的話 它會是怎麼樣發生 或者是大家有什麼樣的看法 對 

**Peter:**
好 目前發言過 好像都是發言過 那會先讓Ronny你 因為剛剛阿甘有發 就是發言過比較 阿甘跟貴智可能都有發言過 比較多次了 

**Ronny:**
好 因為我有聽到後面其實有點崛起為什麼會有人會對這裡做反對 
[01:26:16 - 01:26:39] 

**Ronny:**
那我是反對的 但我認為警語一定要加 但是我認為因為這一題 如果今天AI只要遇到這問題 AI就拒絕回答 那今天假設不是脫口秀演員 今天是一個社會研究學者 我想要研究為什麼大家會有歧視性言論 什麼樣的歧視性言論 我想要去問AI 結果AI說我不能告訴你為什麼 我不能給你內容 然後因為我拒絕回答那我覺得也會失去很多人 

[01:26:39 - 01:27:02] 

**Ronny:**
要來善用這種歧視言論的資訊的機會 所以我認為警語一定要加 但是AI不應該完全拒絕 除非AI有辦法真的知道你的目的 但是我覺得AI沒有辦法知道 人的目的是什麼 因為脫口秀演員 他也可以偽裝成社會學的時候 我今天為了要解決大家的爭議問題 所以我想要去問這個 他可能拿去作惡 所以我認為對 我這題我是反對的 

[01:27:04 - 01:27:26] 

**Peter:**
好 那目前 剛剛還有三位包含阿甘 然後冠汝跟貴智 好像都要發表意見 那因為剛剛 不好意思 我有漏掉 因為剛剛發表意見的話 好像是冠汝比較少 那可能會先讓冠汝先發表 然後再來換阿甘跟貴智這樣子 

**冠汝:**
沒有 我剛剛想講的其實跟Ronny想講的一樣 

[01:27:26 - 01:27:50] 

**冠汝:**
就是說 一樣是說 今天如果有人要來測試 然後他不是 他只是想要做一個外部研究 到底這個系統有沒有歧視與偏見 他當然可能會問一些 就是請這個AI去創作的問題 那我可能就是在這點延伸補充說 其實我不知道就是OpenAI現在 

[01:27:50 - 01:28:12] 

**冠汝:**
它如何去做這種演算法 去測試它在每個階段有沒有bias 我不知道它是怎麼去做這個集合 因為我之前是有看過 那個ACLU 它是針對 不是生成式的 它是針對預測性的演算法 某個菌的預測性演算法然後它去做 

[01:28:14 - 01:28:36] 

**冠汝:**
不管是它預測分數出來的結果 跟它過去到底 拿了什麼單位的資料 拿了什麼單位 什麼族群的資料 去判斷它在這個演算法開發過程中 為什麼會累積這麼多偏差 導致它最後會針對 身心障礙族群會判斷這個家庭有比較高的 

[01:28:39 - 01:29:01] 

**冠汝:**
就是對兒少 兒少虐待的風險等等 所以其實不管是從結果 或者是研究人員可以接觸到 過去這些訓練資料 就是這些資料來源 或者是它怎麼被訓練 然後到最後它怎麼產出 其實對於要去判斷這個系統它到底有沒有歧視 

[01:29:01 - 01:29:24] 

**冠汝:**
歧視與偏見是蠻重要的 好 

**Peter:**
剛剛Ronny跟佑宇 討論的部分比較集中在 人工智慧的生成結果的部分 究竟要如何去處理的問題 那剛剛冠汝又拉了 算是有點像是提到說 在資料的這個面向 也會同樣影響到 生成是人工智慧的生成的結果 那等於是在資料在比較前端跟比較後端 

[01:29:24 - 01:29:51] 

**Peter:**
在這個人工智慧的生命週期的 前端跟後端的部分 都可能會涉及到 這個歧視跟偏見的內容 那想問一下 現在還有其他參與者 想要發言的嗎 目前這邊看起來 有一位好像剛剛還沒有發言過 是柔依嗎 柔依 剛剛問問題了 那有想要繼續嗎 還是 好 那請

**柔伊:**
因為我自己有簡單使用過 

[01:29:51 - 01:30:15] 

**柔伊:**
Chat GPT 然後就是嘗試在上面 問一些問題 就比方說 台灣出櫃的公眾人物有哪些 那其實我得到的回應 的內容是錯的 所以我就是會覺得說 就以議題工作者而言 Chat GPT現在對我來講 好像就是會有一點 我沒有辦法很相信它因為它給我的最基本的資訊 

[01:30:15 - 01:30:38] 

**柔伊:**
都是錯的 所以我就會覺得說 那連基礎的資訊都是錯的 那我現在可以進 就是 我覺得不太知道說 那要怎麼進到 就是討論好像更進階的議題上 這樣子 對 大概是這樣子 就比方說我問 公開出櫃的人物有哪些 其中一個就是藍正龍 但藍正龍他不是同志 他只是最近出了跟同志有關的電影而已 

[01:30:38 - 01:31:00] 

**Peter:**
這樣子 對 好 那剛剛看到了 目前剛剛有 就是發表意見 是阿甘 貴智跟戴瑜慧教授 那就按照剛剛有舉手的順序先來 然後還有就是Nicole 就是按照剛剛有舉手的順序 先來安排 先阿甘 然後再來貴智 然後再來戴瑜慧 還有RR 對 不好意思 對 好好 沒問題 
[01:31:01 - 01:31:24] 

**阿甘:**
謝謝 我有第一個問題 是我想請教主辦單位 過去G&B所在 類似這樣 就是說收集意見的時候 我們常常所做的意見 其實是給我們的政府 但是因為你這次這個活動 是針對跟OpenAI 所給的funding來做 所以如果我們今天收集的意見 是給OpenAI這樣的一個 私人的高科技巨頭的話那麼我覺得可能 

[01:31:24 - 01:31:47] 

**阿甘:**
我覺得在思考角度上 會不大一樣 因為當我們說 不應該有偏見 不應該什麼 那後面有一個裁決者 那可是我從來不認為 高科技公司有權做這樣子 以政府的角色來判斷 誰有偏見 誰有歧視 所以我不確定這件事 是不是要跟我們大家announce 我們在想的角度上 我覺得會有很大的關係好的 感謝阿甘 

[01:31:47 - 01:32:09] 

**Peter:**
對 這個的確是一個 需要考量的點 那的確 因為現在的諮詢會議的內容 除了會公開給大眾之外 它另外一個部分是會 就是我們會去 我們會就是 跟OpenAI報告 就是我們目前 這樣子的一個意見 徵集的結果是如何 然後我們會跟他們 我們希望的是達到的是密切的去 

[01:32:09 - 01:32:31] 

**Peter:**
看他們有沒有落實 這樣子的一個結果 還是說 就是他有做到 有沒有真的去 還是說他只是想要 就是做一個 類似這樣子的一個show 這樣子 對 不好意思 因為我剛才其實是 針對你的回答之後 有一個偏見的問題 

**阿甘:**
我可以接著問嗎 還是應該先給別人 可以 但是 可以給他注意時間 好 謝謝那如果是這樣的話 
[01:32:31 - 01:32:54] 

**阿甘:**
你們是針對OpenAI的話 然後因為我拒絕 讓高科技公司 我不認為高科技公司 應該扮演像政府的 一個仲裁者角色的話 那我認為 在關於有偏見這一塊上 應該盡量呈現 那個文本出來的時候 是多元性的 因為譬如說 他關於政治性 文化性的時候 他不應該只給一個 特定的意見這樣 或許可以多給兩三個但是設置是不一樣的 

[01:32:54 - 01:33:17] 

**Peter:**
謝謝 好的 看來這個 關於偏見跟歧視的部分 大家都滿有 目前排隊的發言者有點多 那先請貴智 那如果可以的話 可能要縮短一下時間 謝謝 

**貴智:**
我的想法跟前一位 跟前一位這個講者 想法是一樣的 就是針對這個議題我也反對 

[01:33:17 - 01:33:39] 

**貴智:**
就是由高科技公司來擔任 就是判斷什麼叫做仇恨言論 什麼叫做不正 什麼叫做加深刻板印象 因為仇恨言論之所以是仇恨 它是因為來自於這個 我們這個社群 已經普遍 已經可以認 大家都普遍認同 這樣子的言論 它是會 它會讓 它會讓大家 感覺到不舒服甚至會被冒犯 

[01:33:39 - 01:34:02] 

**貴智:**
那刻板印象的前提 是要有刻板印象 那誰來決定刻板印象是什麼 那這件事情如果讓 OpenAI來負這個責任的話 第一個並不公平 第二個也不恰當 因為OpenAI 第一個沒有能力去判斷 什麼叫做刻板印象 第二個是由他來決定 也很奇怪 現在活生生的例子 就是臉書在做這件事 臉書在 因為臉書被罵太久了 所以他現在被迫不情願的做這件事情 

[01:34:02 - 01:34:25] 

**貴智:**
那下場就是很多 很多其實 我們不認為不恰當的言論 反而被刪掉 所以在面對這個狀況 我覺得 我覺得這個責任 我覺得這個風險是存在的 就是AI它會造成歧視 跟偏見的擴大 但是它的解決方式 我覺得是我們 也許一時半刻還想不到 但目前我覺得 不適合的方式是讓科技公司來負擔這個責任 

[01:34:25 - 01:34:48] 

**貴智:**
那 那 那我覺得目前比較能夠 我如果要提供 OpenAI一些建議的話 我覺得比較合適的就會是 那OpenAI它有沒有可能 自己去判斷 它有沒有可能盡可能的 去判斷這樣子的一個言論 它是不是會對特定的族群 造成傷害 不好意思我再佔用一點時間 像我覺得編號第31 這個讓我覺得非常的有思考性 因為一般我們講 刻板印象的時候我的經驗是 

[01:34:48 - 01:35:11] 

**貴智:**
我是很少想到客家人 那我舉例好了 採茶唱山歌 這個對有一些客家人來說 他可能覺得 造成刻板印象 可是我相信 每一個族群 都需要有自己的特色 不然我客家人的特色是什麼 那到底如何分辨 客家人的特色 哪些是 哪些使用上客家人 不會覺得被冒犯 哪些客家人覺得會被冒犯 那這個區別到底未來要怎麼去討論 

[01:35:11 - 01:35:34] 

**貴智:**
我覺得它會是一個 超出我們今天的議題 

**Peter:**
感謝貴智 我們可能要依循 依循目前的發言順序 目前是戴瑜慧教授 然後再來是Nicole 奕成 RR 然後再來是冠汝 謝謝 

**戴瑜慧:**
謝謝 然後這個題目 第八題的確讓我也 很掙扎很久 那主要幾個理由 第一個現在各國或各個公司 

[01:35:34 - 01:35:57] 

**戴瑜慧:**
都在提出 AI倫理規範 code of conduct 然後裡面也很標準的 標準版標規 就是不要對弱勢族群 性少數族群 然後產生刻板印象 或仇恨言論 所以我們應該避免 這樣一個 code of conduct 把倫理規範 好像變成一個好像就寫在那邊 

[01:35:57 - 01:36:21] 

**戴瑜慧:**
然後 但是它有實際 起什麼作用嗎 那這是第一個原因 第二個是 因為我自己很喜歡看 政治talk show 那可能大家知道 美國的像daily show 像John Stuart 或Clobert 他們其實是非常非常厲害的而且是進步派 

[01:36:21 - 01:36:43] 

**戴瑜慧:**
progressive的菁英 那他們常常講的話 看起來就是很諷刺 然後很嘲弄 但是其實它是 在針對一些社會問題 在做批判 我的意思是說 文化產品很複雜 你很難說 它 它可能看起來是很粗暴的言論

[01:36:43 - 01:37:06] 

**戴瑜慧:**
但是它其實可能 是在點出一個問題 那川普也有可能講 女人是豬 那當然就是仇恨言論 可是它文化產品 就是很複雜 這是我第二個論點 所以你可以很簡單的 全部都forbid 禁止 但是可能只是滿足了 這些公司看起來很正當那第三個理由是 

[01:37:06 - 01:37:30] 

**戴瑜慧:**
我覺得第14點要很小心 什麼叫做遵守當地的規範 因為像中國 它現在在全球 在推動的就是中國模式 或者是說 各國要尊 全世界要尊重 當地的風俗民情 那各國要有各國的規範那也就是不要有

[01:37:30 - 01:37:53] 

**戴瑜慧:**
普世人權這樣子的概念 所以14題 其實要可能要很注意 很小心 好 謝謝教授 

**Peter:**
然後我們接下來換Nicole 然後再來是奕成 然後再來是RR 

**Nicole:**
好 謝謝 我個人的觀點就從剛剛一連串的討論 

[01:37:53 - 01:38:16] 

**Nicole:**
就剛好可以看得出來一件事情 就是說滿多的問題 如果你的答案只有0跟1 那就是一件非常大的disaster 那回過頭來看 GAI會產生的議題 如果我們從 剛剛那位朋友其實也有提到 我們從它會帶來什麼風險的角度來看這件事情的話 

[01:38:16 - 01:38:40] 

**Nicole:**
然後透過什麼樣風險的process 去回應這件事情 讓我們大家都知道 它幹了什麼事 那我要不要adapt它 我要不要相信它 我要不要怎麼樣 用這樣的觀點來看 可能某種程度可以讓 這些議題的 造成的social impact 某種程度可以降低 當然in the end 最後還是要去解決根本的問題 那如果我們來看說AI風險的定性的描述 

[01:38:40 - 01:39:03] 

**Nicole:**
通常它一般 如果你原來的那個data本身就有 歧視或偏見 那當然是一個議題 可是因為 如果我們今天要討論AI的話 它更大的問題是在於 它的風險在數據的bias 算法的不透明 還有它的這種 可能它自己最後就越來越智慧了 自主性越來越高 它在那個過程當中會產生不可控的 

[01:39:03 - 01:39:25] 

**Nicole:**
最後generated出來content的結果 那如果是這樣子的話 回過頭來看 以這樣子的一種風險定性的描述 我們應該要要求的 就會在於 它需要有透明度 需要有可解釋性 需要有公平性 需要有可追溯性 我去看說 它用什麼方法去把它導引出來 那如果是這樣的話 還要特別去看說其實它的風險管理 

[01:39:25 - 01:39:47] 

**Nicole:**
它不是單點 它是一個life cycle 就像我們今天處理資料治理 你的資料可能是 在不同的時間點進來的 那我要怎麼去看 你這個資料的有效性 效度等等 所以 如果我們在思考這個問題的時候 盡量讓它的算法 它的這個資料的來源 讓它的透明度 讓所有的人都知道說 OK好 那你就是這樣來的那我來看說 

[01:39:47 - 01:40:09] 

**Nicole:**
我要不要相信這件事情 那當然它fundamental違法 那當然就法律要去處理了 基本上 可能會降低某種程度的 的social impact 

**Peter:**
好的 下一個 歡迎奕成 

**周奕成:**
大家好 我是周奕成 我想我們 全世界的人都被 CHPT驚豔 然後也被它驚嚇 那驚嚇部分就是說發現說它 

[01:40:10 - 01:40:33] 

**周奕成:**
會做一些很奇怪的回應 那就我所知 現在連OpenAI 他們自己的專家 也不太清楚 這個 model 為什麼會 做這樣的 的回應 那那個是因為 現在的CHPT 它 就它的名字 它就已經講說 它是一個pre-trained model就是說它現在 

[01:40:33 - 01:40:56] 

**周奕成:**
是在一個海量的 這個資料 然後去 訓練出來的model 那當然如果說 接下來 像meta 他們的這個model 也 加入之後 那他們的文字資料 是來自 social media 那上面可能會有更多 更大量的歧視性的言論 

[01:40:56 - 01:41:19] 

**周奕成:**
那換言之 這些 如果說是 pre-trained model的話 那它 基本上會反映 它所看到的所有的資料 的 這些 它的 它的這個狀態 那但是我認為將來的這些 聊天機器人 或者說跟我們聊天的 

[01:41:20 - 01:41:43] 

**周奕成:**
AI 或者說回答我們問題的AI 它以後不會再是一個 pre-trained model 它將來會被tune 也就是說 它是會被再訓練 然後訓練成一個 我們不同的人 會 不同的去接受它 所以將來它可能會變成是 不同的族群或不同政治立場的人 

[01:41:43 - 01:42:05] 

**周奕成:**
那你會按照你的選擇 去選擇一個 chatbot 來跟你回答你的問題 那所以它 真正將來可能的發展 可能也不會很久 可能很快 這個發展會變成說 有點像我們在選擇 我們喜好的媒體平台 或者說 我們喜好的這些意見領袖那我跟他進行對話 

[01:42:05 - 01:42:28] 

**周奕成:**
那所以在我看來 最終 還是 行為者 因為行為者是人 就是說 我們去歧視別人 或我們去violate別人的權利 這個還是人 所以最終還是 這個實體世界的民主 這品質的問題 在我看來是這個樣子 

**Peter:**
好 謝謝 RR 然後RR發言之前就是我們剛剛有兩位

[01:42:28 - 01:42:51] 

**Peter:**
等一等 有劉昌德老師跟張正老師 剛剛進來了 那就是如果可以的話 就是 如果需要的話 可以參考一下 剛剛的影片 或者是剛剛的一些紀錄跟連結 好 那RR 

**RR:**
那我快速延續一下 剛剛整個一個討論 然後稍微一點延伸 然後就是說 我其實我個人 在提第八題的時候 我也跟我也寫是反對

[01:42:51 - 01:43:13] 

**RR:**
那我理由跟Ronny 跟冠汝一樣 就是其實除了學術研究以外 然後其實還有一部分原因 那就會像剛才戴老師提到了 可能在中國 就是我剛才剛剛講到 這個就是箝制的狀況 所以其實我沒有很同意 就是像那個阿甘或貴智 剛剛提到的 就是說確實我們都認為 資本企業不應該做 這樣子的一個價值判斷但政府能做這樣的價值判斷嗎 

[01:43:13 - 01:43:36] 

**RR:**
其實我也不覺得確定 就是就算有 然後有就算有 讓司法來做的話 那大家應該也可以想像 如果司法可以快速解決這個問題 那現在我們很多網路問題 就已經不存在了 但所以就是 其實根本的問題還是可能 就是回到剛一開始說是 可能還是要靠警語 這件事情去做 那這時候很關鍵就是 警語的內容是什麼然後同時很重要的是 

[01:43:36 - 01:44:00] 

**RR:**
哪些東西要加上警語 因為現在我們在討論的是 LGBTQ或者是就是脫口 或者是就是一些原住民 或者是客戶族群 但實際上的狀況可能是 還有其他內容 像德國的一些政治家 剛才那個案例 那這樣子到底哪一些 要寫回饋警語 哪些不要 我覺得是需要一個 公眾可以討論的回饋機制那剛才回饋的透明度 

[01:44:00 - 01:44:23] 

**RR:**
當然也是很重要的 對 

**Peter:**
好 那目前的話 現場還有誰 想要針對剛剛的討論 發表意見嗎 好 目前這邊有冠汝跟佑宇 然後 對 那就先冠汝 然後再來是佑宇 然後其實因為我們這一次 有找到一個題目可能是比較分歧的是 

[01:44:23 - 01:44:46] 

**Peter:**
第28個身為新住民 我希望不要總是跟勞工跟外勞 等這樣放在一起 不曉得等一下能不能夠邀請 譬如說 洪滿枝小姐能夠發表 針對你的 就是 相關的一些經驗 來發表意見 好 那貴智我看到你的舉手 感謝 那我們等一下會把它排到 排行順序當中 來 冠汝請 

**冠汝:**
好 我是想綜合講一下 

[01:44:46 - 01:45:10] 

**冠汝:**
我剛剛前面參加的討 聽 參加跟大家的討論 我覺得說 因為現在的題目其實 有一些涉及到內容審查 然後或者是管制 就我在附加一個警語 那我其實覺得在處理 歧視與偏見的時候 AI的部分要區分說 內容審查跟一個是辨識資料 

[01:45:10 - 01:45:33] 

**冠汝:**
本身的偏差 就是這兩件事情是 兩個途徑 那當然剛前面聽到大家 很多有分享說 我們其實也都不希望 Open AI變得像 我們現在的社群媒體 是它的審查是越來越 就是它一樣是用 AI在做審查啦 但它的審查密度變得越來越高這樣子 

[01:45:33 - 01:45:56] 

**冠汝:**
那所以我覺得在 又回到前面就是說 辨識資料本身 有沒有偏差的時候 其實對於資料 資料本身的抽樣 它當初在抽的 抽樣或者是取樣的 多元性夠不夠 我覺得也是會反映到 這些的問題 那有一個事情是 我覺得可能沒有到歧視與偏見 

[01:45:56 - 01:46:21] 

**冠汝:**
但我之前在看到 有一些 就是跟一些學生 合作的時候會看到說 我不確定他們是不是用 Open AI 但都是用生成式 生成式AI 然後幫忙協助整理 跟翻譯一些資料 縱程後來會發現說 它的語言 不是用我們台灣習慣的語言它就會很常見的把數位 

[01:46:21 - 01:46:45] 

**冠汝:**
然後寫成是數字 等等這類的 可能在語言取樣上不是 不是我們台灣平常習慣的 習慣的用語等等 這種多樣性缺乏的狀況 那另外也想回應說 剛剛提到說 企業可能沒有權利 或是義務去定義 什麼是歧視 什麼是偏見那我想回應這部分是說 

[01:46:45 - 01:47:09] 

**冠汝:**
但其實在聯合國 或是在很多企業之間 集結的團體 一直在形塑說 企業責任是非常重要的 那也有相關的人權指引 然後跟各 當然不是台灣 但有很多國家是在 due diligence

[01:47:09 - 01:47:31] 

**冠汝:**
其實這個是 這部分是越來越加強企業 必須去避免它的產品 未來可能產生的人權風險 所以我們也不能去迴避這一塊 

**Peter:**
好 謝謝 那目前的話線上slido 其實有一個提問是 我想詢問 我們國家已經選擇 OpenAI這家公司的軟體 與相對應的第三方工具作為國家發展的選項嗎 

[01:47:31 - 01:47:55] 

**Peter:**
這個答案的話應該是 所以Nicole這邊是表示說 好像中研院是 好 沒關係 那因為這個問題 他比較像是說 他想要問這一題 題目是在講AI公司 還是在講開放式的AI架構 那ChatGPT是 OpenAI的一個軟體還有很多的做AI的公司 

[01:47:55 - 01:48:18] 

**Peter:**
像是Meta Google 還有Twitter 還有很多在基礎面 做機器學習的公司 那他想問的問題是 我覺得這個問題 可能我主持人可以協助示意 就是他說 我們是想要討論 ChatGPT的部分的問題 還是整體面向的這個問題呢 那這樣子的話 就是我會覺得說 其實我們應該是討論 從剛剛的角度看起來我們應該不只是討論ChatGPT 

[01:48:18 - 01:48:41] 

**Peter:**
我們還有討論到 很多不同的整體面向 所以如果大家有任何疑問 或想要丟出來的 分享議題的話 都可以從整個整體面向 來加以討論 然後現在有另外一個意見是 總覺得這是假題目 因為民主流程 就是被投票的數字 哪個多就選哪一個 但是大多數人民並不了解 真正AI的過去現在與未來 要用這個題目作為主題 想要問問最後您希望獲得怎麼樣的結果 

[01:48:41 - 01:49:03] 

**Peter:**
如果大家都覺得 不適合用AI 用票數解決一切 那麼請問這個會議 能解決這樣子的問題 難道大家決定不要用 我們國家就不用吧 應該是不是這樣子的吧 這個可能會回到 我們這個會議 想要做整個V Taiwan的程序 或整個諮詢會議 想要做的目的 那作為整個團隊的參與者 我覺得我可以先 簡單回答這個部分就是我們希望透過 

[01:49:03 - 01:49:27] 

**Peter:**
我們這個會議 並不是單純的讓 現場的大家投票決定 我們要不要用AI 因為他的這個問題 決定要不要用AI 而是希望幫助大家 去提供更多有關 人工智慧相關的議題 然後同時能夠提出更多的討論 我相信就如同剛剛 就是現場的參與者Nicole提到的 就是整個問題 可能並不是0跟1的問題而是在0跟1之間 

[01:49:27 - 01:49:49] 

**Peter:**
我們能夠找到 更多可能性的問題 那我覺得這個會議的目的 某種程度上來講 他就是為了要找到 這個可能性而存在的 大概是這樣 那Nicole有想要補充剛剛的部分嗎 不好意思Nicole可以用一下麥克風 

**Nicole:**
這個可以參考啦 就是國科會有一個計畫 叫做Trustworthy AI Dialogue Engine簡稱TAIDE 

[01:49:49 - 01:50:12] 

**Nicole:**
我不知道怎麼念 TAIDE計畫 那大家如果有興趣 可以去Google這個新聞 大概是六七月的時候 他們用了三四個月的時間 宣布出來 包括陽交大林育杰教授等等 這個是國科會有支持的 

**Peter:**
好 那因為現在時間的關係 所以可能要看現場的參與者 有沒有想要再做意見的徵集那如果有的話 

[01:50:12 - 01:50:34] 

**Peter:**
我們可能就再開放最後一個 那如果沒有的話 就是我們會讓線上的參與者 看看還有沒有想要 做意見徵集的部分 如果有的話 可能麻煩現在舉手 那我們就會排入到 發言的順序當中 好 那現場的話 剛剛是貴智 好 那就是讓貴智發言因為剛你提到那個編號28 

[01:50:34 - 01:50:58] 

**貴智:**
我覺得編號28跟編號31 編號8都是滿有意思的議題 我覺得AI的 我分享我自己的想法 當然可以很多人不認同 我覺得AI 現在的這個AI 或者是之前演算法 它都是大數據的產物 所以我覺得 這些刻板印象的存在 是社會必須要 共同承認的一個現實但是解決這個刻板印象的方法 

[01:50:58 - 01:51:21] 

**貴智:**
是我們必須要去尋找的 那當然我完全認同 就是科技的發展 它會放大的問題的存在 但是直接從科技這段 認為解決了 讓科技不要做這件事情 讓chat gpt 不要講這些笑話 刻板印象就不會存在嗎 我覺得不是解方 所以我覺得 我剛剛會提到說 為什麼我覺得這個議題它超出了今天可以解決的範圍 

[01:51:21 - 01:51:44] 

**貴智:**
是因為我們要如何去解決 社會大眾的刻板印象 這件事情是需要 它是一個更高層次的問題 我為什麼會提到 它可能是國家層次的問題 我並不是認為國家 可以來決定刻板印象 可以來決定什麼是仇恨言論 而是國家應該要提供方法 讓我們社會的公眾 讓我們這個國家這個社群可以一起去討論 

[01:51:44 - 01:52:07] 

**貴智:**
哪一些刻板印象 是我們認為都要消除 哪一些仇恨言論 是我們認為應該要被禁止 有這個前提之後 科技公司再來配合 所以我覺得今天這個議題 會讓我覺得它超出 我們可以討論的範圍 這是我講的一個 這是一個原因 所以我倒覺得AI 如果要給OpenAI建議的話 我覺得我可以給的建議是因為OpenAI 

[01:52:07 - 01:52:30] 

**貴智:**
它已經擁有非常多數據 從這個數據 其實我們可以去找到 這些譬如說新住民 如果他總是會跟老公 外勞一起出現的話 其實我覺得OpenAI大數據 它都是讓我們找到 原來刻板印象 真實存在的一個 很重要的證據 因為刻板印象 常常很多人講了 但別人不相信 那我覺得 其實我對於這件事情是樂觀 所以我覺得這件事情我覺得OpenAI大數據 

[01:52:30 - 01:52:52] 

**貴智:**
它可以幫助我們證明 刻板印象它如何的存在 然後如何的 被出現在什麼地方 讓我們更有機會來解決它 但是解方 不應該有OpenAI來幫我們找 

**Peter:**
謝謝 因為時間的關係 我們可能要邁到下一個議題 如果大家針對歧視跟偏見這個議題 還有任何的想法的話都歡迎透過 

[01:52:52 - 01:53:16] 

**Peter:**
共筆的連結 還有slido的連結 來進行相關的補充 slido的連結是Vtaiwan0924 就是Vtaiwan 然後再加上今天的日期 英文字母的部分都是小寫 下一個議題 

**Erica:**
我們進到議題三 議題三是我們今天最後一個議題 其實有一些部分 也有包含到議題三 剛剛有提到的關於國家審查的制度 

[01:53:16 - 01:53:40] 

**Erica:**
或者是不同文化之間的宗教 或者是什麼的 到底該怎麼決定 那所以我稍微簡短summarize 所以議題三我們想要探討的就是 我們要怎麼樣建立 就是在同一個AI的系統底下 在不同的地區 是不是應該有不同的樣貌那要怎麼樣去取決這個界線 

[01:53:40 - 01:54:02] 

**Erica:**
在哪裡 那這個 因為我們現在是一個全球化的時代 所以不同國家之間的互動 我們要怎麼樣可以確保跨國界 它是要一致的嗎 還是不需要 那如果不需要 那為什麼不需要 或者是說是因為像剛剛有提到中國 

[01:54:02 - 01:54:26] 

**Erica:**
中國可能在人權方面 可能想法是跟其他國家不一樣的 或者是像少數族群 關於LGBTQ 可能不是每個國家的法律 也都是一樣的 那在這個議題上 我們應該可以怎麼樣 去更深入的討論 然後大家也可以想想 有沒有什麼樣的看法 然後針對我們我們這邊也選出了八個 

[01:54:26 - 01:54:49] 

**Erica:**
在這個議題三裡面的觀點 

**Peter:**
然後另外一個想要補充的是 就是從剛剛討論到 我覺得可能大家 有一些在座的參與者 或是線上的參與者可能誤解 就是我們今天並不是當作 OpenAI的顧問 來收集大家的意見 我們是作為一個社群 跟OpenAI互動 希望透過這樣的方式 透過社群的力量去影響OpenAI的決策 

[01:54:49 - 01:55:12] 

**Peter:**
所以跟兩個之間的差異性在於說 如果是過為顧問的話 我們是完全聽命於OpenAI 但是並不是 我們一直都在 不斷的討論的過程當中 做出大大小小跟OpenAI的反抗 那就是 所以就是試圖的去爭取 更多的空間 讓社群的聲音可以被參與進去 那以上是我們需要澄清的 好 那接下來我們就可以開始進行在地化的討論 

[01:55:15 - 01:55:37] 

**Peter:**
有 好 貴智率先舉手 那如果可以的話 其他參與者如果可以的話 也可以提出你們的意見 來 貴智請 

**貴智:**
我覺得在地化的這一題是重要的 不過我覺得這題是不是 其實相對比較簡單 因為在地化的我覺得 它就是要了解當地的脈絡 那假設如果OpenAI 它已經擁有非常大的資料庫 那接下來的話其實我覺得問題就會進入到 

[01:55:37 - 01:56:00] 

**貴智:**
那怎麼樣去讓這些資料 更符合這些當地使用者的需求 我覺得譬如說編號20來講 當我搜尋婚紗的時候 只生成西方的白紗 它有兩個層次 第一個層次是 它是不是擴大了西方文化的主流性 那第二個我覺得比較簡單層次是 它對於東方 非西 不要講東方 非西方使用者來說它就是個不好用的工具 

[01:56:00 - 01:56:23] 

**貴智:**
所以我覺得這件事情 從比較 從一個比較務實 或者是講一個比較 比較商業資本的角度出發 其實我覺得是不是 應該去考慮到使用者 他會希望獲得什麼樣的回饋 然後來去解決在地化這個問題 我覺得這樣子是不是某種程度上 可以先解決掉很大一部分 造成困擾 但是如果上升到人權和道德倫理判斷的時候 

[01:56:23 - 01:56:46] 

**貴智:**
我覺得它相對就會比較困難 因為人權及 人權議題它有一個普世性的 有一個普世性的概念 所以很多人權議題 它必須要有一致性 在世界各地都要一樣 但是這些一致性的答 這些一致性的概念 它如何讓世界各國 不同文化的人都能夠接受 我覺得這件事情又超出了一個 是不是又可能它又超出了chat gpt

[01:56:46 - 01:57:09] 

**貴智:**
或者是OpenAI它的能力 這是我目前的困惑 到底要怎麼樣去 在人權議題上 去符合各地文化宗教脈絡 甚至是OpenAI 它適不適合直接去批評 這個宗教這個文化 這個習慣有侵害人權 我覺得這件事情是非常敏感的 所以我倒覺得 這個是一個 比較困難的層次的問題 

**Peter:**
好 感謝貴智

[01:57:09 - 01:57:31] 

**Peter:**
可以順便補充一下 其實就算是連OpenAI 這麼龐大的公司 他們其實在取得在地化資料上 也會有一些困難 因為像我們這一次 參與專案的計畫的時候 其實我們也會有機會去參與 OpenAI他們舉辦的一些講座的活動 事實上在之前 應該是上上週五的時候 我參與OpenAI的一個講座活動 它其實就有提到一件事情是OpenAI他們有在做 

[01:57:31 - 01:57:55] 

**Peter:**
各個語言模型當中 他們所反映的一個政治的立場 是如何的 但他們的語言模型的相關的資料 其實都是來自於皮尤研究中心 還有一些大型民調公司 對於美國的民眾所做的意見 其實在問答的環節的時候 我就有問說 為什麼你們只做美國的東西 他們其實就回答說 很簡單 因為他們找不到 其他國家可能比較可信的一些民調的資料來作為 

[01:57:55 - 01:58:19] 

**Peter:**
他們複製這個研究的一個方法 他們其實也有在努力的爭取 相關的資源在做 所以其實可以知道的事情是 就算大型如OpenAI的公司 它也不算很大型 它就是一個新創公司 但我的意思是 開發人工智慧的公司 可能都會多少遇到 這樣子一個在地化的困境 這個是可以補充給大家知道的 目前還有其他的人目前阿甘有想要發言 

[01:58:20 - 01:58:43] 

**Peter:**
那阿甘 那再來的話看有沒有其他的 OK 好 沒問題 阿甘再來是Teemo 

**阿甘:**
不好意思 我還是想釐清一下 這邊的倫理規範是指說 我們給了建議之後 OpenAI未來作為它的產品的 倫理規範還是指 它所生成的內容 然後在各地的倫理規範譬如說在亞洲地區 

[01:58:43 - 01:59:06] 

**阿甘:**
甚至在台灣地區 然後在南美 北美的那個倫理規範 我有點搞不太清楚 那個倫理規範到底是 規範對象是誰 

**Peter:**
倫理規範 應該說這邊它 這邊的倫理規範 它的意思是這些議題 是比較跟就是AI的在地化 還有倫理規範的內容相關的 所以我們把它歸類到這個集合裡面 但不代表說這邊的討論只會回饋給 

[01:59:06 - 01:59:28] 

**Peter:**
就是認為說 讓OpenAI來作為一個 他們設置倫理規範的一個參考 只是它的議題的標籤是 我們是 我們把它分類的方式 是透過這樣的方式來分類 這樣希望有解答到你的疑惑 

**阿甘:**
好 那沒關係 那我們開始說一下 就是我剛才同意 那個剛才貴智說 我覺得這個左邊跟右邊 其實是不同層次的問題那如果說針對人權 

[01:59:29 - 01:59:52] 

**阿甘:**
像幾乎類似58題 這類的議題 我幾乎都是選拒絕回答 拒絕回答不是因為我覺得 OpenAI應不應該做這個判斷 等等那些 而是其實 你會發現說 如果說要 我們都強調在地化 在地脈絡是重要的 可是你又擔心說 當過度在地化的時候 對某一些也會變成造成同溫層過高 

[01:59:52 - 02:00:14] 

**阿甘:**
那變成是 你完全聽不到別的地方的聲音這樣 所以其實是 我覺得因為也回應剛才主持人 一開始說有一些問題 大部分人拒絕回答 其實我通常拒絕回答 都是因為 我覺得太複雜 沒有辦法用這樣的幾句話來表達 謝謝 

**Peter:**
是 感謝 那剛剛看到的是Teemo 有想要回應 剛剛前幾位參與者的意見 請好 
[02:00:16 - 02:00:40] 

**Teemo:**
我希望 我在這邊希望 OpenAI可以把他的moderation 就是他的內容仲裁 開放民主化 讓大家可以直接 建立自己的機制 就像台灣的BBS 自己建立自己的版規 自己決定版規的內容 如何限制這個看板調整所以有自己版上面的規範 

[02:00:40 - 02:01:03] 

**Teemo:**
建立出自己的次文化 如何去規範 以我的理解 身為一個LGBTQ 然後又是客家人 然後勞工這樣子 我覺得 我覺得如果在婚姻平權 前十年 有這個OpenAI 他可以去推特上面 告訴我說 這兩個人是情侶關係我非常的崩潰 

[02:01:03 - 02:01:25] 

**Teemo:**
OpenAI出來之後 立刻告訴整個社群 這樣子使用會有危險 所以 當他如果可以告訴我們 推特上面 兩個人有情侶關係的時候 如果這個事情是發生在 婚姻平權後的十年 我覺得沒什麼問題 你知道嗎 就是因為時代已經 隨著那個時間流動 

[02:01:25 - 02:01:47] 

**Teemo:**
他已經有所改變了 現在我們餵進去的資料 他有沒有與時俱進的改變 我真的很好奇 所以這個倫理規範跟在地化 實際上某個時間點 可能是不適用的 但未來的某一天 可能會適用 所以我希望他開放 開放內容仲裁的這一層 是民主化然後可以調整的 

[02:01:47 - 02:02:09] 

**Teemo:**
然後開放社群 參與民主化的過程 

**Peter:**
Teemo提到了一個 就是為什麼要採取 民主化的方式 來治理倫理規範的原因 可能是因為時間點 然後各地的時間點 可能都不一樣 也因此不適合用一個 可能相關的方式 來做一個一致性的規範 那還有誰想要針對剛剛前面參與者 

[02:02:09 - 02:02:33] 

**Peter:**
提出來的看法 表達相關的意見的嗎 有嗎 我剛剛看到 好 RR又舉手了 

**RR:**
我要先澄清 我對議題二跟議題三 這樣子的分野 跟定義題目 我覺得很好沒有問題 但是對我來說 解決方案的話 可能議題二三並不會有太強烈的差異 

[02:02:33 - 02:02:56] 

**RR:**
他們只是在 處於不同的面向 但我覺得根本的思維 應該理論上是一樣的 因為其實有時候 歧視跟在地化這件事情 可能有些人覺得 是同一件事情 對 然後 所以我覺得可能 處理的方式可以參考 就是剛才之前 大家的討論 然後或者是另外就是說 可能像這樣 OpenAI大型 想要面對全球市場的廠商他就可以去設 

[02:02:56 - 02:03:18] 

**RR:**
就是那種開關 就是我想要一個 符合在地化的 一個顯示方式 例如說我現在在台灣 或是他自己指定地點 或指定文化 然後這樣子去做處理 

**Peter:**
好 RR提出來 或許可以透過選擇的方式 讓使用者自行去選擇 他要觀察到 比較在地化的內容 還是沒有那麼在地化的 一個內容這樣子那不曉得 

[02:03:18 - 02:03:42] 

**Peter:**
還有其他的使用 參與者 或者是線上的參與者 有想要針對 剛剛提出來的意見 去進行回覆 或是想要針對這邊 呈現出來的這個議題 面向來進行回覆的嗎 如果沒有的話 可能我就會想要 偷偷的用一下主持人的資訊 就是稍微的想要去 Push一下一些 剛剛沒有發言過的參與者或還沒有機會發言的參與者 

[02:03:42 - 02:04:05] 

**Peter:**
讓他們就是 表達他們的看法喔 有嗎 有 那如果沒有的話 可能 看一下喔 那如果可以的話 我想要問問看 就是像是劉昌德老師 劉昌德教授 或者是張正老師對於這個議題的意見是什麼 

[02:04:05 - 02:04:29] 

**Peter:**
因為分別是來自於 譬如說像是科技傳媒等等 或者是新移民等等相關的一些 相關的背景 所以想說可以 如果可以的話 我們也非常希望 能夠聽到你們相關的意見 那 

**劉昌德:**
我不知道有沒有進入到討論脈絡 不過因為剛剛有聽到 應該是Teemo說的關於在地化倫理規範的 

[02:04:29 - 02:04:51] 

**劉昌德:**
一個行程過程的 這樣的一個 民主化的這個原則 我覺得我個人是贊成這個原則 那我現在想要提出的 可能會是在這個操作上面的 一個困難 也就是說去想像 PTT當時行程的過程 其實跟現在 跟OpenAI要做這個比方說語言生成模型 

[02:04:51 - 02:05:14] 

**劉昌德:**
這一些 大型的這樣跨國的一個做法 我覺得會相當的不同 它大概沒有機會 讓我們是一個小小的社群 慢慢去衍生出 它希望出現的 這一個次文化的版規 舉例來說 如果我們現在講 就是說這上面在講比方說中國的Chat GPT 

[02:05:14 - 02:05:37] 

**劉昌德:**
它可能有一些關鍵字 是當地的人 認為可以或不可以討論的 那如果過去的PPT 我覺得PTT可能 它相對是一個草根由下往上的 但是當如果我現在在中國 我只是想像 其實台灣我覺得 也會有類似的狀況就是當我們要決定 

[02:05:37 - 02:06:00] 

**劉昌德:**
這個語言模型 有一些東西 可不可以出現的時候 可能會有太多 不同的大型的力量 不管政治或資本 會進來干擾 它不是一個草根的文化 慢慢生成的過程 要讓這一群人來決定 而這一群人相對又 意志又大的時候 好像在這個部分 我覺得會有一點點小小的困難 給大家做參考 謝謝好 感謝 

[02:06:00 - 02:06:23] 

**Peter:**
那 老師不好意思 麥克風這邊 請用那個無線麥克風 

**張正:**
不好意思 我跟昌德遲到 所以不見得進得去了 我剛剛只是 那個議題二的 剛剛最後一個講 新住民那個 其實我是有點感想 因為那個我也不知道誰寫的就希望新住民 

[02:06:23 - 02:06:45] 

**張正:**
不要跟外勞 勞工放在一起 這很像我之前在看一本書 在談華工 在南非的華工 他們的抗議是說 不要把我跟黑人放在一起 因為就是在對白人說話 說不要把我們跟黑人放在一起 我們是不一樣的 其實大家都可能是被歧視 可是我剛剛前面聽到的 是比如像貴智說的我就覺得還 

[02:06:46 - 02:07:08] 

**張正:**
就很有道理 就是這個東西 可能不是 就是它其實是反映實況 我覺得貴智剛剛講的很聰明 就是因為這個實況 反而可以證明了這個歧視 或者分類的存在 然後從這個上面往下推 就是應該可以怎麼改那我當然也不太知道 

[02:07:08 - 02:07:32] 

**張正:**
OpenAI有多大的能量 要做這個事 那其實光是OpenAI 或GPT這樣子的功能 它應該本身就有一些 自己的宗旨 那今天可能收集大家的意見 但是有沒有可能聽起來好像是要收集大家的意見 

[02:07:32 - 02:07:54] 

**張正:**
再來做事 可是我相信主辦的人 或者現在流行叫主理人 可能他有自己的意見 我還蠻樂觀其成的 我覺得就看他怎麼往前推 那也相信他們 也不能隨便相信 我樂觀的覺得應該還可以謝謝 

[02:07:54 - 02:08:18] 

**Peter:**
好的 感覺張正老師是一個 比較樂觀 偏向樂觀的一個 就是看法的人 那關於議題三的部分 還有什麼想要回應的嗎 目前看起來申翰有想要回應的 

**洪申翰:**
我其實非常同意 其實議題二跟議題三 我認為它有一個本質相同的邏輯 

[02:08:18 - 02:08:42] 

**洪申翰:**
因為它處理的都是 你一個產生過程裡面 會出現一個比較霸權 或主流的事情 我覺得是相同的邏輯 但說實話 我對於要讓一個科技工具 去做價值判斷這件事情 我真的是比較保留的 或者是我不傾向 當我們遇到問題時候第一個時間優先的做法 

[02:08:42 - 02:09:05] 

**洪申翰:**
是讓科技公司去做價值判斷 我覺得這會衍生非常多的風險 那剛剛大家舉Meta的例子 是其中一個例子 我認為這個例子 要舉起來的話還是很多 那現在當然會看說 到底怎麼理解這個AI有些人理解這個AI 

[02:09:05 - 02:09:29] 

**洪申翰:**
會是各種社會現實的 某一種濃縮或者投射或放大 這是一種理解 還是說它其實會出現某一種質變 當然這部分我可能也想請教 更多的技術工作者 它未來有沒有可能會產生某一種 其實一個東西在這裡面 它真的會轉化出去而不是只是一種放大投射的概念 

[02:09:29 - 02:09:52] 

**洪申翰:**
這個事情我沒有各位了解 可是我覺得說 我還是要說 我確實不傾向在這裡面做一些 尤其透過技術公司的篩選 它最後會出現的Bias 我覺得反而會更大 甚至會離我們原本期待的 某一種民主更遠某一種更原則上的民主更遠 

[02:09:52 - 02:10:15] 

**洪申翰:**
這是我會擔心的事情 

**Peter:**
在繼續排定發言之前 想要來補充一個 就是剛剛線上參與者 提出來的一個意見 提出者他有具名 叫慧穎 然後他提出說 我認為28題所呈現的歧視 並不來自於AI 而是來自於留言者留言者認為新住民等於外勞跟勞工 

[02:10:15 - 02:10:37] 

**Peter:**
並說AI不應加深刻板印象 但他的言論卻在歧視另一個群體 雖然新住民在台灣所使用的 用語多於稱呼婚姻移民 但是新住民是一個複雜的概念 移工跟外籍學生 事實上也是台灣的新住民 Open AI的Data會需要更細緻在地化與完整 

[02:10:37 - 02:11:06] 

**Peter:**
這個是來自於線上參與者 放到slido的意見上 所提供的一個意見 不好意思 您好 您好 不好意思 對 對 對 好 那您有想要再用麥克風 補充意見嗎 OK 好 謝謝 還有其他 不好意思 請

**戴瑜慧:**
就是我們可能要避免 

[02:11:06 - 02:11:29] 

**戴瑜慧:**
把新住民或是某個族群都同質化 譬如說像我以前跟遊民一起工作 有的人就會很強調說 我們也很乾淨 不是說大家都髒兮兮的 但是其實裡面有很複雜的 內在的心理機制 因為這整個社會就是一直在污名化這個族群 

[02:11:29 - 02:11:51] 

**戴瑜慧:**
所以其實裡面有一些遊民 他會很想要去融入主流社會 所以他會強調 我也是很乾淨的等等 就很像有些同志 以前在爭取權利的時候會說 我們也有納稅 那為什麼我們沒有這個權利 可是其實同志裡面也有有錢的跟沒有錢的 

[02:11:51 - 02:12:13] 

**戴瑜慧:**
有階級差距 所以再回到我們的第三個議題 就是共同的一個 你說所謂的在地化 其實裡面牽涉到全球化 然後各個國族 各個國家的法律規範 還有各個社群 那可是社群他又不是統一的 

[02:12:13 - 02:12:36] 

**戴瑜慧:**
同樣同質的概念 那也有不同的意見 那所以 那假設各個國家裡面 他可能對同志 他是認為是非法的 那所以他尊重在地的話 他就是說 這個同志的法令是非法的嗎 等等所以可能就要回到 

[02:12:36 - 02:13:00] 

**戴瑜慧:**
我們對普世人權的討論 那第五題這個部分 就是呼應昌德老師剛剛講的 就是我們大概都知道 中國政府有建立一個 很有名的防火長城 所以其實那個前提是 你這些跨國公司 你要進去營業的話你要先接受他的審查體系 

[02:13:00 - 02:13:22] 

**戴瑜慧:**
他的系統 那你才能夠進去 而其實根本就輪不到 中國的公民去做這個權利 他有沒有排那個keyword的權利 所以就是說 我們可能要小心個體 個人的權利有這麼的大嗎 

**Peter:**
好謝謝那還有其他的參與者

[02:13:22 - 02:13:46] 

**Peter:**
是想要針對這個部分來發言嗎 剛剛看到PBS好像有 一直在皺眉頭 想要發表意見的感覺 

**PBS:**
好 我其實剛剛一直在思考 因為作為一個在 好我這樣講好了 在Chat GPT出來以後 其實台灣不論是 我忘記台智雲還是怎麼樣然後有一些科技公司 

[02:13:46 - 02:14:08] 

**PBS:**
他們也推出了一個企業版的 他們所謂稱為台版的Chat GPT 然後在企業端大家都講 因為其實台灣的硬體滿厲害的 他們就會說 台灣的硬體撐得起這樣的軟體 但其實看著這群人 這群開發的人 然後跟他們相處的過程 我其實是打了一個滿大的問號 因為其實在這個產業裡面在看他們開發的時候 

[02:14:08 - 02:14:31] 

**PBS:**
滿明確的可以感覺到 他們其實是對於相關的東西 不是那麼有sense的 所以當我們今天在討論人權 或者是其實大家剛剛有提到說 公民或者是使用者 是否有決定權 可以來去參與這個過程 他跟現實當中 其實是有一個滿大的gap 我不得不說 所以我覺得這個gap是可能有點超出議題 

[02:14:31 - 02:14:53] 

**PBS:**
這個議題本身的框架 就是框架是說 我們該不該有這樣的 engagement在裡面 我覺得改一改 但是現實層面來說 它還是有實行上的困難 但這部分的話 如何去把它辦到 可能就是下一步 大家可以做的事情 謝謝

**Peter:**
現場或線上的參與者 

[02:14:53 - 02:15:18] 

**Peter:**
有什麼想要表達意見的嗎 線上的參與者 如果有任何想要表達意見的話 都歡迎直接舉手 然後我們就會讓您發言 因為剛剛一直都沒有聽到 就是舉手的聲音 所以目前的話 就是好像還沒有聽到 來自線上參與者的發言 不過如果有任何 想要發表的意見 或是針對剛剛討論的內容 有任何看法的話 都歡迎直接提出來 那現場的話針對剛剛不管是PBS 

[02:15:18 - 02:15:40] 

**Peter:**
或者是針對其他的參與者 所提出來的 關於在地化的意見 還有誰想要針對 這樣子的意見去進行分享 或分享你的想法或意見的嗎 好 如果沒有的話 那我們今天的活動差不多就會來到 

[02:15:40 - 02:16:04] 

**Peter:**
比較最後的一個階段 就會是一個主持人的 總結的部分 然後在主持人總結的部分 其實因為說實在 其實總結花不了15分鐘 這麼長的時間 所以其實我還蠻希望 能夠讓剛剛沒有發言過的參與者 可以在這個最後的階段 有一個發言的機會的所以我剛剛注意了一下 

[02:16:04 - 02:16:26] 

**Peter:**
現場可能沒有發言過的參與者 包含就是YY 然後不曉得會不會從您開始 就是大概發表一下 不管是整體的意見等等都可以 

**YY:**
大家好 因為其實我上禮拜三 禮拜四左右 在我的業務裡面 就是在整理一些資料 那其實我現在個人也在一種矛盾跟複雜當中 

[02:16:26 - 02:16:49] 

**YY:**
因為就像剛剛提到 不管是個資倫理 或者是一些偏見上面的問題 一開始我的想法也是 那既然不敢碰 那我們就提供一些客觀的 一些量化的分析數據 可是這過了三分鐘之後 我就自己在想 這某種程度在限制 AI上面的一個發展你如果只是做資料分析 

[02:16:49 - 02:17:11] 

**YY:**
那現在很多工具早就能做了 我的AI不需要再發展下去 所以如果我們在一些議題上面 先做人的一些主觀的定義跟限制的話 那這個AI的發展上面 我個人是有一點矛盾 因為其實我剛剛自我介紹自我介紹就提到 

[02:17:11 - 02:17:34] 

**YY:**
我其實是樂見AI 對於整個人類發展的效能上面 或者是效率上面的提升 所以對於太多的限制 我個人是有一些矛盾在 那所以像剛剛在提的 不管是個資或者是限制上面的話 剛剛大家討論的時候 其實我突然在想 大家都在講不同切面的東西 像一開始有人在講說我可能是個資的訓練 

[02:17:34 - 02:17:57] 

**YY:**
是用在所謂的一個訓練階段 有人在使用階段 或是說我的個資在保護上面 去符合個資法 或是說我有遺忘權 這是在不同切面上面 在大家的一個討論 所以我在想像這樣的一個討論 可能要切得更細 或不同層面去討論 不然像這樣分散 是我自己也在想說我就算也要發表言論 

[02:17:57 - 02:18:19] 

**YY:**
我自己都講不出來 因為我自己在矛盾 我自己的腦袋都在矛盾當中 謝謝 

**Peter:**
感謝YY提出來的意見 那接下來的話 目前看起來 如果是第二排的話 Jenny 看有沒有辦法Vanessa 

[02:18:19 - 02:18:42] 

**Peter:**
你對今天的會議 或今天的活動有什麼看法 或是你對AI的問題 像是地區化 或者是歧視 或是保護個人資訊和數據 我想你可以把你的看法寫在英文 

[02:18:42 - 02:19:05] 

**Peter:**
我們會嘗試翻譯 當我們實際上錄製的時候 好的 

**Vaness:**
我認為 我看到很多可能性和可能性 例如國際交流 和國際理解但是我也很擔心 

[02:19:05 - 02:19:29] 

**Vaness:**
如何能夠讓小的群體 有少量數據 可以展示出來 還有文化 是一個非常複雜的題材 有很多層次 如何能夠實現例如如果我的夢想實現了 

[02:19:29 - 02:19:52] 

**Vaness:**
我能夠自動地 通過翻譯軟件 那麼誰會決定 如何傳遞給我的文化層次 所以我覺得 我沒有答案只是有很多問題 

[02:19:56 - 02:20:19] 

**Peter:**
好的 謝謝 下一位可能沒有發表過意見的是 洪滿枝小姐 有想要發表嗎 不好意思 

**洪滿枝:**
對 好像我的想法跟剛剛慧穎所發表的 
[02:20:19 - 02:20:47] 

**洪滿枝:**
跟前面那一位的是類似的 所以我就覺得 我不用再重複一次 

**Peter:**
好的 謝謝 那 我看一下 再來的話可能是 Mariko 謝謝有什麼意見嗎 

[02:20:47 - 02:21:15] 

**Mariko:**
謝謝 不好意思 我突然參加了這個會議 不好意思 因為我台語不太懂 所以不太懂討論的內容 但是大家非常認真地討論 沒關係 謝謝謝謝 

[02:21:16 - 02:21:45] 

**Peter:**
那麼日本的朋友們 一起 不好意思 謝謝 那麼謝謝 

[02:21:45 - 02:22:09] 

**unnamed Japanese Participant1:**
不好意思 不好意思 我也是來自東京的 我叫竹中 剛好來到這裡 我們現在正在調查 台灣相當海島 VTaiwan 

**unnamed Japanese Participant2:**
剛好來到這裡知道這是VTaiwan的論議一角 
[02:22:09 - 02:22:31] 

**unnamed Japanese Participant2:**
讓我非常感動 非常感興趣地聽了 非常感謝 謝謝 

**Peter:**
那再來的話 算那位戴眼鏡 黃衣服 對對對 可以自我介紹 因為你好像比較晚進來 

**智原:**
我比較晚來 我是智原那我目前是台大城鄉所研究生 

[02:22:31 - 02:22:57] 

**智原:**
就台大城鄉所 那我比較跟 跟這塊議題可能多多少少 有點差別 但是剛我比較晚來 但是我在思考其實就是 重新 就是我大概中途到後面才加入 對 不好意思 然後但主要在理解一些 就是我其實在想的是 我們想要它做什麼 就是 這個東西是反映反映著這個社會現在的狀況 

[02:22:57 - 02:23:19] 

**智原:**
但其實在很久以前的 任何新媒體剛出來的時候 其實都會有一次差不多的討論 那我只在想 我還沒有很完整的想法 只會覺得 像剛看到那個 關於西方白沙的生成這件事情 就是我們當然會期待 會有更多元的 就是想說關注一個 很邊緣的各種東西但是我會很希望 

[02:23:19 - 02:23:41] 

**智原:**
各種其他東西被看到 但是在市場上就是 這件事情還是會繼續發生 那我們要在什麼程度上 去干預這件事情 就是我剛在思考的事情 感謝大家 

**Peter:**
好的 謝謝智原 那智原旁邊那一位女士 不好意思 好像剛也沒有太多發言的機會 來 麻煩你

**Sophie:**
大家好 我是Sophie 

[02:23:41 - 02:24:03] 

**Sophie:**
那我跳脫這三個一個總結 我的感想就是說 GPT好像那個 神隱少女裡面的那個泥巴人 有沒有 就吃進去很多東西 然後受全人類使用者 一直在餵養 那它會長成什麼樣子 是來自於我們餵養的內容那在這個平台生成的階段當中 

[02:24:03 - 02:24:25] 

**Sophie:**
我們每個人都是貢獻者 也是使用者 也可能是被潛在的 被侵害人 所以在這個過程中 我想我們也應該要去探討 確實GPT 作為一個平台的責任是什麼 那像今天的這樣的場合很好 我們有一個徵求意見的管道 那是不是平台 它自己本身也應該要建立一個對公眾開放 

[02:24:25 - 02:24:48] 

**Sophie:**
徵集意見的管道 讓我們把我們認為的 普世價值 或是在地文化 或是不適合的倫理規範 或是我們希望 未來的人類 可以如何更好的一些想法 可以透過一個平台 公開的一個窗口 我們可以輸入進去 所以平台的責任還有它擁抱大眾的意見的這個機制 

[02:24:48 - 02:25:11] 

**Sophie:**
也應該被要求被建立 以上 謝謝 謝謝 

**Peter:**
那目前看來現場的 應該都至少讓現場的大家 有一次的發言機會 那我們想要 這時候想要問一下 線上的朋友 關於今天的會議 不曉得能不能夠邀請線上的 像是Sanya 政翔等等 尤其像政翔今天 好像還沒有針對議程還有Wendy 

[02:25:11 - 02:25:33] 

**Peter:**
也沒有針對議程的部分 進行討論 所以想說可以的話 是否能夠邀請你們 在線上發表你們的意見呢 謝謝 那第一個不曉得 方不方便邀請政翔發表意見 政翔 如果政翔不太方便的好 

[02:25:34 - 02:25:58] 

**Peter:**
那Sanya 不好意思 方便邀請您嗎 好喔 

**Sanya:**
因為其實我們自己 也有偷偷在Meet的聊天視窗 有稍微分享一些想法 因為今天真的 大家提出來的想法 都是讓我們 好像真的還可以再多想一些 所以一時間真的 比較不容易整理出一套 有條理的說法那我個人覺得這一場會議 

[02:25:58 - 02:26:20] 

**Sanya:**
就是可以讓我們激發 很多想法以後 才會發現說 原來很多事情 還可以這麼去想 因為我們有時候 太習以為常的想法 會讓我們限縮想像 那就跟我本身 在參與勞權運動一樣 我們有時候就是 有跟不同的人交換想法 像甚至有些朋友 才會想到說原來我是可以準時下班的 

[02:26:20 - 02:26:43] 

**Sanya:**
類似這樣子的一個驚覺 那我覺得在今天的 這一個場域裡面 我們就是有各種 這樣子的激盪 那當然就是激發出來的 這些問題 我們都不可能在線上 或者就是短時間內處理掉 那我相信說 今天大家都有 這樣的一個種子 在心裡的時候都是會讓未來的AI發展 

[02:26:43 - 02:27:09] 

**Sanya:**
有一個 讓我們有一個 更好的方向 這是我個人今天的心得 那謝謝 

**Peter:**
謝謝Sanya 那不曉得方便請Wendy或政翔 分享你們的想法或看法嗎 Wendy方便嗎 還是政翔現在可以了呢好 
[02:27:09 - 02:27:33] 

**Peter:**
Wendy不好意思請 好 

**Wendy:**
不好意思 我這邊就簡單分享一下 個人的想法 就是現在的 不管是 chat GPT 或者是其他的大型語言模型 那使用的相關的資料 其實都是用 之前 就是 不管是在網路上或者是在哪裡所取得到的 

[02:27:33 - 02:27:56] 

**Wendy:**
公開的資料 來進行相關的訓練 那但是在 就是自從去年底 OpenAI Chair GBT 就是這樣子的一個 爆發性成長性的一個發展之後 那實際上其實越來越多人關注 就是生成出來的內容 是不是有符合大家的期待或者是各種價值的包容 

[02:27:56 - 02:28:21] 

**Wendy:**
跟包含的這些內容在內 那我認為像類似今天這樣子的一個 公眾參與的討論的一個模式 或者甚至 未來可能大型的這個語言模型的開發公司 也可以建立類似像這樣子的一個 參與的這個意見導入 跟資料蒐集的一個 價值取捨的內容然後可以反饋到這些大型語言模型公司 

[02:28:21 - 02:28:44] 

**Wendy:**
裡面來做接下來訓練 就是大型語言模型之後 可以遵循的一些方向跟準則 那我相信可能在 就是接下來生成是AI的發展上 就是不會是以這個資本主義 或商業主義為主的一個開發方向 那也會漸漸的就是 會也不一定說漸漸我應該是說期待 

[02:28:44 - 02:29:07] 
**Wendy:**
就是未來的這個發展可以更加的平衡 謝謝 

**Peter:**
謝謝Wendy 那不曉得最後政翔方不方便分享呢 

**政翔:**
好這樣子有聲音嗎 有的有聽到非常清楚 就是很感謝就是家偉 就舉辦這個活動那中間大家也分享了很多議題 

[02:29:07 - 02:29:31] 

**政翔:**
那的確是很多東西是需要大家在 尤其是我 我們司改會這邊也會需要再思考的地方 就很感謝大家今天提供了 大家這麼多意見這樣謝謝 

**Peter:**
好謝謝政翔 然後也同時順便講一下 就是其實剛剛政翔講說是家偉舉辦 但並不是我舉辦是我跟V Taiwan的社群參與者 

[02:29:31 - 02:29:53] 

**Peter:**
以及現場所有工作人員一起舉辦的 那不管今天從現場的整個動線的引導 乃至於報導 甚至是剛剛的計時 還有就是線上議程助理們的 就是協助的就是做意見整理 還有攝影師的幫大家拍攝 美美的照片 還有的主持人夥伴 還有就是幫我們做攝影還有直播的幕後人員 

[02:29:53 - 02:30:15] 

**Peter:**
任祥跟他的夥伴 其實都辦在這個活動當中 扮演非常重要的角色 那這其實也是V Taiwan的精神 就是任何人在V Taiwan的整個流程當中 不論你是在什麼樣的位置 不論你是坐在觀眾席 來提供相關參與者的意見 或者是用線上參與的方式 遠端跟我們同在 甚至是在現場協助整個流程的進行大家都是整個流程進行當中 

[02:30:15 - 02:30:39] 

**Peter:**
非常重要的一份子 那我也希望在此 稍微借用一下 自己作為主持人的一個權利來感謝 然後也希望大家可以幫我們鼓掌 來感謝一下 今天參與的每一個工作人員 謝謝大家 好 那我覺得這個 其實蠻適合作為今天的總結 那今天提出來其實蠻多的意見 然後也有很多意見 他值得進一步的發掘 但可惜因為我們並不是一個馬拉松式的討論 

[02:30:39 - 02:31:02] 

**Peter:**
我們並不像就是 我們並不要在今天 就得出一個很肯定的答案 但我們希望今天的相關的討論 在被匯集下來的時候 能夠持續的在其他地方被發酵 然後甚至能夠進行後續的討論 那如果有興趣的話 在這邊也想要再趁機廣告宣傳一下 就是如果有興趣的話 都歡迎掃描那個比較小的QR Code 因為V Taiwan之後可能還會辦其他的意見徵集 

[02:31:02 - 02:31:25] 

**Peter:**
或者是相關的諮詢會議的活動 如果想要持續收到V Taiwan的相關訊息的話 也都歡迎透過這樣的QR Code連結 然後來報名參與 那當然如果你希望 直接的跟社群參與的討論的話 我們也非常歡迎您 就是透過G0V臨時政府的Slack 然後加入之後 我們會在V Taiwan的頻道上 做很多的討論 那事實上今天的活動還有整個專案的活動的共筆

[02:31:25 - 02:31:47] 

**Peter:**
全部都是公開透明 除了有涉及到隱私資料的內容之外 基本上全部都是公開透明 也都有提出討論的人跟相關的Credit 所以非常感謝大家今天的參與 那我們今天活動到這邊告一段落 剩下的時間就歡迎大家可以自由交流 謝謝大家在離開之前可能還要提出 

[02:31:47 - 02:32:10] 

**Peter:**
就是看一下 最後一個匿名的提問 就是包含說 就是其實有很多歧視上的問題 它其實可能都已經夠 就是超出台灣的架構 而是說在國際現實環境底下 在OpenAI這種大型語言模型當中 台灣的聲音一樣被壓制 那在此狀況之下 可能要討論的是 台灣要如何就是突破目前的困境讓OpenAI這些大型公司 

[02:32:10 - 02:32:34] 

**Peter:**
能夠讓使用台灣文化界新住民 還有大多數台灣人民 所相信的資料跟數據 這個的確是我們在舉辦 這一次諮詢會議的時候 希望做到的事情 就是我們希望 至少作為一個入選團隊 我們的聲音是相較於 可能世界各地其他的 其他沒有入選的團隊來說 可能是相對比較大的 那我們可能就可以利用 這樣子的一個機會來把我們的聲音帶進 

[02:32:34 - 02:32:57] 

**Peter:**
就是OpenAI帶進 這些大型語言 然後並且透過 V Taiwan的既有的一個機制 來建立起相關的架構 好 那如果還有任何問題的話 都歡迎 我們線上連結還會持續開著 所以大家就歡迎直接利用線上連結 再補充今天沒有討論到的問題 那我們今天活動到這邊告一段落 我們有準備了飲料 因為今天真的很熱 所以就有準備飲料給大家 那為什麼在會後發呢因為這邊是禁止飲食的 

[02:32:57 - 02:33:03] 

**Peter:**
所以就是歡迎大家 就是在會後 找外面的工作人員 去索取相關的飲料 那感謝大家今天前來 謝謝大家 



