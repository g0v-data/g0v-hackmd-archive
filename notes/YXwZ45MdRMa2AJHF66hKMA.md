Chapter 4: Threads & Concurrency
有問prcess與thread的不同之處
**Single-threaded** 和 **multi-threaded** processes 是兩種執行程序的不同方式，主要差別在於它們如何管理和利用系統資源來進行並行（concurrent）運算。

### 1. **Single-threaded Process（單執行緒程序）**

一個 **single-threaded process** 是一個只包含**一條執行緒**的程序。執行緒可以被看作程序中實際執行任務的單元。當程序是單執行緒的時候，所有的任務都必須按順序執行，這意味著每次只有一個操作或指令在被執行。

#### 特點：
- **順序執行**：程序從開始到結束以一個線性順序進行，當一個任務被執行時，其他任務必須等待。
- **資源競爭少**：由於只有一個執行緒，不會發生執行緒之間的競爭或同步問題。
- **簡單實現**：編寫和調試相對容易，因為不用考慮多執行緒間的交互和同步問題。

#### 缺點：
- **效率較低**：在多核處理器中，程序只能使用一個處理器核心，無法充分利用多核處理能力。
- **阻塞問題**：如果程序需要進行長時間的I/O操作（如讀取檔案或等待網路響應），整個程序會被阻塞，無法繼續執行其他任務。

---

### 2. **Multi-threaded Process（多執行緒程序）**

**Multi-threaded process** 是包含**多條執行緒**的程序。這些執行緒可以並行執行，即使在一個處理器核心上，系統也會通過快速切換執行緒來模擬並行。在多核處理器上，多執行緒可以真正並行執行不同的執行緒。

#### 特點：
- **並行處理**：多個執行緒可以同時執行不同的任務，提升效率。
- **資源共享**：所有的執行緒共享同一個程序的內存空間和資源（如變量、文件描述符），因此能夠快速地在執行緒之間交換信息。
- **更高效利用資源**：在多核處理器上，每個執行緒可以被分配到不同的處理器核心，實現真正的並行計算。

#### 優點：
- **響應速度快**：在等待I/O操作時，其他執行緒仍然可以繼續工作，不會阻塞整個程序。
- **更好的資源利用率**：在多核處理器上，能夠並行執行多個任務，提升性能。

#### 缺點：
- **同步問題**：由於多個執行緒共享相同的內存空間，因此需要仔細設計來避免執行緒之間的競爭條件和死鎖。
- **調試困難**：多執行緒程序中容易出現難以檢測的並發錯誤，這使得調試和測試變得複雜。

---

### **應用場景：**

1. **Single-threaded Process** 適合那些簡單的應用，比如：
   - 命令列工具
   - 小型桌面應用
   - 不涉及大量I/O或複雜並行計算的應用

2. **Multi-threaded Process** 適合需要同時處理多個任務或對性能要求較高的應用，比如：
   - 伺服器應用（如網頁伺服器）
   - 即時遊戲
   - 資料庫系統
   - 多媒體處理（如視頻編碼）

---

### 總結：
- **Single-threaded** 程序只會有一條執行緒，所有的工作都按順序執行。
- **Multi-threaded** 程序能夠同時執行多個執行緒，有助於加速程序並提高資源利用率，但也帶來同步和並發問題。

![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_55577a1d584de3f0c87cfa2cc225267e.PNG)
**Multithreaded Server Architecture（多執行緒伺服器架構）** 是一種伺服器設計模式，用來提高伺服器處理並發請求的能力。在這種架構中，伺服器會利用多個執行緒來同時處理來自多個客戶端的請求，從而提高伺服器的吞吐量和反應速度。

### **基本概念**

當一個客戶端向伺服器發送請求時，伺服器需要進行一系列操作來處理該請求，這可能包括數據讀寫、計算操作、查詢資料庫等。如果伺服器是**單執行緒架構**，它將會一次處理一個請求，其他請求需要等待當前請求完成，這可能會導致延遲和低效。**多執行緒伺服器**則允許伺服器同時處理多個客戶端請求。

### **Multithreaded Server 的工作原理**(上課有問)

在多執行緒伺服器架構中，通常每當伺服器接收到一個新請求時，它會創建一個新的執行緒來專門處理該請求。這樣做的好處是：
1. 每個客戶端的請求能夠**並行處理**，從而縮短等待時間。
2. I/O 操作（如讀取文件或資料庫查詢）可以被交由一個執行緒處理，而其他執行緒可以繼續處理其他請求，不會因為單個客戶端的延遲影響到其他客戶端。

#### 具體步驟：
1. **主執行緒監聽請求**：伺服器主執行緒監聽客戶端請求，當接收到請求時，將請求分配給新的執行緒或可用的執行緒。
2. **創建或分配執行緒**：伺服器為每個客戶端的請求創建一個新的執行緒，或從執行緒池中取出一個可用的執行緒來處理請求。
3. **請求處理**：每個執行緒獨立處理與該客戶端的交互，執行具體的邏輯操作，例如讀取數據、處理業務邏輯、返回結果等。
4. **執行緒結束或返回池中**：當處理完成後，該執行緒要麼終止，要麼返回執行緒池中，等待下次被分配新的請求。

### **Multithreaded Server 的架構模型**

1. **Thread-per-request 模型**：
   - 每個客戶端的請求都由一個新的執行緒處理。
   - 這種模式實現簡單，適合處理少量請求的伺服器，但在高並發時，創建過多執行緒會導致**資源消耗過大**。

2. **Thread Pool（執行緒池）模型**：
   - 預先創建固定數量的執行緒，當有請求來臨時，分配一個可用的執行緒來處理。處理完畢後，執行緒不會銷毀，而是返回到池中，等待下個請求。
   - **優點**：限制了同時運行的執行緒數量，減少資源消耗，提高伺服器穩定性。
   - **缺點**：如果請求數量過多，當所有執行緒都在忙碌時，新請求會被迫等待可用執行緒。

3. **混合模型**：
   - 有些伺服器可能會根據不同的請求類型選擇不同的執行緒模型。例如，對於計算密集型任務使用執行緒池，對於輕量級 I/O 請求使用異步 I/O 或單執行緒模型。

### **優點與挑戰**

### 優點
- **響應性responsiveness**：當程序的一部分被阻塞時，可能允許其他部分繼續執行，這對於使用者介面特別重要。
- **資源共享resource sharing**：執行緒共享程序的資源，比共享記憶體或訊息傳遞更容易實現。
- **經濟性**：創建執行緒比創建程序更便宜，執行緒切換的開銷比上下文切換要低。
- **可擴展性**：程序可以利用多處理器架構的優勢來提升性能。

#### **挑戰**：
1. **同步問題**：由於多個執行緒共享伺服器的資源（如內存或資料庫連接），需要解決**資料競爭**和**死鎖**等問題。
2. **資源開銷**：每個執行緒都有其內存開銷，創建和管理大量執行緒也需要額外的計算資源，過多執行緒可能會導致性能下降。
3. **調試難度**：多執行緒應用的**錯誤調試**和**維護**相對較難，尤其是在發生並發錯誤時。
### **應用場景**

- **Web 伺服器**：例如 Apache 或 Nginx，可以通過多執行緒來處理多個來自網頁客戶端的請求。
- **遊戲伺服器**：多玩家同時在線遊戲需要伺服器能夠同時處理大量玩家的請求。
- **即時通訊應用**：如聊天應用或視頻通話應用，需要同時處理多個連接和消息傳遞。
- **資料庫伺服器**：多執行緒能夠處理多個並行查詢，提高查詢效率。

---

### **總結**

**Multithreaded Server Architecture** 是一種伺服器設計架構，它利用多執行緒來同時處理多個請求，提高伺服器的並發性能。通過這種方式，伺服器能夠更快速地響應客戶端，並在多核處理器上更高效地運行。然而，它也帶來了一些同步問題和資源管理挑戰，因此需要合理設計和優化。
![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_75429cc6d2f23184f577f249848ce0f4.PNG)
**多核心程式設計（Multicore Programming）** 是一種針對**多核心處理器**的程序開發方法，旨在使軟體能夠有效地利用處理器中的多個核心來同時執行多個任務或指令。隨著硬體發展，多核心處理器已經成為現代計算機系統的標準配置，這要求軟體能夠充分發揮多核心架構的並行運算能力，以提高性能和效率。

### **基本概念**

多核心處理器指的是一個單一處理器內集成了多個運算核心（CPU 核心），每個核心可以獨立執行指令。傳統的單核心處理器在同一時間只能執行一個任務，而多核心處理器可以在同一時間處理多個任務，通過並行運算來提升系統的總體性能。

**多核心程式設計**的目標是讓應用程式能夠同時使用多個核心進行並行運算，這樣可以更高效地執行複雜的任務或加速運算。

### **多核心程式設計的挑戰**

儘管多核心處理器提供了更高的性能潛力，但如何有效利用這些核心來開發高效的應用程式是個挑戰。以下是多核心程式設計中的一些主要挑戰：

1. **活動劃分（Dividing Activities）**：
   - 將一個大型任務分解為可以同時執行的小型任務是並行運算的核心。如何合理地將工作分配給不同的核心，使得這些核心能夠並行運作，對程序的設計和性能至關重要。
   
2. **平衡（Balance）**：
   - 需要確保各個核心的負載均衡，避免某些核心超載而其他核心閒置。負載不均衡會降低並行運算的效率，導致資源浪費和性能瓶頸。

3. **資料分割（Data Splitting）**：
   - 為了實現並行計算，需要將數據分割給不同的執行緒或進程來處理。然而，如何有效地分配和管理數據，避免不同執行緒之間的數據競爭或數據不一致是重要的設計考量。

4. **資料依賴性（Data Dependency）**：
   - 當多個執行緒或進程同時處理共享數據時，資料依賴性可能會導致同步問題。例如，如果一個執行緒需要依賴另一個執行緒的輸出結果，這會導致性能下降。如何避免和解決這些依賴關係是並行程式設計中的重要挑戰。

5. **測試與除錯（Testing and Debugging）**：
   - 多執行緒和並行程序的測試與除錯比單執行緒程序更為困難，因為執行緒之間的交互是非確定性的。並行程式設計可能會遇到競爭條件、死鎖和數據不同步等問題，這些問題很難重現和檢測。

### **多核心程式設計的常見模式**

在實現多核心程式設計時，通常有幾種常見的程式設計模式或技術來幫助開發者：

1. **多執行緒編程（Multithreading Programming）**：
   - 多執行緒允許一個程序同時執行多個執行緒，每個執行緒可以分配給不同的核心運行。這是最常用的並行編程技術。

2. **並行框架與庫**：
   - 現代程式語言和環境提供了大量的並行編程框架和庫，如 Java 的 **Fork/Join 框架**、C++ 的 **Thread** 標準庫、Python 的 **Multiprocessing** 庫，這些工具可以簡化多核心程序的開發。

3. **資料並行（Data Parallelism）**：
   - 將數據集分割成多個部分，每個處理核心負責處理一部分數據，這種方法常用於大數據處理、科學計算和機器學習中。

4. **任務並行（Task Parallelism）**：
   - 將不同的工作（或任務）分配給不同的處理核心，這種方法適用於任務之間相互獨立的情況。

### **多核心程式設計的優點**

1. **性能提升**：
   - 多核心程式設計能夠通過並行運算來顯著提高程序的執行速度，尤其是在多核 CPU 的環境下。

2. **資源利用最大化**：
   - 將不同的核心分配給不同的計算任務，使系統資源得到更充分的利用。

3. **可擴展性（Scalability）**：
   - 多核心程序可以利用更多的處理器核心來提高性能，因此具有良好的可擴展性。在未來的多核心處理器中，可以通過增加核心數量來進一步提升系統性能。

### **應用場景**

多核心程式設計廣泛應用於各類需要大量運算或並發處理的場景中，例如：
- **遊戲引擎**：同時處理多個物理運算、遊戲邏輯和圖像渲染。
- **大數據處理**：如 MapReduce 框架，將數據集切分並行處理。
- **科學計算**：如矩陣運算、大規模模擬等。
- **視頻編碼與渲染**：將視頻文件或三維場景分割並行處理，以加快處理速度。
- **即時系統與伺服器**：多執行緒技術用於高效處理大量同時的客戶端請求。

---

多核心或多處理器系統對程式設計師帶來壓力，挑戰包括：
- **活動劃分**：如何將工作劃分為不同的部分來並行執行。
- **平衡**：確保各部分的工作負載平衡，不會出現某些處理器閒置而其他處理器超載的情況。
- **資料分割**：如何有效地將數據分配給不同的執行緒或處理器來處理。
- **資料依賴性**：處理資料之間的依賴關係，避免執行緒之間的競爭和衝突。
- **測試與除錯**：對多執行緒和並行程序進行測試與調試的難度更大。
Concurrency vs. Parallelism
![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_f6eddfb6a2946e2ef55eb11d9f7ed749.PNG)
**Concurrency（並發）** 和 **Parallelism（並行）** 是計算機科學中兩個相關但不同的概念，它們都涉及同時執行多個任務或進程。這兩者的區別在於它們如何處理多個任務和如何實現同時執行。

### **1. Concurrency（並發）**

**並發** 是指多個任務在系統中**同時存在**，但不一定是**真正同時執行**。在並發系統中，任務可以在不同的時間片段中執行，並且通過快速切換來達到“同時進行”的效果，即多個任務共享一個處理資源（如 CPU）。

並發的重點是**結構化處理多個任務**，而不是強調它們必須實際上同時運行。在單核處理器上，並發通常通過時間切片（time slicing）實現：系統快速切換不同任務的執行，使它們看起來是同時運行的。

#### **特點**：
- 任務看似同時進行，但實際上可能是交替執行的。
- 主要目的是提高系統的**響應性**，允許系統在等待一個任務完成的同時進行其他任務。
- 並發的實現可能不依賴於硬體的多核心能力。

#### **應用場景**：
- 多個任務之間可能需要等待某些外部事件（如 I/O 操作完成），並發允許在等待期間繼續處理其他任務。例如，圖形使用者介面（GUI）程序可以在等待用戶輸入的同時繼續運行其他後台任務。

#### **比喻**：
- **並發**像是一個人同時處理多個事情，通過快速切換來完成不同的工作，例如一個人來回在兩本書之間快速閱讀，雖然不是真正同時閱讀兩本書，但在短時間內處理了兩個任務。

---

### **2. Parallelism（並行）**

**並行** 是指多個任務**真正同時執行**，這需要多個處理資源，如多核心處理器或多個處理單元。在並行系統中，任務可以同時在不同的處理器或核心上運行，從而達到真正的同時執行。

並行的目的是**加速計算**，通過將一個大型任務分解為若干個可以同時執行的子任務來提高性能。

#### **特點**：
- 任務實際上是同時在不同的處理資源上運行的。
- 並行的效率高度依賴於硬體架構，如多核心處理器或分布式計算系統。
- 並行更多地強調**提高計算效率**和**縮短執行時間**。

#### **應用場景**：
- 資源密集型應用（如大規模數據處理、科學計算、視頻編碼）中，並行能夠將任務分成多個部分，並行處理以加快運算速度。

#### **比喻**：
- **並行**像是有多個人同時閱讀不同的書，每個人都在讀一本書，這樣可以同時完成多本書的閱讀。

---

### **Concurrency vs. Parallelism 的區別**

| 特徵               | **Concurrency（並發）**                                      | **Parallelism（並行）**                                |
|-------------------|-------------------------------------------------------------|------------------------------------------------------|
| **定義**            | 同時處理多個任務，但不一定同時執行。                          | 多個任務在不同處理資源上真正同時執行。                 |
| **核心區別**        | 任務之間可以交替進行，強調系統的響應性和結構化管理。               | 任務真正同時執行，目的是提高計算效率。                   |
| **硬體需求**        | 不需要多核心處理器，也可以在單核系統上實現。                      | 需要多核心處理器或多個處理單元來實現真正的並行運算。       |
| **目的**            | 最大化系統的利用率和響應性。                                   | 加速運算，減少任務執行時間。                            |
| **典型場景**        | I/O 密集型應用、互動式應用（如 GUI）。                        | 資源密集型應用（如大規模數據處理、科學計算、分布式系統）。 |
| **示例**            | 一個多執行緒程序在單核心上快速切換任務。                          | 在多核心 CPU 上同時運行不同的程序或執行緒。              |

---

### **Concurrency 和 Parallelism 的關係**

- **並發** 和 **並行** 並不互斥。系統可以是並發的而不並行，也可以是並行的而不並發。當系統既可以同時管理多個任務（並發），又能真正同時執行它們（並行），那麼這個系統就是**同時具備並發和並行**的能力。
  
  比如，一個多執行緒的伺服器在單核處理器上可以實現並發，但如果在多核心處理器上執行，則可以同時實現並發和並行。

### **總結**

- **Concurrency** 強調的是**管理多個任務的同時進行**，無論它們是否實際上同時運行。
- **Parallelism** 強調的是**同時執行多個任務**，這通常需要硬體支持多個處理核心。

這兩者是設計並行系統的重要概念，也是多核心與多執行緒編程中的關鍵考慮因素。
以下是該段內容的翻譯：

### 使用者執行緒（User Threads）和核心執行緒（Kernel Threads）

- **使用者執行緒（User Threads）**：由**使用者層級的執行緒庫**進行管理。
  - 三種主要的執行緒庫：
    - POSIX Pthreads（POSIX 標準執行緒）
    - Windows 執行緒
    - Java 執行緒

- **核心執行緒（Kernel Threads）**：由**操作系統核心**支援。
  - 例子：幾乎所有的通用操作系統都支援核心執行緒，包括：
    - Windows
    - Solaris
    - Linux
    - Tru64 UNIX
    - Mac OS X
**使用者執行緒（User Threads）** 和 **核心執行緒（Kernel Threads）** 是兩種執行緒的管理模型，它們的區別在於由誰負責管理執行緒的創建、切換、和調度。

### 1. **使用者執行緒（User Threads）**

**使用者執行緒**是由應用程式在**使用者空間**中自行管理的執行緒，與核心沒有直接交互。這意味著執行緒的創建、切換、同步等操作都由應用程式內部的執行緒庫處理，核心不會感知到這些執行緒的存在。

#### **特點**：
- **管理由使用者層級的執行緒庫負責**，不依賴核心的調度機制。
- **效率較高**：因為所有的執行緒操作都在使用者空間完成，無需進行核心模式和使用者模式的切換，所以操作開銷較低。
- **無法利用多處理器**：在大多數實現中，核心只看到一個單一的進程，因此無法在多核心處理器上真正同時執行多個執行緒。
- **阻塞問題**：如果一個使用者執行緒進行系統調用並被阻塞，整個進程的所有執行緒都可能會被阻塞，因為核心不知道其他執行緒的存在。

#### **優點**：
- 執行緒操作速度快，因為所有的操作都發生在使用者空間。
- 不需要核心干預，執行緒切換和調度開銷較低。

#### **缺點**：
- 如果一個執行緒阻塞，可能會影響整個進程。
- 無法充分利用多核處理器，因為核心只能看到一個進程，不能進行並行運算。

#### **常見的使用者執行緒庫**：
- **POSIX Pthreads**：一個標準的跨平台執行緒庫。
- **Windows Threads**：Windows 的原生執行緒庫。
- **Java Threads**：Java 虛擬機內置的執行緒管理。

---

### 2. **核心執行緒（Kernel Threads）**

**核心執行緒**是由**操作系統的核心**進行管理的執行緒。每個核心執行緒都能被核心識別，並由核心負責調度和切換，因此可以充分利用多核心處理器的能力來進行並行運算。

#### **特點**：
- **核心直接管理**：核心負責執行緒的創建、調度和同步。
- **可並行運行**：核心知道所有的執行緒，因此可以在多核心處理器上將不同的執行緒分配給不同的核心運行，實現真正的並行處理。
- **支持多處理器**：在多核系統中，核心可以將不同的執行緒分配到不同的核心上執行，從而有效利用多處理器的計算資源。

#### **優點**：
- 能夠利用多處理器，實現真正的並行運算。
- 如果一個執行緒阻塞，核心可以調度其他執行緒繼續運行，避免進程整體阻塞。

#### **缺點**：
- 執行緒的創建和切換需要進行核心與使用者模式之間的切換，這增加了操作開銷。
- 核心執行緒的管理較複雜，並且需要核心的支持。

#### **支持核心執行緒的操作系統**：
- **Windows**
- **Solaris**
- **Linux**
- **Tru64 UNIX**
- **Mac OS X**

---

### **使用者執行緒 vs. 核心執行緒** 的比較

| 特徵                | **使用者執行緒（User Threads）**                              | **核心執行緒（Kernel Threads）**                           |
|--------------------|-------------------------------------------------------------|----------------------------------------------------------|
| **管理者**            | 使用者空間的執行緒庫管理                                        | 操作系統核心管理                                             |
| **核心感知度**        | 核心對其無法感知，核心只看到整個進程                                | 核心可以直接感知並管理每個執行緒                                     |
| **效能**             | 無需切換至核心模式，操作效率高，但無法充分利用多核心處理器                 | 可以利用多處理器，但執行緒操作需要切換至核心模式，開銷較大                   |
| **阻塞問題**          | 一個執行緒阻塞會導致整個進程阻塞                                   | 一個執行緒阻塞時，核心可以調度其他執行緒繼續運行，避免進程阻塞               |
| **並行性**            | 無法實現真正的並行，因為核心只能看到一個進程                           | 支持並行，核心可以將不同執行緒分配到不同處理器上運行                            |
| **應用場景**          | 適用於 I/O 密集型的輕量級應用程式                                  | 適用於需要充分利用多核心處理器的計算密集型應用，如科學計算或高並發伺服器系統         |

---

### **結合模式：混合模型（Hybrid Model）**

有些系統使用**混合模型**，結合了使用者執行緒和核心執行緒的優點。這種模式下，使用者層的執行緒可以映射到一個或多個核心執行緒上，這樣可以既保持使用者執行緒的高效，又能充分利用核心的並行處理能力。
**Multithreading Models** 指的是將使用者執行緒（User Threads）和核心執行緒（Kernel Threads）進行映射的不同方式。這些模型決定了執行緒如何在使用者層和核心層之間進行交互。**Many-to-One 模型**是其中最基本的一種多執行緒模型。

### **Many-to-One 模型**

在 **Many-to-One** 模型中，**多個使用者執行緒**被映射到**單個核心執行緒**上。這意味著無論有多少個使用者執行緒，同一時刻只能有一個使用者執行緒由核心執行，因為所有使用者執行緒都共用一個核心執行緒。

#### **特點**：
1. **多個使用者執行緒對應一個核心執行緒**：所有的執行緒調度和管理都在使用者空間內部完成，核心只知道有一個核心執行緒的存在。
2. **執行緒切換由使用者層級負責**：因為所有的使用者執行緒共用同一個核心執行緒，執行緒的切換和管理都是由應用程式的執行緒庫來負責，核心無需參與。
3. **無法並行運行**：即使在多核心系統上，由於所有的使用者執行緒都映射到一個核心執行緒，導致同一時間只能在一個處理器上執行一個執行緒，無法真正實現並行處理。
4. **阻塞問題**：如果某個使用者執行緒執行系統調用並被阻塞，整個核心執行緒也會被阻塞，導致其他使用者執行緒無法運行，這可能會大大降低系統的效率。

#### **優點**：
- **簡單高效**：由於核心只看到一個執行緒，因此執行緒切換不需要進行核心與使用者模式的切換，開銷較低，執行效率高。
- **適用於單核心系統**：在單核心系統中，因為只有一個處理核心，這種模型可能會更簡單、開銷更少。

#### **缺點**：
- **無法利用多核心處理器**：在多核心處理器上無法實現並行運行，這會限制多執行緒程序的性能，尤其在計算密集型應用中。
- **阻塞問題**：一旦一個使用者執行緒被阻塞（例如等待 I/O），整個進程的所有執行緒都會被阻塞。

#### **適用場景**：
- **單核心處理器**的環境中，由於無法實現真正的並行運算，Many-to-One 模型相對簡單且有效。
- 對於不依賴多執行緒並行處理、但需要使用執行緒來組織代碼結構的應用程式，這種模型適用。

**One-to-One 模型** 是多執行緒模型中的一種，它將每個**使用者執行緒（User Thread）**映射到一個**核心執行緒（Kernel Thread）**。這意味著每創建一個使用者執行緒，操作系統就會為其創建一個對應的核心執行緒來進行管理和調度。這樣的模型在多核心處理器上可以實現真正的並行運行。

### **One-to-One 模型的特點**

1. **每個使用者執行緒對應一個核心執行緒**：
   - 每當創建一個使用者執行緒時，系統會同時創建一個核心執行緒。這意味著每個使用者執行緒都能獲得核心級的支持，能夠充分利用核心的資源。

2. **支持真正的並行運行**：
   - 由於每個使用者執行緒都有一個對應的核心執行緒，這允許在多核心處理器上同時運行多個執行緒，實現真正的並行計算。這對於計算密集型應用特別有利。

3. **執行緒阻塞不會影響其他執行緒**：
   - 由於每個使用者執行緒都有自己的核心執行緒，如果一個執行緒被阻塞（例如等待 I/O 操作），其他執行緒仍然可以繼續運行，不會因此受到影響。

4. **高開銷**：
   - 由於每個使用者執行緒都需要對應一個核心執行緒，因此系統開銷較高，尤其是當應用程式創建大量的執行緒時，系統資源消耗會迅速增加。創建核心執行緒的成本相對較高，且需要在核心與使用者空間之間進行切換，這增加了操作的開銷。

### **優點**：
- **真正的並行運行**：能夠充分利用多核心處理器，允許多個執行緒同時在不同核心上運行。
- **阻塞不影響整個進程**：如果一個執行緒阻塞，其他執行緒可以繼續運行，保持高效的資源利用。
- **易於管理**：每個使用者執行緒都有一個核心執行緒來進行調度，執行緒之間的管理更容易，尤其是在多執行緒程序中。

### **缺點**：
- **資源消耗較高**：由於每個使用者執行緒都需要對應一個核心執行緒，當執行緒數量非常多時，系統的資源開銷（例如記憶體和處理器的負擔）也會大幅增加。
- **系統負荷大**：由於操作系統需要創建並管理大量的核心執行緒，這對於系統來說是一個較大的負荷，尤其在執行緒數量過多的情況下。

### **適用場景**：
- **多核心處理器環境**：One-to-One 模型特別適合於多核心處理器，因為它可以在多個核心上同時運行多個執行緒，充分利用硬體資源。
- **高並行計算需求的應用**：如科學計算、大數據處理和高效能伺服器等應用，需要高並行性和高響應速度的情況下，One-to-One 模型非常適合。
Examples
 Windows
 Linux
 Solaris 9 and later
**Many-to-Many 模型**是多執行緒模型中的一種，它允許多個**使用者執行緒（User Threads）**同時對應於多個**核心執行緒（Kernel Threads）**。這意味著多個使用者執行緒可以被映射到多個核心執行緒上運行，從而充分利用系統資源，實現更高效的執行緒管理和調度。

### **Many-to-Many 模型的特點**

1. **多對多的映射**：
   - 在此模型中，使用者執行緒和核心執行緒之間存在一種靈活的映射關係。多個使用者執行緒可以共享多個核心執行緒，這樣可以在不同的核心上運行多個使用者執行緒。

2. **並行執行**：
   - 由於可以將多個使用者執行緒映射到多個核心執行緒上，因此該模型支持真正的並行運行，允許同時執行多個執行緒，特別是在多核心處理器系統中。

3. **動態調度**：
   - 這種模型允許系統根據當前的負載和執行緒的狀態動態調整執行緒的映射。核心執行緒可以隨時被分配或釋放，使得系統可以在不同的工作負載下進行優化。

4. **阻塞管理**：
   - 如果一個使用者執行緒被阻塞，系統可以將其他非阻塞的使用者執行緒分配到可用的核心執行緒上，這樣就可以避免整個進程的阻塞，提高整體性能。

### **優點**：
- **高效利用資源**：由於可以靈活地將多個使用者執行緒分配到多個核心執行緒，這使得系統能夠更高效地利用可用的處理器資源。
- **減少阻塞影響**：一個執行緒的阻塞不會影響到其他執行緒，因為有多個核心執行緒可以同時運行其他使用者執行緒，保持系統的高可用性。
- **靈活性**：動態調整執行緒映射的能力使得系統在面對不同的負載情況下能夠進行自我調整，優化性能。

### **缺點**：
- **實現複雜性**：Many-to-Many 模型的實現相對較為複雜，因為它需要在使用者空間和核心空間之間進行多種狀態的管理和調度。
- **開銷增加**：雖然可以實現高並行性，但同時需要管理更多的核心執行緒，這可能會增加上下文切換和調度的開銷。
- **需要額外的支持**：該模型需要操作系統提供更強大的支持，這可能會使得某些較舊的或簡單的操作系統無法有效實現。

### **適用場景**：
- **多核心處理器環境**：在多核處理器上，Many-to-Many 模型特別適用於需要高並行性和可擴展性的應用。
- **高性能計算**：如科學計算、大數據分析和伺服器應用，這些場景中需要快速響應和高效能的計算能力。
- **異步 I/O 操作**：在進行大量 I/O 操作的情況下，這種模型可以有效管理阻塞和非阻塞的執行緒，保持系統的高效率。

執行緒庫（Thread Libraries）是提供程序員用來創建、管理和控制執行緒的應用程式介面（API）。它們簡化了多執行緒程式設計的過程，使開發者能夠有效地利用並行處理的優勢，從而提高應用程式的性能和響應能力。

執行緒庫的實現主要有兩種方式：一是**使用者空間庫**，二是**核心級庫**。使用者空間庫完全在應用程式的使用者空間中運行，執行緒的管理和調度均由使用者級程式庫控制。這樣的庫通常具有較低的開銷，因為執行緒切換不需要進行核心模式與使用者模式的切換。但由於核心並不知曉這些執行緒的存在，因此如果一個執行緒被阻塞，整個進程的所有執行緒也會受到影響。

另一方面，核心級庫則由操作系統的核心進行管理和調度，每個使用者執行緒都對應一個核心執行緒，這樣可以實現真正的並行運行。這使得系統能夠更好地利用多核心處理器的能力，並且在執行緒阻塞的情況下，其他執行緒仍然可以繼續運行。雖然核心級庫的開銷較高，但它在支持高性能和多任務處理方面具有明顯的優勢。

**執行緒庫（Thread Libraries）**

- **執行緒庫提供了程序員用來創建和管理執行緒的應用程式介面（API）**。
- **主要有兩種實現方式**：
  - **完全在使用者空間中的庫**。
  - **由操作系統支持的核心級庫**。
**Pthreads（POSIX Threads）** 是一種用於多執行緒程式設計的API，符合POSIX標準（IEEE 1003.1c），旨在提供一組統一的介面來創建和管理執行緒。Pthreads使得開發者能夠在應用程式中有效地使用多執行緒技術，從而提高性能和響應速度。以下是Pthreads的幾個關鍵特點：

### 1. **標準化**
- Pthreads是POSIX標準的一部分，這意味著它在多個操作系統（特別是UNIX和類UNIX系統）中被廣泛支持，包括Linux、Solaris和Mac OS X。
- 該標準定義了執行緒的行為、創建和終止執行緒的方法，以及執行緒之間的同步機制。

### 2. **使用者級和核心級執行緒**
- Pthreads可以實現為使用者級執行緒（User-level Threads），這些執行緒的管理和調度完全在使用者空間中進行，也可以作為核心級執行緒（Kernel-level Threads），這些執行緒由操作系統的核心直接管理。
- 核心級執行緒可以更好地利用多核心處理器的能力，實現真正的並行處理。

### 3. **執行緒的創建和管理**
- Pthreads提供API來創建執行緒、終止執行緒、同步執行緒之間的操作，以及管理執行緒的屬性。
- 開發者可以利用這些API進行執行緒間的通信與協調，從而有效地管理並行運算。

### 4. **同步機制**
- Pthreads支持多種同步機制，包括互斥鎖（mutexes）、條件變量（condition variables）和讀寫鎖（read-write locks），這些工具可以幫助開發者處理多執行緒環境中的競爭條件和資源共享問題。

### 5. **可移植性**
- 作為POSIX標準的一部分，Pthreads的可移植性非常高，這使得開發者可以編寫在不同操作系統上都能運行的多執行緒應用程序，而不必擔心底層實現的差異。

**Pthreads（POSIX執行緒）**

- Pthreads可以作為使用者級或核心級執行緒庫提供。
- 它是一個針對執行緒創建和同步的POSIX標準（IEEE 1003.1c）API。
- Pthreads是規範，而非具體實現。
- 該API指定了執行緒庫的行為，具體實現則取決於該庫的開發。
- Pthreads在UNIX操作系統中非常常見，例如Solaris、Linux和Mac OS X。
Pthreads Example
![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_ea2f0e11f633b60bbf46307de56633a2.PNG)
![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_b628bab950ed7e1ad3eb6604dfd5bc55.PNG)
Windows Multithreaded C Program
![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_4c51b86292831b58d40f2e5d1c453192.PNG)
![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_9904ca862093d9f26b8bf7665691a49d.PNG)
**Java執行緒（Java Threads）**是Java語言中實現多執行緒編程的一種機制。執行緒是進程中的一個輕量級執行單元，每個執行緒都有自己的執行路徑和上下文，但可以共享進程中的資源，如記憶體和開放的檔案。以下是Java執行緒的一些關鍵特性和概念：

### 1. **JVM管理**
- Java執行緒由Java虛擬機（JVM）管理，這使得執行緒的創建、執行和終止變得更為簡單和高效。
- JVM負責處理執行緒的生命週期，包括執行緒的創建、調度和終止。

### 2. **執行緒模型**
- Java執行緒通常是基於底層操作系統提供的執行緒模型實現的。這意味著Java執行緒的運行和調度是依賴於操作系統的調度器來完成的。
- 在多核心處理器的環境中，Java執行緒可以在不同的CPU核心上並行運行，充分利用硬體資源。

### 3. **創建執行緒**
- 在Java中，創建執行緒可以通過兩種主要方式：
  - **繼承`Thread`類**：創建一個新的類繼承自`Thread`，並重寫其`run()`方法，然後創建該類的實例並調用`start()`方法。
  - **實現`Runnable`接口**：創建一個實現`Runnable`接口的類，並將其傳遞給`Thread`類的構造函數，然後調用`start()`方法。

### 4. **執行緒的生命週期**
- Java執行緒的生命週期包括幾個狀態：新建（New）、就緒（Runnable）、執行（Running）、阻塞（Blocked）、等待（Waiting）、和死亡（Terminated）。
- 當執行緒開始運行時，它會從新建狀態變為就緒狀態，然後進入執行狀態。執行後，執行緒可能因等待I/O或被其他執行緒搶佔而進入阻塞或等待狀態。

### 5. **同步和通信**
- Java提供多種機制來處理執行緒之間的同步和通信，包括`wait()`、`notify()`和`notifyAll()`方法，以及使用`volatile`關鍵字和`java.util.concurrent`包中的工具，如`Locks`和`Executors`。
- 使用這些機制可以有效地解決多執行緒環境中的競爭條件和資料一致性問題。

### 6. **執行緒池**
- Java也支持執行緒池的概念，這是通過`Executors`框架實現的。執行緒池可以重用執行緒，減少創建和銷毀執行緒的開銷，提高應用程式的性能。

### **總結**
Java執行緒是Java語言中實現並行處理的核心機制，通過JVM管理和底層操作系統的支持，提供了一個高效且易於使用的多執行緒編程模型。利用Java的執行緒，開發者可以構建高效的應用程式，實現同時處理多個任務，提升程式的響應能力和性能。
Java Multithreaded Program
![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_d8d8c756349a737ea62bf32720cfee1e.PNG)
![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_3c41d0d58e717523e628faffcdc5232a.PNG)
**執行緒問題（Threading Issues）**

- **fork() 和 exec() 系統調用的語意** 
- **信號處理**
- **同步和非同步**
- **目標執行緒的取消**
- **非同步或延遲**
- **執行緒池**
- **執行緒本地存儲**
- **調度器激活**
在Unix和類Unix系統中，`fork()`和`exec()`是兩個基本的系統調用，通常用於創建新進程和執行程序。它們的語意和行為對於多執行緒環境有特別的考量。

### 1. **fork() 的語意**

- **複製進程**：
  - 當調用`fork()`時，當前進程將被複製，並創建一個新的子進程。這包括父進程的執行狀態、開放的文件描述符、記憶體空間等。

- **執行緒的複製**：
  - 在多執行緒環境中，`fork()`的行為取決於具體的實現。一般來說，`fork()`會複製調用它的執行緒的上下文，而不是所有執行緒的上下文。這意味著如果父進程有多個執行緒，只有調用`fork()`的那個執行緒會在子進程中存在，其他執行緒不會被複製。

- **兩種版本的fork()**：
  - 某些Unix系統可能提供兩個版本的`fork()`：一個是標準版本，另一個是專為多執行緒環境設計的版本（例如，`vfork()`），這種版本通常會在父進程和子進程之間共享某些資源，以提高性能。

### 2. **exec() 的語意**

- **替換進程映像**：
  - 當調用`exec()`系列函數時，當前進程的執行映像會被新的程序所替換。這意味著當`exec()`成功返回時，原進程的代碼、數據和堆棧都將被新程序的內容取代。

- **對執行緒的影響**：
  - `exec()`調用通常會影響所有執行緒，因為整個進程的執行環境將被替換。這意味著所有在進程中運行的執行緒都會隨著`exec()`的調用而消失。

### 總結

`fork()`和`exec()`在進程創建和程序執行中扮演著重要的角色，但在多執行緒環境下，它們的行為會有特別的考量。特別是在使用`fork()`時，只有調用該函數的執行緒會被複製，而在`exec()`中，整個進程的所有執行緒都會隨著進程的替換而消失。這些行為對於開發多執行緒應用程式的設計和實現具有重要意義。
![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_50b1b8f8ef602f5fbd7b568ce7b05e83.PNG)
執行緒取消（Thread Cancellation）

在執行緒完成之前終止該執行緒。
需要被取消的執行緒稱為目標執行緒。
主要有兩種一般方法：
非同步取消：立即終止目標執行緒。
延遲取消：允許目標執行緒定期檢查是否應該被取消。
Pthread 代碼示例：創建和取消執行緒
![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_6ce81aa177db16241aae592612067866.PNG)
**信號處理（Signal Handling）**

- 信號在UNIX系統中用來通知進程某個特定事件已經發生。
- 信號處理器（Signal Handler）用於處理信號：
  1. 信號由特定事件產生。
  2. 信號被送達到進程。
  3. 信號由兩種信號處理器之一處理：
     (1) 默認處理器（default）
     (2) 用戶定義的處理器（user-defined）
  
- 每個信號都有一個默認處理器，當處理信號時，內核將運行該處理器。
  - 用戶定義的信號處理器可以覆蓋默認處理器。
  - 對於單執行緒進程，信號會送達到進程中。
**在多執行緒中，信號應該送達到哪裡？**

- 將信號送達到適用於該信號的執行緒。
- 將信號送達到進程中的每個執行緒。
- 將信號送達到進程中的特定執行緒。
- 指定一個特定的執行緒來接收進程的所有信號。
**執行緒池（Thread Pools）**是一種用於管理多執行緒的設計模式，特別適用於需要執行大量短期任務的情況。這種模式的核心思想是重用已存在的執行緒，而不是每次都創建和銷毀執行緒，從而提高應用程序的性能和資源利用率。

### 工作原理

執行緒池通常會預先創建一組執行緒，這些執行緒在應用程序的整個生命週期內保持活動狀態。當有任務需要執行時，應用程序可以從池中獲取一個空閒的執行緒來處理該任務。一旦任務完成，該執行緒不會被銷毀，而是返回池中，等待下一個任務的分配。這樣可以避免在高頻率創建和銷毀執行緒帶來的性能開銷。

### 優勢

1. **性能提升**：通過重用執行緒，執行緒池能夠顯著減少創建和銷毀執行緒的時間和資源消耗，特別是在高並發場景中。
  
2. **資源管理**：執行緒池可以有效控制同時運行的執行緒數量，防止系統因為過多執行緒而導致性能下降。

3. **簡化開發**：使用執行緒池的API可以簡化多執行緒編程的複雜性，開發者可以專注於任務的邏輯，而不必關心執行緒的管理。

### 應用場景

執行緒池廣泛應用於Web伺服器、數據處理系統和任何需要處理大量短期任務的應用中。Java的`Executor`框架和Python的`concurrent.futures.ThreadPoolExecutor`都是實現執行緒池的典型例子。

總的來說，執行緒池是多執行緒編程中一種高效且靈活的解決方案，能夠顯著提高應用程序的性能和可維護性。
**創建一個執行緒池，其中執行緒等待工作**

- **優點**：
  - 通常用已存在的執行緒來處理請求比創建新執行緒稍快。
  - 允許應用程序中的執行緒數量與池的大小相綁定。
  - 將要執行的任務與創建任務的機制分開，使得可以對任務運行的策略採取不同的方法。
    - 例如，任務可以被安排定期執行。
  
- **Windows API 支持執行緒池**。
**執行緒特定數據（Thread Specific Data）**

- 屬於同一進程的執行緒共享該進程的數據。
- 然而，允許每個執行緒擁有其自己的數據副本（執行緒特定數據）是非常有用的。
- 我們可以使用執行緒特定數據來將每個執行緒與其唯一的ID關聯起來。
- 大多數執行緒庫提供某種形式的支持來處理執行緒特定數據。
**調度器激活（Scheduler Activations）**

- 多對多模型需要通信以維持分配給應用程序的適當數量的內核執行緒。
- 通常在用戶執行緒和內核執行緒之間使用中間數據結構——輕量級進程（Lightweight Process, LWP）。
- LWP看起來像是一個虛擬處理器，進程可以在其上安排用戶執行緒運行。
- 每個LWP都與一個內核執行緒相連接。
- 該創建多少個LWP？
- 調度器激活提供了上調用（upcalls）——一種從內核到執行緒庫中上調用處理器的通信機制。
- 這種通信使應用程序能夠維持正確數量的內核執行緒。
**調度器激活（Scheduler Activations）**是一種高效的多執行緒管理機制，特別適用於多對多的執行緒模型。在這個模型中，應用程序的用戶執行緒（user threads）可以與內核執行緒（kernel threads）進行映射，允許靈活地調整和分配系統資源。

### 工作原理

調度器激活使用輕量級進程（Lightweight Processes, LWP）作為用戶執行緒和內核執行緒之間的中介。每個LWP代表一個虛擬處理器，允許進程在其上調度用戶執行緒。這樣，應用程序就可以將用戶執行緒的執行與內核執行緒的管理相結合。每個LWP都與一個內核執行緒相關聯，這使得系統能夠根據需要動態調整內核執行緒的數量。

### 調度器激活的優勢

調度器激活提供了上調用（upcalls）機制，這是一種從內核到用戶執行緒庫的通信方式。當內核需要與用戶執行緒庫進行交互以調整內核執行緒數量時，會發出上調用。這種通信方式允許應用程序在運行時保持正確的內核執行緒數量，從而提高性能和響應能力。

### 應用場景

調度器激活廣泛應用於需要高效並發處理的系統，例如伺服器應用和高性能計算環境。透過動態調整內核執行緒的數量，調度器激活能夠有效利用多核處理器的資源，提高整體系統的運行效率。
Operating System Examples
**Windows 執行緒（Windows Threads）**

- Windows 實現了 Windows API，這是 Windows 98、Windows NT、Windows 2000、Windows XP 和 Windows 7 的主要 API。
- 實現了一對一映射，屬於內核級別的執行緒。
  
每個執行緒包含以下內容：

- **執行緒 ID**：唯一標識每個執行緒的標識符。
- **寄存器集**：表示處理器狀態的寄存器集合。
- **用戶堆棧和內核堆棧**：用於執行緒在用戶模式或內核模式下運行時的分別堆棧。
- **私有數據存儲區**：由運行時庫和動態鏈接庫（DLL）使用的私有數據存儲區。

寄存器集、堆棧和私有存儲區統稱為執行緒的上下文（context）。
執行緒的主要數據結構包括：

- **ETHREAD（執行緒執行塊）**：包含指向執行緒所屬進程的指針以及指向 KTHREAD 的指針，位於內核空間。
  
- **KTHREAD（內核執行緒塊）**：包含調度和同步信息、內核模式堆棧、指向 TEB 的指針，位於內核空間。
  
- **TEB（執行緒環境塊）**：包含執行緒 ID、用戶模式堆棧、執行緒本地存儲，位於用戶空間。
**Linux 執行緒（Linux Threads）**

- Linux 將執行緒稱為任務（tasks），而非執行緒（threads）。
- 執行緒的創建是通過 `clone()` 系統調用來完成的。
- `clone()` 允許子任務共享父任務（進程）的地址空間。
- 標誌（Flags）控制執行緒的行為。
- `struct task_struct` 指向進程數據結構（共享或唯一）。![](https://s3-ap-northeast-1.amazonaws.com/g0v-hackmd-images/uploads/upload_48950abd30afaf4c07ee345df1a5b7c3.PNG)
