---
tags: vtaiwan
---
# AI 用於數位公民參與經驗共筆

## 緣起
- 在 6/3 收到 FNF 夥伴的信件，長期關注數位公民參與的組織 People Powered 正在收集應用人工智慧到數位公民參與的回饋。覺得這是一個可以輸出議題小聚經驗的機會。[name=peter]
- 相關資訊如下：
:::info
Our partner—People Powered is collecting best practices of digital participation and AI applications that have resulted in clear benefits for governments, organizations, and communities to facilitate people's participation, particularly from Africa, Asia (Of course, for friends in Taiwan, it definitely includes Taiwan, where our hub is located), Eastern Europe, and Latin America. Selected cases will be part of the new digital participation guide and that we are developing with People Powered. If you or your offices know/have done any great practices from your offices or https://www.peoplepowered.org/ your offices' partner organizations, please feel free to submit it to Submit here by June 10.
:::

## 我想要參與的話，我可以怎麼做？
- 你可以直接在下面打上你想要給出的建議。
- 如果你的建議牽涉到特定的情境，建議好好說明相關的情境。


## 意見收集區
### Joshua Yang: 
From vTaiwan's perspective, AI works most effectively when different tools handle distinct democratic challenges. Rather than seeking one universal solution, we match specific technologies to particular participatory problems based on what we've already implemented and what we envision for the future.

Our current approach focuses on how AI technologies work together across the democratic process. We currently deploy different tools at two main stages: first, mapping citizen opinions through Polis; then facilitating deeper discussion through LLM-monitored deliberation. Each stage addresses specific barriers to meaningful participation, whilst we envision expanding this toolkit to include better information-gathering tools.

**Understanding:** Polis currently handles broad participation through intelligent consensus-finding that actively encourages perspective-taking. Our existing system does far more than simply map opinions. Polis deliberately nudges participants towards greater understanding of alternative viewpoints by strategically presenting statements from people who hold different views. This creates a dynamic learning environment where people often discover common ground they didn't know existed, or develop more nuanced understanding of why others hold different positions. The approach effectively processes large-scale input: by 2020, vTaiwan's mailing list included 200,000 individuals Lessons From Consensus Building in Taiwan, revealing not just where people currently stand, but helping them explore different perspectives through respectful engagement.

LLMs currently analyse these Polis clusters to understand the reasoning behind different opinion camps. Once Polis has mapped public opinion, we deploy large language models to examine what distinguishes different groups of participants. The LLMs process the specific statements that each cluster agreed or disagreed with, identifying the underlying values, concerns, or assumptions that drive different positions. This analysis reveals not just that people hold different views, but why they hold them—whether disagreements stem from different priorities, different factual understandings, or different experiences.

**Deliberating:** During face-to-face deliberation, LLMs currently monitor conversations to track how understanding evolves. Armed with insights about different opinion camps from the Polis analysis, LLM technology monitors live discussions to identify when participants begin to understand alternative viewpoints or when new consensus emerges around unexpected solutions. This creates a feedback loop from opinion mapping through analysis to deep deliberation.

**Learning:** Future developments focus on realising our vision for enhanced information-gathering before participation begins. We're exploring AI agents that could autonomously research policy questions and interactive LLM-based documents that would allow citizens to explore issues through conversation-style interfaces. These envisioned tools would strengthen the preparation phase, ensuring participants arrive at both Polis voting and face-to-face discussions with robust understanding of technical details and broader context.

Human validation ensures democratic accountability, particularly around AI-generated summaries. The most critical oversight occurs when AI systems summarise both the Polis cluster analysis and subsequent face-to-face conversations. Participants vote on these summaries to verify they accurately capture what different opinion camps actually believe and what was genuinely discussed, ensuring AI cannot misrepresent human voices.

### Peter 
1. 核心還是在參與者對於人工智慧工具的信任上。
    - 最近一篇在 reddit 網路論壇上測試人工智慧與人類生成結果的研究引發的爭議帶出了這個議題背後的爭議。
    - 在討論過程中，有參與者詢問人工智慧的資料如何生成，以及如何被利用。
2. 人工智慧協助修正與改進意見，會有助於部分參與者在審議與討論程序中的表達。
3. 作為審議主持人，發現在審議討論的過程中其實還是有需要人類投入的。
    - 例如，在不同的利害關係人發言時，如何引導大家發言、穿插不同的討論內容，以及適時提供相關的案例與資訊，促進更深度的討論，這部分是人工智慧目前還無法取代的。
5. 人工智慧在整理資料與彙整資訊上，具有讓審議的過程變得更即時與動態的潛力（可以現場即時結合參與者提出的意見，進行修正
6. 相關的

### Anan 
1. 請人工智慧生成或者是產出的意見，是否需要註明？如果不揭露，是否會讓他人誤以為是其他真人的意見？
2. 如果大量意見來自 AI，決策者是否會失去對參與品質的信任？
3. 3. 參與門檻與公平性
    * 有人因語言或表達能力差，需要靠 AI 才能參與。揭露會讓他們被標籤嗎？
    * 有錢人可用 GPT-4，沒錢的只能用免費版本，這樣是否不公平？
4. 具體揭露方式
    * 是否應該在論壇留言或問卷回饋上設置「是否使用 AI 協助」的勾選？
    * 是否應設計技術性自動偵測 AI 文本的機制？（如 spam check）

### Yu ting
1. 與人工智慧互動確實會影響人類的意見。不過目前的研究都是聚焦在審議場合之外。
    - 實驗：利用一段文字，標註有 AI 以及由人類生成，看看受試者對於這段文字的反應是什麼。
3. 審議的過程中有很多很難標準化的內容，或許可以透過準實驗的方式來討論我們想要討論的變項。
    - 如果要做實驗的話，參與者的背景與主題上可能也都要控制。

### Tim
1. AI 可以應用的地方：
    - 討論 (實體 or 線上) → [對話逐字稿] → [重點摘要 (爭點 or 共識)] 
2. 對於 AI 的揭露是可以做，也可以不做的
3. 從上一次議題小聚的經驗來看，由 AI 來提供基本素材（將討論內容轉成逐字稿），再由人類來檢查，檢查後再來餵給 AI進行重點摘要的內容，可以節省人力。
4. 目標是讓討論能夠延續，甚至是持續修正。
5. 對於是否要揭露，在意的是錯誤能不能夠被修正的機制，因為人跟 AI 都有可能犯罪，藉由設計機制來做錯誤修正，是比較重要。